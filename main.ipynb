{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install gym pyvirtualdisplay\n",
    "!sudo apt-get install -y xvfb python-opengl ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install --upgrade setuptools --user\n",
    "!pip3 install ez_setup \n",
    "!pip3 install gym[atari] \n",
    "!pip3 install gym[accept-rom-license] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import gym\n",
    "import torch\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils import find_max_lives, check_live, get_frame, get_init_state\n",
    "from model import DQN\n",
    "from config import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://www.gymlibrary.dev/environments/atari/breakout/. \n",
    "\n",
    "In breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_lives = find_max_lives(env)\n",
    "state_size = env.observation_space.shape\n",
    "action_size = 3 #fire, left, and right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DQN Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n",
    "\n",
    "__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n",
    "\n",
    "__Frame__ : Number of frames processed in total.\n",
    "\n",
    "__Memory Size__ : The current size of the replay memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_dqn = False # set to True if using double DQN agent\n",
    "\n",
    "if double_dqn:\n",
    "    from agent_double import Agent\n",
    "else:\n",
    "    from agent import Agent\n",
    "\n",
    "agent = Agent(action_size)\n",
    "evaluation_reward = deque(maxlen=evaluation_reward_length)\n",
    "frame = 0\n",
    "memory_size = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 1.0   memory length: 7670   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4878048780487805\n",
      "episode: 1   score: 0.0   memory length: 7793   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4523809523809523\n",
      "episode: 2   score: 3.0   memory length: 8060   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.4883720930232558\n",
      "episode: 3   score: 2.0   memory length: 8279   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 4   score: 0.0   memory length: 8401   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4666666666666666\n",
      "episode: 5   score: 3.0   memory length: 8626   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 6   score: 0.0   memory length: 8748   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4680851063829787\n",
      "episode: 7   score: 3.0   memory length: 8996   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 8   score: 0.0   memory length: 9119   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.469387755102041\n",
      "episode: 9   score: 2.0   memory length: 9316   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 10   score: 1.0   memory length: 9485   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.4705882352941178\n",
      "episode: 11   score: 2.0   memory length: 9703   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.4807692307692308\n",
      "episode: 12   score: 2.0   memory length: 9901   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.490566037735849\n",
      "episode: 13   score: 2.0   memory length: 10118   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 14   score: 4.0   memory length: 10393   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.5454545454545454\n",
      "episode: 15   score: 0.0   memory length: 10516   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5178571428571428\n",
      "episode: 16   score: 2.0   memory length: 10714   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5263157894736843\n",
      "episode: 17   score: 0.0   memory length: 10837   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 18   score: 2.0   memory length: 11055   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.5084745762711864\n",
      "episode: 19   score: 0.0   memory length: 11178   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4833333333333334\n",
      "episode: 20   score: 0.0   memory length: 11301   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.459016393442623\n",
      "episode: 21   score: 3.0   memory length: 11526   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.4838709677419355\n",
      "episode: 22   score: 3.0   memory length: 11770   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.507936507936508\n",
      "episode: 23   score: 2.0   memory length: 11968   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.515625\n",
      "episode: 24   score: 2.0   memory length: 12166   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.523076923076923\n",
      "episode: 25   score: 1.0   memory length: 12317   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5151515151515151\n",
      "episode: 26   score: 10.0   memory length: 12744   epsilon: 1.0    steps: 427    lr: 0.0001     evaluation reward: 1.6417910447761195\n",
      "episode: 27   score: 1.0   memory length: 12913   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.6323529411764706\n",
      "episode: 28   score: 0.0   memory length: 13036   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.608695652173913\n",
      "episode: 29   score: 0.0   memory length: 13159   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5857142857142856\n",
      "episode: 30   score: 7.0   memory length: 13459   epsilon: 1.0    steps: 300    lr: 0.0001     evaluation reward: 1.6619718309859155\n",
      "episode: 31   score: 1.0   memory length: 13627   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.6527777777777777\n",
      "episode: 32   score: 1.0   memory length: 13796   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.643835616438356\n",
      "episode: 33   score: 2.0   memory length: 13993   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.6486486486486487\n",
      "episode: 34   score: 0.0   memory length: 14116   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6266666666666667\n",
      "episode: 35   score: 0.0   memory length: 14239   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.605263157894737\n",
      "episode: 36   score: 2.0   memory length: 14456   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.6103896103896105\n",
      "episode: 37   score: 2.0   memory length: 14654   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.6153846153846154\n",
      "episode: 38   score: 0.0   memory length: 14777   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5949367088607596\n",
      "episode: 39   score: 5.0   memory length: 15120   epsilon: 1.0    steps: 343    lr: 0.0001     evaluation reward: 1.6375\n",
      "episode: 40   score: 3.0   memory length: 15348   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.654320987654321\n",
      "episode: 41   score: 1.0   memory length: 15517   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.646341463414634\n",
      "episode: 42   score: 2.0   memory length: 15735   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.6506024096385543\n",
      "episode: 43   score: 2.0   memory length: 15933   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.6547619047619047\n",
      "episode: 44   score: 4.0   memory length: 16224   epsilon: 1.0    steps: 291    lr: 0.0001     evaluation reward: 1.6823529411764706\n",
      "episode: 45   score: 3.0   memory length: 16451   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.697674418604651\n",
      "episode: 46   score: 0.0   memory length: 16574   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6781609195402298\n",
      "episode: 47   score: 0.0   memory length: 16697   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6590909090909092\n",
      "episode: 48   score: 2.0   memory length: 16895   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.6629213483146068\n",
      "episode: 49   score: 2.0   memory length: 17096   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.6666666666666667\n",
      "episode: 50   score: 2.0   memory length: 17314   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.6703296703296704\n",
      "episode: 51   score: 5.0   memory length: 17625   epsilon: 1.0    steps: 311    lr: 0.0001     evaluation reward: 1.7065217391304348\n",
      "episode: 52   score: 3.0   memory length: 17895   epsilon: 1.0    steps: 270    lr: 0.0001     evaluation reward: 1.7204301075268817\n",
      "episode: 53   score: 2.0   memory length: 18112   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.7234042553191489\n",
      "episode: 54   score: 3.0   memory length: 18338   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.736842105263158\n",
      "episode: 55   score: 2.0   memory length: 18561   epsilon: 1.0    steps: 223    lr: 0.0001     evaluation reward: 1.7395833333333333\n",
      "episode: 56   score: 2.0   memory length: 18758   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.7422680412371134\n",
      "episode: 57   score: 1.0   memory length: 18930   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.7346938775510203\n",
      "episode: 58   score: 0.0   memory length: 19053   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7171717171717171\n",
      "episode: 59   score: 0.0   memory length: 19176   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 60   score: 1.0   memory length: 19327   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 61   score: 2.0   memory length: 19542   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 62   score: 1.0   memory length: 19710   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 63   score: 5.0   memory length: 20029   epsilon: 1.0    steps: 319    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 64   score: 0.0   memory length: 20152   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 65   score: 1.0   memory length: 20303   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 66   score: 3.0   memory length: 20550   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 67   score: 1.0   memory length: 20718   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 68   score: 3.0   memory length: 20985   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 69   score: 0.0   memory length: 21107   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 70   score: 2.0   memory length: 21307   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 71   score: 2.0   memory length: 21525   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 72   score: 1.0   memory length: 21675   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 73   score: 1.0   memory length: 21847   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 74   score: 4.0   memory length: 22143   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 75   score: 0.0   memory length: 22266   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 76   score: 1.0   memory length: 22417   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 77   score: 4.0   memory length: 22690   epsilon: 1.0    steps: 273    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 78   score: 1.0   memory length: 22841   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 79   score: 1.0   memory length: 23010   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 80   score: 0.0   memory length: 23132   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 81   score: 1.0   memory length: 23283   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 82   score: 0.0   memory length: 23406   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 83   score: 3.0   memory length: 23669   epsilon: 1.0    steps: 263    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 84   score: 1.0   memory length: 23839   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 85   score: 0.0   memory length: 23962   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 86   score: 0.0   memory length: 24084   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 87   score: 4.0   memory length: 24358   epsilon: 1.0    steps: 274    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 88   score: 1.0   memory length: 24526   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 89   score: 2.0   memory length: 24726   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 90   score: 2.0   memory length: 24924   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 91   score: 2.0   memory length: 25122   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 92   score: 0.0   memory length: 25245   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 93   score: 1.0   memory length: 25396   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 94   score: 3.0   memory length: 25645   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 95   score: 1.0   memory length: 25816   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 96   score: 0.0   memory length: 25938   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 97   score: 0.0   memory length: 26060   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 98   score: 3.0   memory length: 26308   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 99   score: 5.0   memory length: 26675   epsilon: 1.0    steps: 367    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 100   score: 3.0   memory length: 26922   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 101   score: 1.0   memory length: 27073   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 102   score: 0.0   memory length: 27195   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 103   score: 2.0   memory length: 27393   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 104   score: 2.0   memory length: 27591   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 105   score: 1.0   memory length: 27763   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 106   score: 0.0   memory length: 27886   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 107   score: 2.0   memory length: 28105   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 108   score: 2.0   memory length: 28303   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 109   score: 0.0   memory length: 28426   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 110   score: 0.0   memory length: 28549   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 111   score: 3.0   memory length: 28795   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 112   score: 4.0   memory length: 29076   epsilon: 1.0    steps: 281    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 113   score: 3.0   memory length: 29343   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 114   score: 4.0   memory length: 29640   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 115   score: 1.0   memory length: 29790   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 116   score: 2.0   memory length: 29988   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 117   score: 1.0   memory length: 30158   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 118   score: 3.0   memory length: 30404   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 119   score: 3.0   memory length: 30648   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 120   score: 0.0   memory length: 30771   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 121   score: 0.0   memory length: 30894   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 122   score: 5.0   memory length: 31237   epsilon: 1.0    steps: 343    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 123   score: 0.0   memory length: 31360   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 124   score: 0.0   memory length: 31483   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 125   score: 3.0   memory length: 31748   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 126   score: 2.0   memory length: 31946   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 127   score: 1.0   memory length: 32097   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 128   score: 0.0   memory length: 32220   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 129   score: 2.0   memory length: 32418   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 130   score: 1.0   memory length: 32588   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 131   score: 0.0   memory length: 32710   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 132   score: 1.0   memory length: 32880   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 133   score: 0.0   memory length: 33003   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 134   score: 3.0   memory length: 33249   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 135   score: 1.0   memory length: 33399   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 136   score: 2.0   memory length: 33597   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 137   score: 0.0   memory length: 33720   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 138   score: 3.0   memory length: 33968   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 139   score: 1.0   memory length: 34138   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 140   score: 1.0   memory length: 34309   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 141   score: 2.0   memory length: 34511   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 142   score: 0.0   memory length: 34634   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 143   score: 0.0   memory length: 34757   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 144   score: 0.0   memory length: 34880   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 145   score: 3.0   memory length: 35127   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 146   score: 0.0   memory length: 35250   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 147   score: 0.0   memory length: 35372   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 148   score: 0.0   memory length: 35494   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 149   score: 1.0   memory length: 35645   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 150   score: 3.0   memory length: 35888   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 151   score: 0.0   memory length: 36010   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 152   score: 1.0   memory length: 36162   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 153   score: 0.0   memory length: 36284   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 154   score: 1.0   memory length: 36453   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 155   score: 1.0   memory length: 36625   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 156   score: 3.0   memory length: 36872   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 157   score: 2.0   memory length: 37091   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 158   score: 0.0   memory length: 37213   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 159   score: 3.0   memory length: 37480   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 160   score: 2.0   memory length: 37678   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 161   score: 2.0   memory length: 37894   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 162   score: 4.0   memory length: 38170   epsilon: 1.0    steps: 276    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 163   score: 1.0   memory length: 38321   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 164   score: 0.0   memory length: 38444   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 165   score: 0.0   memory length: 38567   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 166   score: 0.0   memory length: 38690   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 167   score: 1.0   memory length: 38860   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 168   score: 1.0   memory length: 39032   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 169   score: 0.0   memory length: 39155   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 170   score: 2.0   memory length: 39374   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 171   score: 0.0   memory length: 39497   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 172   score: 1.0   memory length: 39666   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 173   score: 1.0   memory length: 39838   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 174   score: 1.0   memory length: 39988   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 175   score: 2.0   memory length: 40186   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 176   score: 2.0   memory length: 40384   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 177   score: 2.0   memory length: 40582   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 178   score: 1.0   memory length: 40734   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 179   score: 0.0   memory length: 40856   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 180   score: 1.0   memory length: 41024   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 181   score: 0.0   memory length: 41147   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 182   score: 0.0   memory length: 41270   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 183   score: 4.0   memory length: 41545   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 184   score: 3.0   memory length: 41796   epsilon: 1.0    steps: 251    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 185   score: 1.0   memory length: 41965   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 186   score: 0.0   memory length: 42087   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 187   score: 3.0   memory length: 42333   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 188   score: 3.0   memory length: 42579   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 189   score: 0.0   memory length: 42702   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 190   score: 2.0   memory length: 42918   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 191   score: 0.0   memory length: 43041   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 192   score: 0.0   memory length: 43164   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 193   score: 0.0   memory length: 43287   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 194   score: 2.0   memory length: 43507   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 195   score: 3.0   memory length: 43733   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 196   score: 1.0   memory length: 43901   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 197   score: 2.0   memory length: 44118   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 198   score: 1.0   memory length: 44269   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 199   score: 2.0   memory length: 44466   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 200   score: 0.0   memory length: 44588   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 201   score: 2.0   memory length: 44807   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 202   score: 2.0   memory length: 45005   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 203   score: 2.0   memory length: 45223   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 204   score: 0.0   memory length: 45346   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 205   score: 2.0   memory length: 45543   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 206   score: 1.0   memory length: 45711   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 207   score: 1.0   memory length: 45880   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 208   score: 3.0   memory length: 46148   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 209   score: 0.0   memory length: 46270   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 210   score: 0.0   memory length: 46393   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 211   score: 2.0   memory length: 46609   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 212   score: 0.0   memory length: 46732   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 213   score: 3.0   memory length: 46998   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 214   score: 0.0   memory length: 47121   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 215   score: 3.0   memory length: 47347   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 216   score: 2.0   memory length: 47562   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 217   score: 3.0   memory length: 47829   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 218   score: 4.0   memory length: 48085   epsilon: 1.0    steps: 256    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 219   score: 1.0   memory length: 48256   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 220   score: 2.0   memory length: 48435   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 221   score: 0.0   memory length: 48558   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 222   score: 2.0   memory length: 48756   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 223   score: 2.0   memory length: 48954   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 224   score: 3.0   memory length: 49199   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 225   score: 1.0   memory length: 49350   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 226   score: 7.0   memory length: 49700   epsilon: 1.0    steps: 350    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 227   score: 2.0   memory length: 49918   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 228   score: 0.0   memory length: 50041   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 229   score: 1.0   memory length: 50210   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 230   score: 0.0   memory length: 50332   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 231   score: 0.0   memory length: 50455   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 232   score: 1.0   memory length: 50627   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 233   score: 1.0   memory length: 50797   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 234   score: 1.0   memory length: 50948   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 235   score: 5.0   memory length: 51293   epsilon: 1.0    steps: 345    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 236   score: 2.0   memory length: 51490   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 237   score: 0.0   memory length: 51612   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 238   score: 1.0   memory length: 51783   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 239   score: 5.0   memory length: 52070   epsilon: 1.0    steps: 287    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 240   score: 2.0   memory length: 52289   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 241   score: 2.0   memory length: 52487   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 242   score: 1.0   memory length: 52638   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 243   score: 2.0   memory length: 52858   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 244   score: 1.0   memory length: 53009   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 245   score: 0.0   memory length: 53132   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 246   score: 1.0   memory length: 53283   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 247   score: 1.0   memory length: 53434   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 248   score: 2.0   memory length: 53652   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 249   score: 3.0   memory length: 53917   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 250   score: 2.0   memory length: 54132   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 251   score: 2.0   memory length: 54348   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 252   score: 1.0   memory length: 54516   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 253   score: 3.0   memory length: 54762   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 254   score: 0.0   memory length: 54884   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 255   score: 2.0   memory length: 55107   epsilon: 1.0    steps: 223    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 256   score: 1.0   memory length: 55276   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 257   score: 4.0   memory length: 55555   epsilon: 1.0    steps: 279    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 258   score: 0.0   memory length: 55678   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 259   score: 2.0   memory length: 55876   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 260   score: 2.0   memory length: 56074   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 261   score: 3.0   memory length: 56322   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 262   score: 0.0   memory length: 56444   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 263   score: 0.0   memory length: 56567   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 264   score: 1.0   memory length: 56738   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 265   score: 1.0   memory length: 56907   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 266   score: 0.0   memory length: 57029   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 267   score: 1.0   memory length: 57201   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 268   score: 2.0   memory length: 57399   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 269   score: 0.0   memory length: 57521   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 270   score: 0.0   memory length: 57644   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 271   score: 0.0   memory length: 57767   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 272   score: 2.0   memory length: 57966   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 273   score: 1.0   memory length: 58135   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 274   score: 2.0   memory length: 58351   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 275   score: 2.0   memory length: 58531   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 276   score: 6.0   memory length: 58925   epsilon: 1.0    steps: 394    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 277   score: 0.0   memory length: 59048   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 278   score: 0.0   memory length: 59171   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 279   score: 0.0   memory length: 59294   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 280   score: 1.0   memory length: 59445   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 281   score: 3.0   memory length: 59672   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 282   score: 2.0   memory length: 59889   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 283   score: 2.0   memory length: 60107   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 284   score: 2.0   memory length: 60325   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 285   score: 0.0   memory length: 60447   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 286   score: 3.0   memory length: 60692   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 287   score: 2.0   memory length: 60910   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 288   score: 0.0   memory length: 61033   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 289   score: 2.0   memory length: 61234   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 290   score: 0.0   memory length: 61357   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 291   score: 2.0   memory length: 61575   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 292   score: 3.0   memory length: 61821   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 293   score: 1.0   memory length: 61990   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 294   score: 1.0   memory length: 62140   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 295   score: 2.0   memory length: 62338   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 296   score: 2.0   memory length: 62536   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 297   score: 3.0   memory length: 62785   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 298   score: 3.0   memory length: 63034   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 299   score: 2.0   memory length: 63232   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 300   score: 1.0   memory length: 63383   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 301   score: 0.0   memory length: 63505   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 302   score: 1.0   memory length: 63675   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 303   score: 3.0   memory length: 63922   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 304   score: 1.0   memory length: 64072   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 305   score: 1.0   memory length: 64243   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 306   score: 0.0   memory length: 64365   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 307   score: 0.0   memory length: 64488   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 308   score: 4.0   memory length: 64764   epsilon: 1.0    steps: 276    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 309   score: 0.0   memory length: 64887   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 310   score: 0.0   memory length: 65009   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 311   score: 3.0   memory length: 65273   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 312   score: 1.0   memory length: 65441   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 313   score: 1.0   memory length: 65591   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 314   score: 0.0   memory length: 65714   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 315   score: 8.0   memory length: 66055   epsilon: 1.0    steps: 341    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 316   score: 0.0   memory length: 66178   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 317   score: 2.0   memory length: 66376   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 318   score: 0.0   memory length: 66499   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 319   score: 3.0   memory length: 66746   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 320   score: 3.0   memory length: 66994   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 321   score: 0.0   memory length: 67117   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 322   score: 2.0   memory length: 67315   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 323   score: 4.0   memory length: 67575   epsilon: 1.0    steps: 260    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 324   score: 2.0   memory length: 67773   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 325   score: 3.0   memory length: 68022   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 326   score: 0.0   memory length: 68145   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 327   score: 2.0   memory length: 68325   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 328   score: 0.0   memory length: 68447   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 329   score: 3.0   memory length: 68711   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 330   score: 1.0   memory length: 68883   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 331   score: 2.0   memory length: 69105   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 332   score: 3.0   memory length: 69332   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 333   score: 1.0   memory length: 69483   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 334   score: 0.0   memory length: 69605   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 335   score: 3.0   memory length: 69850   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 336   score: 0.0   memory length: 69973   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 337   score: 1.0   memory length: 70125   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 338   score: 4.0   memory length: 70385   epsilon: 1.0    steps: 260    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 339   score: 1.0   memory length: 70556   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 340   score: 0.0   memory length: 70678   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 341   score: 7.0   memory length: 70977   epsilon: 1.0    steps: 299    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 342   score: 0.0   memory length: 71100   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 343   score: 0.0   memory length: 71222   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 344   score: 2.0   memory length: 71420   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 345   score: 1.0   memory length: 71571   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 346   score: 3.0   memory length: 71817   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 347   score: 1.0   memory length: 71968   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 348   score: 0.0   memory length: 72090   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 349   score: 3.0   memory length: 72317   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 350   score: 0.0   memory length: 72440   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 351   score: 0.0   memory length: 72563   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 352   score: 1.0   memory length: 72714   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 353   score: 1.0   memory length: 72883   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 354   score: 0.0   memory length: 73006   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 355   score: 1.0   memory length: 73157   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 356   score: 3.0   memory length: 73382   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 357   score: 0.0   memory length: 73504   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 358   score: 0.0   memory length: 73627   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 359   score: 3.0   memory length: 73853   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 360   score: 1.0   memory length: 74004   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 361   score: 1.0   memory length: 74172   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 362   score: 2.0   memory length: 74391   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 363   score: 4.0   memory length: 74687   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 364   score: 0.0   memory length: 74809   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 365   score: 1.0   memory length: 74980   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 366   score: 1.0   memory length: 75149   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 367   score: 3.0   memory length: 75394   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 368   score: 2.0   memory length: 75592   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 369   score: 0.0   memory length: 75714   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 370   score: 0.0   memory length: 75837   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 371   score: 2.0   memory length: 76034   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 372   score: 3.0   memory length: 76280   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 373   score: 4.0   memory length: 76573   epsilon: 1.0    steps: 293    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 374   score: 2.0   memory length: 76791   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 375   score: 2.0   memory length: 76988   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 376   score: 0.0   memory length: 77111   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 377   score: 0.0   memory length: 77234   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 378   score: 1.0   memory length: 77405   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 379   score: 2.0   memory length: 77605   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 380   score: 1.0   memory length: 77756   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 381   score: 2.0   memory length: 77955   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 382   score: 1.0   memory length: 78124   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 383   score: 0.0   memory length: 78247   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 384   score: 0.0   memory length: 78370   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 385   score: 2.0   memory length: 78585   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 386   score: 2.0   memory length: 78782   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 387   score: 2.0   memory length: 78964   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 388   score: 0.0   memory length: 79087   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 389   score: 2.0   memory length: 79306   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 390   score: 1.0   memory length: 79475   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 391   score: 1.0   memory length: 79626   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 392   score: 2.0   memory length: 79824   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 393   score: 1.0   memory length: 79993   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 394   score: 1.0   memory length: 80164   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 395   score: 4.0   memory length: 80461   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 396   score: 2.0   memory length: 80659   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 397   score: 2.0   memory length: 80875   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 398   score: 3.0   memory length: 81101   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 399   score: 0.0   memory length: 81224   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 400   score: 1.0   memory length: 81393   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 401   score: 4.0   memory length: 81668   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 402   score: 2.0   memory length: 81884   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 403   score: 1.0   memory length: 82035   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 404   score: 2.0   memory length: 82252   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 405   score: 0.0   memory length: 82375   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 406   score: 1.0   memory length: 82545   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 407   score: 2.0   memory length: 82731   epsilon: 1.0    steps: 186    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 408   score: 2.0   memory length: 82929   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 409   score: 4.0   memory length: 83222   epsilon: 1.0    steps: 293    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 410   score: 2.0   memory length: 83440   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 411   score: 1.0   memory length: 83611   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 412   score: 0.0   memory length: 83733   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 413   score: 0.0   memory length: 83855   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 414   score: 2.0   memory length: 84074   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 415   score: 0.0   memory length: 84197   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 416   score: 0.0   memory length: 84319   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 417   score: 0.0   memory length: 84441   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 418   score: 2.0   memory length: 84657   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 419   score: 4.0   memory length: 84954   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 420   score: 2.0   memory length: 85152   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 421   score: 0.0   memory length: 85275   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 422   score: 1.0   memory length: 85446   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 423   score: 5.0   memory length: 85735   epsilon: 1.0    steps: 289    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 424   score: 0.0   memory length: 85858   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 425   score: 1.0   memory length: 86027   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 426   score: 1.0   memory length: 86178   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 427   score: 3.0   memory length: 86388   epsilon: 1.0    steps: 210    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 428   score: 0.0   memory length: 86511   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 429   score: 1.0   memory length: 86662   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 430   score: 1.0   memory length: 86830   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 431   score: 1.0   memory length: 86981   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 432   score: 0.0   memory length: 87103   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 433   score: 2.0   memory length: 87320   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 434   score: 1.0   memory length: 87489   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 435   score: 2.0   memory length: 87688   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 436   score: 1.0   memory length: 87839   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 437   score: 2.0   memory length: 88037   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 438   score: 1.0   memory length: 88188   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 439   score: 3.0   memory length: 88434   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 440   score: 2.0   memory length: 88632   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 441   score: 1.0   memory length: 88783   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 442   score: 0.0   memory length: 88906   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 443   score: 0.0   memory length: 89028   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 444   score: 3.0   memory length: 89275   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 445   score: 3.0   memory length: 89493   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 446   score: 2.0   memory length: 89692   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 447   score: 1.0   memory length: 89862   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 448   score: 1.0   memory length: 90012   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 449   score: 2.0   memory length: 90232   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 450   score: 1.0   memory length: 90382   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 451   score: 1.0   memory length: 90551   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 452   score: 0.0   memory length: 90673   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 453   score: 2.0   memory length: 90855   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 454   score: 0.0   memory length: 90978   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 455   score: 1.0   memory length: 91129   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 456   score: 3.0   memory length: 91402   epsilon: 1.0    steps: 273    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 457   score: 0.0   memory length: 91525   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 458   score: 2.0   memory length: 91723   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 459   score: 2.0   memory length: 91921   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 460   score: 0.0   memory length: 92044   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 461   score: 0.0   memory length: 92166   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 462   score: 2.0   memory length: 92364   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 463   score: 3.0   memory length: 92611   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 464   score: 0.0   memory length: 92733   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 465   score: 1.0   memory length: 92904   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 466   score: 0.0   memory length: 93026   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 467   score: 0.0   memory length: 93149   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 468   score: 2.0   memory length: 93368   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 469   score: 0.0   memory length: 93491   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 470   score: 2.0   memory length: 93709   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 471   score: 2.0   memory length: 93907   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 472   score: 5.0   memory length: 94251   epsilon: 1.0    steps: 344    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 473   score: 2.0   memory length: 94470   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 474   score: 2.0   memory length: 94691   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 475   score: 0.0   memory length: 94814   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 476   score: 0.0   memory length: 94936   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 477   score: 2.0   memory length: 95134   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 478   score: 0.0   memory length: 95257   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 479   score: 1.0   memory length: 95427   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 480   score: 3.0   memory length: 95691   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 481   score: 1.0   memory length: 95844   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 482   score: 1.0   memory length: 95995   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 483   score: 1.0   memory length: 96167   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 484   score: 4.0   memory length: 96464   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 485   score: 0.0   memory length: 96587   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 486   score: 1.0   memory length: 96738   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 487   score: 1.0   memory length: 96907   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 488   score: 0.0   memory length: 97029   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 489   score: 1.0   memory length: 97197   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 490   score: 1.0   memory length: 97369   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 491   score: 2.0   memory length: 97567   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 492   score: 0.0   memory length: 97690   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 493   score: 2.0   memory length: 97887   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 494   score: 2.0   memory length: 98067   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 495   score: 1.0   memory length: 98235   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 496   score: 0.0   memory length: 98358   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 497   score: 0.0   memory length: 98481   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 498   score: 3.0   memory length: 98729   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 499   score: 2.0   memory length: 98930   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 500   score: 0.0   memory length: 99053   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 501   score: 1.0   memory length: 99223   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 502   score: 2.0   memory length: 99441   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 503   score: 0.0   memory length: 99564   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 504   score: 0.0   memory length: 99686   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 505   score: 3.0   memory length: 99929   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanshporwal/memory.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sample = np.array(sample)\n",
      "/home/vanshporwal/agent.py:63: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mini_batch = np.array(mini_batch).transpose()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 506   score: 3.0   memory length: 100173   epsilon: 0.9996535000000075    steps: 244    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 507   score: 0.0   memory length: 100296   epsilon: 0.9994099600000128    steps: 123    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 508   score: 1.0   memory length: 100466   epsilon: 0.9990733600000201    steps: 170    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 509   score: 2.0   memory length: 100665   epsilon: 0.9986793400000287    steps: 199    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 510   score: 2.0   memory length: 100863   epsilon: 0.9982873000000372    steps: 198    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 511   score: 2.0   memory length: 101060   epsilon: 0.9978972400000456    steps: 197    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 512   score: 0.0   memory length: 101183   epsilon: 0.9976537000000509    steps: 123    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 513   score: 3.0   memory length: 101430   epsilon: 0.9971646400000616    steps: 247    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 514   score: 4.0   memory length: 101708   epsilon: 0.9966142000000735    steps: 278    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 515   score: 2.0   memory length: 101926   epsilon: 0.9961825600000829    steps: 218    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 516   score: 0.0   memory length: 102049   epsilon: 0.9959390200000882    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 517   score: 3.0   memory length: 102318   epsilon: 0.9954064000000997    steps: 269    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 518   score: 0.0   memory length: 102440   epsilon: 0.995164840000105    steps: 122    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 519   score: 1.0   memory length: 102591   epsilon: 0.9948658600001115    steps: 151    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 520   score: 2.0   memory length: 102788   epsilon: 0.9944758000001199    steps: 197    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 521   score: 0.0   memory length: 102911   epsilon: 0.9942322600001252    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 522   score: 1.0   memory length: 103062   epsilon: 0.9939332800001317    steps: 151    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 523   score: 1.0   memory length: 103230   epsilon: 0.9936006400001389    steps: 168    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 524   score: 2.0   memory length: 103410   epsilon: 0.9932442400001467    steps: 180    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 525   score: 1.0   memory length: 103581   epsilon: 0.992905660000154    steps: 171    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 526   score: 0.0   memory length: 103704   epsilon: 0.9926621200001593    steps: 123    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 527   score: 0.0   memory length: 103827   epsilon: 0.9924185800001646    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 528   score: 4.0   memory length: 104122   epsilon: 0.9918344800001773    steps: 295    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 529   score: 2.0   memory length: 104340   epsilon: 0.9914028400001866    steps: 218    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 530   score: 1.0   memory length: 104490   epsilon: 0.9911058400001931    steps: 150    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 531   score: 2.0   memory length: 104710   epsilon: 0.9906702400002025    steps: 220    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 532   score: 1.0   memory length: 104880   epsilon: 0.9903336400002098    steps: 170    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 533   score: 1.0   memory length: 105031   epsilon: 0.9900346600002163    steps: 151    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 534   score: 0.0   memory length: 105153   epsilon: 0.9897931000002216    steps: 122    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 535   score: 0.0   memory length: 105275   epsilon: 0.9895515400002268    steps: 122    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 536   score: 2.0   memory length: 105473   epsilon: 0.9891595000002353    steps: 198    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 537   score: 0.0   memory length: 105596   epsilon: 0.9889159600002406    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 538   score: 2.0   memory length: 105776   epsilon: 0.9885595600002484    steps: 180    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 539   score: 1.0   memory length: 105926   epsilon: 0.9882625600002548    steps: 150    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 540   score: 1.0   memory length: 106097   epsilon: 0.9879239800002622    steps: 171    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 541   score: 1.0   memory length: 106266   epsilon: 0.9875893600002694    steps: 169    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 542   score: 2.0   memory length: 106464   epsilon: 0.9871973200002779    steps: 198    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 543   score: 2.0   memory length: 106681   epsilon: 0.9867676600002873    steps: 217    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 544   score: 0.0   memory length: 106804   epsilon: 0.9865241200002925    steps: 123    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 545   score: 1.0   memory length: 106956   epsilon: 0.9862231600002991    steps: 152    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 546   score: 1.0   memory length: 107124   epsilon: 0.9858905200003063    steps: 168    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 547   score: 2.0   memory length: 107345   epsilon: 0.9854529400003158    steps: 221    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 548   score: 0.0   memory length: 107468   epsilon: 0.9852094000003211    steps: 123    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 549   score: 4.0   memory length: 107761   epsilon: 0.9846292600003337    steps: 293    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 550   score: 0.0   memory length: 107883   epsilon: 0.9843877000003389    steps: 122    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 551   score: 1.0   memory length: 108052   epsilon: 0.9840530800003462    steps: 169    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 552   score: 2.0   memory length: 108269   epsilon: 0.9836234200003555    steps: 217    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 553   score: 0.0   memory length: 108391   epsilon: 0.9833818600003608    steps: 122    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 554   score: 0.0   memory length: 108514   epsilon: 0.983138320000366    steps: 123    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 555   score: 1.0   memory length: 108683   epsilon: 0.9828037000003733    steps: 169    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 556   score: 1.0   memory length: 108833   epsilon: 0.9825067000003798    steps: 150    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 557   score: 1.0   memory length: 109001   epsilon: 0.982174060000387    steps: 168    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 558   score: 3.0   memory length: 109227   epsilon: 0.9817265800003967    steps: 226    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 559   score: 3.0   memory length: 109460   epsilon: 0.9812652400004067    steps: 233    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 560   score: 2.0   memory length: 109660   epsilon: 0.9808692400004153    steps: 200    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 561   score: 0.0   memory length: 109782   epsilon: 0.9806276800004206    steps: 122    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 562   score: 0.0   memory length: 109905   epsilon: 0.9803841400004258    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 563   score: 2.0   memory length: 110103   epsilon: 0.9799921000004344    steps: 198    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 564   score: 1.0   memory length: 110254   epsilon: 0.9796931200004408    steps: 151    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 565   score: 2.0   memory length: 110471   epsilon: 0.9792634600004502    steps: 217    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 566   score: 0.0   memory length: 110594   epsilon: 0.9790199200004555    steps: 123    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 567   score: 0.0   memory length: 110717   epsilon: 0.9787763800004607    steps: 123    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 568   score: 2.0   memory length: 110914   epsilon: 0.9783863200004692    steps: 197    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 569   score: 3.0   memory length: 111164   epsilon: 0.97789132000048    steps: 250    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 570   score: 0.0   memory length: 111287   epsilon: 0.9776477800004852    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 571   score: 2.0   memory length: 111485   epsilon: 0.9772557400004938    steps: 198    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 572   score: 2.0   memory length: 111683   epsilon: 0.9768637000005023    steps: 198    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 573   score: 0.0   memory length: 111805   epsilon: 0.9766221400005075    steps: 122    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 574   score: 1.0   memory length: 111973   epsilon: 0.9762895000005147    steps: 168    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 575   score: 0.0   memory length: 112095   epsilon: 0.97604794000052    steps: 122    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 576   score: 4.0   memory length: 112374   epsilon: 0.975495520000532    steps: 279    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 577   score: 3.0   memory length: 112600   epsilon: 0.9750480400005417    steps: 226    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 578   score: 3.0   memory length: 112847   epsilon: 0.9745589800005523    steps: 247    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 579   score: 1.0   memory length: 113018   epsilon: 0.9742204000005596    steps: 171    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 580   score: 1.0   memory length: 113186   epsilon: 0.9738877600005669    steps: 168    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 581   score: 0.0   memory length: 113308   epsilon: 0.9736462000005721    steps: 122    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 582   score: 1.0   memory length: 113478   epsilon: 0.9733096000005794    steps: 170    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 583   score: 3.0   memory length: 113707   epsilon: 0.9728561800005893    steps: 229    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 584   score: 2.0   memory length: 113905   epsilon: 0.9724641400005978    steps: 198    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 585   score: 0.0   memory length: 114028   epsilon: 0.9722206000006031    steps: 123    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 586   score: 1.0   memory length: 114179   epsilon: 0.9719216200006096    steps: 151    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 587   score: 0.0   memory length: 114302   epsilon: 0.9716780800006148    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 588   score: 1.0   memory length: 114455   epsilon: 0.9713751400006214    steps: 153    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 589   score: 0.0   memory length: 114578   epsilon: 0.9711316000006267    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 590   score: 2.0   memory length: 114776   epsilon: 0.9707395600006352    steps: 198    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 591   score: 2.0   memory length: 114975   epsilon: 0.9703455400006438    steps: 199    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 592   score: 0.0   memory length: 115098   epsilon: 0.9701020000006491    steps: 123    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 593   score: 2.0   memory length: 115313   epsilon: 0.9696763000006583    steps: 215    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 594   score: 2.0   memory length: 115511   epsilon: 0.9692842600006668    steps: 198    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 595   score: 1.0   memory length: 115662   epsilon: 0.9689852800006733    steps: 151    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 596   score: 1.0   memory length: 115832   epsilon: 0.9686486800006806    steps: 170    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 597   score: 2.0   memory length: 116030   epsilon: 0.9682566400006891    steps: 198    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 598   score: 1.0   memory length: 116181   epsilon: 0.9679576600006956    steps: 151    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 599   score: 0.0   memory length: 116304   epsilon: 0.9677141200007009    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 600   score: 2.0   memory length: 116521   epsilon: 0.9672844600007102    steps: 217    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 601   score: 3.0   memory length: 116783   epsilon: 0.9667657000007215    steps: 262    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 602   score: 3.0   memory length: 117052   epsilon: 0.966233080000733    steps: 269    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 603   score: 2.0   memory length: 117250   epsilon: 0.9658410400007416    steps: 198    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 604   score: 1.0   memory length: 117421   epsilon: 0.9655024600007489    steps: 171    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 605   score: 2.0   memory length: 117619   epsilon: 0.9651104200007574    steps: 198    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 606   score: 2.0   memory length: 117802   epsilon: 0.9647480800007653    steps: 183    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 607   score: 1.0   memory length: 117973   epsilon: 0.9644095000007726    steps: 171    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 608   score: 3.0   memory length: 118242   epsilon: 0.9638768800007842    steps: 269    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 609   score: 2.0   memory length: 118459   epsilon: 0.9634472200007935    steps: 217    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 610   score: 4.0   memory length: 118753   epsilon: 0.9628651000008062    steps: 294    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 611   score: 1.0   memory length: 118903   epsilon: 0.9625681000008126    steps: 150    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 612   score: 2.0   memory length: 119121   epsilon: 0.962136460000822    steps: 218    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 613   score: 0.0   memory length: 119243   epsilon: 0.9618949000008272    steps: 122    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 614   score: 2.0   memory length: 119442   epsilon: 0.9615008800008358    steps: 199    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 615   score: 0.0   memory length: 119565   epsilon: 0.9612573400008411    steps: 123    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 616   score: 2.0   memory length: 119786   epsilon: 0.9608197600008506    steps: 221    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 617   score: 0.0   memory length: 119909   epsilon: 0.9605762200008559    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 618   score: 1.0   memory length: 120060   epsilon: 0.9602772400008623    steps: 151    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 619   score: 3.0   memory length: 120286   epsilon: 0.9598297600008721    steps: 226    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 620   score: 0.0   memory length: 120409   epsilon: 0.9595862200008773    steps: 123    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 621   score: 0.0   memory length: 120532   epsilon: 0.9593426800008826    steps: 123    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 622   score: 0.0   memory length: 120655   epsilon: 0.9590991400008879    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 623   score: 2.0   memory length: 120873   epsilon: 0.9586675000008973    steps: 218    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 624   score: 4.0   memory length: 121168   epsilon: 0.95808340000091    steps: 295    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 625   score: 0.0   memory length: 121291   epsilon: 0.9578398600009153    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 626   score: 1.0   memory length: 121442   epsilon: 0.9575408800009217    steps: 151    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 627   score: 0.0   memory length: 121565   epsilon: 0.957297340000927    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 628   score: 2.0   memory length: 121763   epsilon: 0.9569053000009355    steps: 198    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 629   score: 0.0   memory length: 121886   epsilon: 0.9566617600009408    steps: 123    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 630   score: 1.0   memory length: 122056   epsilon: 0.9563251600009481    steps: 170    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 631   score: 0.0   memory length: 122178   epsilon: 0.9560836000009534    steps: 122    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 632   score: 2.0   memory length: 122376   epsilon: 0.9556915600009619    steps: 198    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 633   score: 1.0   memory length: 122546   epsilon: 0.9553549600009692    steps: 170    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 634   score: 1.0   memory length: 122714   epsilon: 0.9550223200009764    steps: 168    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 635   score: 1.0   memory length: 122865   epsilon: 0.9547233400009829    steps: 151    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 636   score: 2.0   memory length: 123066   epsilon: 0.9543253600009916    steps: 201    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 637   score: 0.0   memory length: 123188   epsilon: 0.9540838000009968    steps: 122    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 638   score: 1.0   memory length: 123359   epsilon: 0.9537452200010041    steps: 171    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 639   score: 1.0   memory length: 123509   epsilon: 0.9534482200010106    steps: 150    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 640   score: 1.0   memory length: 123660   epsilon: 0.9531492400010171    steps: 151    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 641   score: 1.0   memory length: 123812   epsilon: 0.9528482800010236    steps: 152    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 642   score: 1.0   memory length: 123982   epsilon: 0.9525116800010309    steps: 170    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 643   score: 0.0   memory length: 124105   epsilon: 0.9522681400010362    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 644   score: 0.0   memory length: 124228   epsilon: 0.9520246000010415    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 645   score: 1.0   memory length: 124398   epsilon: 0.9516880000010488    steps: 170    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 646   score: 2.0   memory length: 124616   epsilon: 0.9512563600010582    steps: 218    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 647   score: 0.0   memory length: 124738   epsilon: 0.9510148000010634    steps: 122    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 648   score: 3.0   memory length: 125003   epsilon: 0.9504901000010748    steps: 265    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 649   score: 3.0   memory length: 125248   epsilon: 0.9500050000010853    steps: 245    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 650   score: 2.0   memory length: 125447   epsilon: 0.9496109800010939    steps: 199    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 651   score: 3.0   memory length: 125657   epsilon: 0.9491951800011029    steps: 210    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 652   score: 0.0   memory length: 125780   epsilon: 0.9489516400011082    steps: 123    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 653   score: 0.0   memory length: 125903   epsilon: 0.9487081000011135    steps: 123    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 654   score: 1.0   memory length: 126073   epsilon: 0.9483715000011208    steps: 170    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 655   score: 0.0   memory length: 126196   epsilon: 0.9481279600011261    steps: 123    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 656   score: 0.0   memory length: 126319   epsilon: 0.9478844200011314    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 657   score: 0.0   memory length: 126442   epsilon: 0.9476408800011367    steps: 123    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 658   score: 2.0   memory length: 126660   epsilon: 0.947209240001146    steps: 218    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 659   score: 1.0   memory length: 126810   epsilon: 0.9469122400011525    steps: 150    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 660   score: 0.0   memory length: 126933   epsilon: 0.9466687000011578    steps: 123    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 661   score: 4.0   memory length: 127231   epsilon: 0.9460786600011706    steps: 298    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 662   score: 2.0   memory length: 127446   epsilon: 0.9456529600011798    steps: 215    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 663   score: 0.0   memory length: 127569   epsilon: 0.9454094200011851    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 664   score: 1.0   memory length: 127720   epsilon: 0.9451104400011916    steps: 151    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 665   score: 0.0   memory length: 127843   epsilon: 0.9448669000011969    steps: 123    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 666   score: 2.0   memory length: 128041   epsilon: 0.9444748600012054    steps: 198    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 667   score: 0.0   memory length: 128164   epsilon: 0.9442313200012107    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 668   score: 0.0   memory length: 128287   epsilon: 0.943987780001216    steps: 123    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 669   score: 2.0   memory length: 128503   epsilon: 0.9435601000012253    steps: 216    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 670   score: 2.0   memory length: 128722   epsilon: 0.9431264800012347    steps: 219    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 671   score: 0.0   memory length: 128845   epsilon: 0.94288294000124    steps: 123    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 672   score: 2.0   memory length: 129043   epsilon: 0.9424909000012485    steps: 198    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 673   score: 1.0   memory length: 129211   epsilon: 0.9421582600012557    steps: 168    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 674   score: 6.0   memory length: 129605   epsilon: 0.9413781400012726    steps: 394    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 675   score: 0.0   memory length: 129727   epsilon: 0.9411365800012779    steps: 122    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 676   score: 1.0   memory length: 129898   epsilon: 0.9407980000012852    steps: 171    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 677   score: 2.0   memory length: 130114   epsilon: 0.9403703200012945    steps: 216    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 678   score: 1.0   memory length: 130265   epsilon: 0.940071340001301    steps: 151    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 679   score: 2.0   memory length: 130484   epsilon: 0.9396377200013104    steps: 219    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 680   score: 1.0   memory length: 130653   epsilon: 0.9393031000013177    steps: 169    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 681   score: 1.0   memory length: 130803   epsilon: 0.9390061000013241    steps: 150    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 682   score: 2.0   memory length: 131001   epsilon: 0.9386140600013326    steps: 198    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 683   score: 1.0   memory length: 131173   epsilon: 0.93827350000134    steps: 172    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 684   score: 1.0   memory length: 131325   epsilon: 0.9379725400013466    steps: 152    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 685   score: 0.0   memory length: 131447   epsilon: 0.9377309800013518    steps: 122    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 686   score: 1.0   memory length: 131616   epsilon: 0.9373963600013591    steps: 169    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 687   score: 0.0   memory length: 131738   epsilon: 0.9371548000013643    steps: 122    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 688   score: 1.0   memory length: 131907   epsilon: 0.9368201800013716    steps: 169    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 689   score: 2.0   memory length: 132105   epsilon: 0.9364281400013801    steps: 198    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 690   score: 1.0   memory length: 132274   epsilon: 0.9360935200013873    steps: 169    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 691   score: 0.0   memory length: 132397   epsilon: 0.9358499800013926    steps: 123    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 692   score: 0.0   memory length: 132520   epsilon: 0.9356064400013979    steps: 123    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 693   score: 3.0   memory length: 132767   epsilon: 0.9351173800014085    steps: 247    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 694   score: 0.0   memory length: 132889   epsilon: 0.9348758200014138    steps: 122    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 695   score: 3.0   memory length: 133116   epsilon: 0.9344263600014235    steps: 227    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 696   score: 3.0   memory length: 133361   epsilon: 0.9339412600014341    steps: 245    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 697   score: 1.0   memory length: 133512   epsilon: 0.9336422800014406    steps: 151    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 698   score: 0.0   memory length: 133635   epsilon: 0.9333987400014458    steps: 123    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 699   score: 1.0   memory length: 133803   epsilon: 0.9330661000014531    steps: 168    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 700   score: 0.0   memory length: 133926   epsilon: 0.9328225600014584    steps: 123    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 701   score: 1.0   memory length: 134095   epsilon: 0.9324879400014656    steps: 169    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 702   score: 0.0   memory length: 134217   epsilon: 0.9322463800014709    steps: 122    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 703   score: 0.0   memory length: 134339   epsilon: 0.9320048200014761    steps: 122    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 704   score: 1.0   memory length: 134491   epsilon: 0.9317038600014826    steps: 152    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 705   score: 1.0   memory length: 134660   epsilon: 0.9313692400014899    steps: 169    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 706   score: 1.0   memory length: 134811   epsilon: 0.9310702600014964    steps: 151    lr: 0.0001     evaluation reward: 1.15\n",
      "episode: 707   score: 2.0   memory length: 135008   epsilon: 0.9306802000015049    steps: 197    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 708   score: 3.0   memory length: 135233   epsilon: 0.9302347000015145    steps: 225    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 709   score: 2.0   memory length: 135430   epsilon: 0.929844640001523    steps: 197    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 710   score: 0.0   memory length: 135553   epsilon: 0.9296011000015283    steps: 123    lr: 0.0001     evaluation reward: 1.12\n",
      "episode: 711   score: 1.0   memory length: 135724   epsilon: 0.9292625200015356    steps: 171    lr: 0.0001     evaluation reward: 1.12\n",
      "episode: 712   score: 4.0   memory length: 136004   epsilon: 0.9287081200015477    steps: 280    lr: 0.0001     evaluation reward: 1.14\n",
      "episode: 713   score: 1.0   memory length: 136173   epsilon: 0.9283735000015549    steps: 169    lr: 0.0001     evaluation reward: 1.15\n",
      "episode: 714   score: 3.0   memory length: 136401   epsilon: 0.9279220600015647    steps: 228    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 715   score: 0.0   memory length: 136523   epsilon: 0.92768050000157    steps: 122    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 716   score: 2.0   memory length: 136720   epsilon: 0.9272904400015785    steps: 197    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 717   score: 1.0   memory length: 136888   epsilon: 0.9269578000015857    steps: 168    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 718   score: 0.0   memory length: 137011   epsilon: 0.926714260001591    steps: 123    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 719   score: 1.0   memory length: 137181   epsilon: 0.9263776600015983    steps: 170    lr: 0.0001     evaluation reward: 1.14\n",
      "episode: 720   score: 1.0   memory length: 137353   epsilon: 0.9260371000016057    steps: 172    lr: 0.0001     evaluation reward: 1.15\n",
      "episode: 721   score: 1.0   memory length: 137522   epsilon: 0.9257024800016129    steps: 169    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 722   score: 3.0   memory length: 137752   epsilon: 0.9252470800016228    steps: 230    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 723   score: 3.0   memory length: 138001   epsilon: 0.9247540600016335    steps: 249    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 724   score: 2.0   memory length: 138220   epsilon: 0.9243204400016429    steps: 219    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 725   score: 0.0   memory length: 138342   epsilon: 0.9240788800016482    steps: 122    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 726   score: 2.0   memory length: 138562   epsilon: 0.9236432800016576    steps: 220    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 727   score: 0.0   memory length: 138684   epsilon: 0.9234017200016629    steps: 122    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 728   score: 4.0   memory length: 138962   epsilon: 0.9228512800016748    steps: 278    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 729   score: 2.0   memory length: 139179   epsilon: 0.9224216200016842    steps: 217    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 730   score: 1.0   memory length: 139349   epsilon: 0.9220850200016915    steps: 170    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 731   score: 2.0   memory length: 139567   epsilon: 0.9216533800017008    steps: 218    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 732   score: 2.0   memory length: 139747   epsilon: 0.9212969800017086    steps: 180    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 733   score: 2.0   memory length: 139965   epsilon: 0.9208653400017179    steps: 218    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 734   score: 0.0   memory length: 140088   epsilon: 0.9206218000017232    steps: 123    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 735   score: 1.0   memory length: 140259   epsilon: 0.9202832200017306    steps: 171    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 736   score: 1.0   memory length: 140410   epsilon: 0.9199842400017371    steps: 151    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 737   score: 0.0   memory length: 140532   epsilon: 0.9197426800017423    steps: 122    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 738   score: 1.0   memory length: 140683   epsilon: 0.9194437000017488    steps: 151    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 739   score: 1.0   memory length: 140852   epsilon: 0.9191090800017561    steps: 169    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 740   score: 2.0   memory length: 141035   epsilon: 0.9187467400017639    steps: 183    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 741   score: 2.0   memory length: 141233   epsilon: 0.9183547000017724    steps: 198    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 742   score: 4.0   memory length: 141545   epsilon: 0.9177369400017859    steps: 312    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 743   score: 3.0   memory length: 141774   epsilon: 0.9172835200017957    steps: 229    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 744   score: 1.0   memory length: 141943   epsilon: 0.916948900001803    steps: 169    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 745   score: 2.0   memory length: 142141   epsilon: 0.9165568600018115    steps: 198    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 746   score: 2.0   memory length: 142338   epsilon: 0.9161668000018199    steps: 197    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 747   score: 3.0   memory length: 142584   epsilon: 0.9156797200018305    steps: 246    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 748   score: 1.0   memory length: 142735   epsilon: 0.915380740001837    steps: 151    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 749   score: 2.0   memory length: 142953   epsilon: 0.9149491000018464    steps: 218    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 750   score: 2.0   memory length: 143169   epsilon: 0.9145214200018557    steps: 216    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 751   score: 0.0   memory length: 143292   epsilon: 0.9142778800018609    steps: 123    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 752   score: 0.0   memory length: 143415   epsilon: 0.9140343400018662    steps: 123    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 753   score: 2.0   memory length: 143631   epsilon: 0.9136066600018755    steps: 216    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 754   score: 2.0   memory length: 143828   epsilon: 0.913216600001884    steps: 197    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 755   score: 1.0   memory length: 143980   epsilon: 0.9129156400018905    steps: 152    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 756   score: 1.0   memory length: 144150   epsilon: 0.9125790400018978    steps: 170    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 757   score: 3.0   memory length: 144417   epsilon: 0.9120503800019093    steps: 267    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 758   score: 4.0   memory length: 144690   epsilon: 0.911509840001921    steps: 273    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 759   score: 1.0   memory length: 144840   epsilon: 0.9112128400019275    steps: 150    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 760   score: 6.0   memory length: 145192   epsilon: 0.9105158800019426    steps: 352    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 761   score: 0.0   memory length: 145315   epsilon: 0.9102723400019479    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 762   score: 0.0   memory length: 145438   epsilon: 0.9100288000019532    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 763   score: 0.0   memory length: 145561   epsilon: 0.9097852600019585    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 764   score: 1.0   memory length: 145730   epsilon: 0.9094506400019657    steps: 169    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 765   score: 0.0   memory length: 145852   epsilon: 0.909209080001971    steps: 122    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 766   score: 2.0   memory length: 146067   epsilon: 0.9087833800019802    steps: 215    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 767   score: 0.0   memory length: 146189   epsilon: 0.9085418200019855    steps: 122    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 768   score: 2.0   memory length: 146388   epsilon: 0.908147800001994    steps: 199    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 769   score: 1.0   memory length: 146540   epsilon: 0.9078468400020006    steps: 152    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 770   score: 0.0   memory length: 146663   epsilon: 0.9076033000020058    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 771   score: 1.0   memory length: 146814   epsilon: 0.9073043200020123    steps: 151    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 772   score: 1.0   memory length: 146986   epsilon: 0.9069637600020197    steps: 172    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 773   score: 5.0   memory length: 147292   epsilon: 0.9063578800020329    steps: 306    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 774   score: 0.0   memory length: 147415   epsilon: 0.9061143400020382    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 775   score: 0.0   memory length: 147538   epsilon: 0.9058708000020435    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 776   score: 0.0   memory length: 147661   epsilon: 0.9056272600020487    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 777   score: 1.0   memory length: 147830   epsilon: 0.905292640002056    steps: 169    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 778   score: 1.0   memory length: 147980   epsilon: 0.9049956400020625    steps: 150    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 779   score: 2.0   memory length: 148198   epsilon: 0.9045640000020718    steps: 218    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 780   score: 1.0   memory length: 148367   epsilon: 0.9042293800020791    steps: 169    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 781   score: 2.0   memory length: 148585   epsilon: 0.9037977400020885    steps: 218    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 782   score: 1.0   memory length: 148754   epsilon: 0.9034631200020957    steps: 169    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 783   score: 1.0   memory length: 148906   epsilon: 0.9031621600021023    steps: 152    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 784   score: 2.0   memory length: 149105   epsilon: 0.9027681400021108    steps: 199    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 785   score: 1.0   memory length: 149256   epsilon: 0.9024691600021173    steps: 151    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 786   score: 1.0   memory length: 149406   epsilon: 0.9021721600021237    steps: 150    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 787   score: 1.0   memory length: 149576   epsilon: 0.901835560002131    steps: 170    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 788   score: 1.0   memory length: 149745   epsilon: 0.9015009400021383    steps: 169    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 789   score: 0.0   memory length: 149868   epsilon: 0.9012574000021436    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 790   score: 2.0   memory length: 150085   epsilon: 0.9008277400021529    steps: 217    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 791   score: 0.0   memory length: 150208   epsilon: 0.9005842000021582    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 792   score: 1.0   memory length: 150358   epsilon: 0.9002872000021647    steps: 150    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 793   score: 0.0   memory length: 150481   epsilon: 0.90004366000217    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 794   score: 2.0   memory length: 150679   epsilon: 0.8996516200021785    steps: 198    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 795   score: 3.0   memory length: 150906   epsilon: 0.8992021600021882    steps: 227    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 796   score: 4.0   memory length: 151201   epsilon: 0.8986180600022009    steps: 295    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 797   score: 1.0   memory length: 151369   epsilon: 0.8982854200022081    steps: 168    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 798   score: 0.0   memory length: 151492   epsilon: 0.8980418800022134    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 799   score: 1.0   memory length: 151662   epsilon: 0.8977052800022207    steps: 170    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 800   score: 1.0   memory length: 151812   epsilon: 0.8974082800022272    steps: 150    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 801   score: 1.0   memory length: 151981   epsilon: 0.8970736600022344    steps: 169    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 802   score: 0.0   memory length: 152104   epsilon: 0.8968301200022397    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 803   score: 5.0   memory length: 152431   epsilon: 0.8961826600022538    steps: 327    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 804   score: 3.0   memory length: 152699   epsilon: 0.8956520200022653    steps: 268    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 805   score: 2.0   memory length: 152897   epsilon: 0.8952599800022738    steps: 198    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 806   score: 1.0   memory length: 153067   epsilon: 0.8949233800022811    steps: 170    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 807   score: 3.0   memory length: 153333   epsilon: 0.8943967000022925    steps: 266    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 808   score: 0.0   memory length: 153455   epsilon: 0.8941551400022978    steps: 122    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 809   score: 0.0   memory length: 153578   epsilon: 0.8939116000023031    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 810   score: 1.0   memory length: 153729   epsilon: 0.8936126200023096    steps: 151    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 811   score: 2.0   memory length: 153949   epsilon: 0.893177020002319    steps: 220    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 812   score: 2.0   memory length: 154147   epsilon: 0.8927849800023275    steps: 198    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 813   score: 3.0   memory length: 154416   epsilon: 0.8922523600023391    steps: 269    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 814   score: 3.0   memory length: 154662   epsilon: 0.8917652800023497    steps: 246    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 815   score: 0.0   memory length: 154784   epsilon: 0.8915237200023549    steps: 122    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 816   score: 2.0   memory length: 154966   epsilon: 0.8911633600023627    steps: 182    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 817   score: 0.0   memory length: 155089   epsilon: 0.890919820002368    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 818   score: 3.0   memory length: 155317   epsilon: 0.8904683800023778    steps: 228    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 819   score: 3.0   memory length: 155586   epsilon: 0.8899357600023894    steps: 269    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 820   score: 2.0   memory length: 155768   epsilon: 0.8895754000023972    steps: 182    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 821   score: 4.0   memory length: 156063   epsilon: 0.8889913000024099    steps: 295    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 822   score: 3.0   memory length: 156309   epsilon: 0.8885042200024205    steps: 246    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 823   score: 3.0   memory length: 156554   epsilon: 0.888019120002431    steps: 245    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 824   score: 2.0   memory length: 156753   epsilon: 0.8876251000024395    steps: 199    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 825   score: 3.0   memory length: 157023   epsilon: 0.8870905000024512    steps: 270    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 826   score: 2.0   memory length: 157221   epsilon: 0.8866984600024597    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 827   score: 1.0   memory length: 157390   epsilon: 0.8863638400024669    steps: 169    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 828   score: 2.0   memory length: 157588   epsilon: 0.8859718000024754    steps: 198    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 829   score: 3.0   memory length: 157834   epsilon: 0.885484720002486    steps: 246    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 830   score: 1.0   memory length: 158003   epsilon: 0.8851501000024933    steps: 169    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 831   score: 1.0   memory length: 158153   epsilon: 0.8848531000024997    steps: 150    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 832   score: 1.0   memory length: 158304   epsilon: 0.8845541200025062    steps: 151    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 833   score: 0.0   memory length: 158427   epsilon: 0.8843105800025115    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 834   score: 1.0   memory length: 158599   epsilon: 0.8839700200025189    steps: 172    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 835   score: 3.0   memory length: 158864   epsilon: 0.8834453200025303    steps: 265    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 836   score: 2.0   memory length: 159046   epsilon: 0.8830849600025381    steps: 182    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 837   score: 1.0   memory length: 159218   epsilon: 0.8827444000025455    steps: 172    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 838   score: 0.0   memory length: 159341   epsilon: 0.8825008600025508    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 839   score: 2.0   memory length: 159539   epsilon: 0.8821088200025593    steps: 198    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 840   score: 1.0   memory length: 159711   epsilon: 0.8817682600025667    steps: 172    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 841   score: 2.0   memory length: 159909   epsilon: 0.8813762200025752    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 842   score: 0.0   memory length: 160032   epsilon: 0.8811326800025805    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 843   score: 0.0   memory length: 160155   epsilon: 0.8808891400025858    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 844   score: 3.0   memory length: 160403   epsilon: 0.8803981000025964    steps: 248    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 845   score: 5.0   memory length: 160738   epsilon: 0.8797348000026108    steps: 335    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 846   score: 2.0   memory length: 160936   epsilon: 0.8793427600026194    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 847   score: 1.0   memory length: 161105   epsilon: 0.8790081400026266    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 848   score: 2.0   memory length: 161303   epsilon: 0.8786161000026351    steps: 198    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 849   score: 2.0   memory length: 161525   epsilon: 0.8781765400026447    steps: 222    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 850   score: 1.0   memory length: 161696   epsilon: 0.877837960002652    steps: 171    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 851   score: 1.0   memory length: 161866   epsilon: 0.8775013600026593    steps: 170    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 852   score: 2.0   memory length: 162066   epsilon: 0.8771053600026679    steps: 200    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 853   score: 1.0   memory length: 162234   epsilon: 0.8767727200026751    steps: 168    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 854   score: 2.0   memory length: 162451   epsilon: 0.8763430600026845    steps: 217    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 855   score: 1.0   memory length: 162620   epsilon: 0.8760084400026917    steps: 169    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 856   score: 0.0   memory length: 162743   epsilon: 0.875764900002697    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 857   score: 2.0   memory length: 162961   epsilon: 0.8753332600027064    steps: 218    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 858   score: 0.0   memory length: 163083   epsilon: 0.8750917000027116    steps: 122    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 859   score: 2.0   memory length: 163300   epsilon: 0.874662040002721    steps: 217    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 860   score: 1.0   memory length: 163450   epsilon: 0.8743650400027274    steps: 150    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 861   score: 2.0   memory length: 163667   epsilon: 0.8739353800027367    steps: 217    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 862   score: 1.0   memory length: 163819   epsilon: 0.8736344200027433    steps: 152    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 863   score: 0.0   memory length: 163942   epsilon: 0.8733908800027486    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 864   score: 0.0   memory length: 164065   epsilon: 0.8731473400027538    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 865   score: 3.0   memory length: 164332   epsilon: 0.8726186800027653    steps: 267    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 866   score: 1.0   memory length: 164504   epsilon: 0.8722781200027727    steps: 172    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 867   score: 2.0   memory length: 164701   epsilon: 0.8718880600027812    steps: 197    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 868   score: 1.0   memory length: 164851   epsilon: 0.8715910600027876    steps: 150    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 869   score: 1.0   memory length: 165020   epsilon: 0.8712564400027949    steps: 169    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 870   score: 2.0   memory length: 165237   epsilon: 0.8708267800028042    steps: 217    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 871   score: 2.0   memory length: 165417   epsilon: 0.870470380002812    steps: 180    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 872   score: 2.0   memory length: 165617   epsilon: 0.8700743800028206    steps: 200    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 873   score: 9.0   memory length: 166126   epsilon: 0.8690665600028424    steps: 509    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 874   score: 0.0   memory length: 166249   epsilon: 0.8688230200028477    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 875   score: 2.0   memory length: 166467   epsilon: 0.8683913800028571    steps: 218    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 876   score: 2.0   memory length: 166683   epsilon: 0.8679637000028664    steps: 216    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 877   score: 0.0   memory length: 166806   epsilon: 0.8677201600028717    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 878   score: 1.0   memory length: 166975   epsilon: 0.8673855400028789    steps: 169    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 879   score: 1.0   memory length: 167146   epsilon: 0.8670469600028863    steps: 171    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 880   score: 1.0   memory length: 167298   epsilon: 0.8667460000028928    steps: 152    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 881   score: 0.0   memory length: 167421   epsilon: 0.8665024600028981    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 882   score: 3.0   memory length: 167687   epsilon: 0.8659757800029095    steps: 266    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 883   score: 0.0   memory length: 167809   epsilon: 0.8657342200029148    steps: 122    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 884   score: 1.0   memory length: 167978   epsilon: 0.865399600002922    steps: 169    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 885   score: 0.0   memory length: 168101   epsilon: 0.8651560600029273    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 886   score: 1.0   memory length: 168270   epsilon: 0.8648214400029346    steps: 169    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 887   score: 0.0   memory length: 168393   epsilon: 0.8645779000029399    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 888   score: 0.0   memory length: 168516   epsilon: 0.8643343600029452    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 889   score: 3.0   memory length: 168763   epsilon: 0.8638453000029558    steps: 247    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 890   score: 2.0   memory length: 168979   epsilon: 0.8634176200029651    steps: 216    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 891   score: 2.0   memory length: 169177   epsilon: 0.8630255800029736    steps: 198    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 892   score: 3.0   memory length: 169423   epsilon: 0.8625385000029842    steps: 246    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 893   score: 0.0   memory length: 169545   epsilon: 0.8622969400029894    steps: 122    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 894   score: 0.0   memory length: 169668   epsilon: 0.8620534000029947    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 895   score: 3.0   memory length: 169915   epsilon: 0.8615643400030053    steps: 247    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 896   score: 1.0   memory length: 170087   epsilon: 0.8612237800030127    steps: 172    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 897   score: 4.0   memory length: 170384   epsilon: 0.8606357200030255    steps: 297    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 898   score: 0.0   memory length: 170507   epsilon: 0.8603921800030307    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 899   score: 2.0   memory length: 170705   epsilon: 0.8600001400030393    steps: 198    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 900   score: 2.0   memory length: 170903   epsilon: 0.8596081000030478    steps: 198    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 901   score: 0.0   memory length: 171026   epsilon: 0.8593645600030531    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 902   score: 4.0   memory length: 171286   epsilon: 0.8588497600030642    steps: 260    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 903   score: 0.0   memory length: 171409   epsilon: 0.8586062200030695    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 904   score: 0.0   memory length: 171531   epsilon: 0.8583646600030748    steps: 122    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 905   score: 1.0   memory length: 171700   epsilon: 0.858030040003082    steps: 169    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 906   score: 2.0   memory length: 171899   epsilon: 0.8576360200030906    steps: 199    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 907   score: 0.0   memory length: 172022   epsilon: 0.8573924800030959    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 908   score: 1.0   memory length: 172173   epsilon: 0.8570935000031024    steps: 151    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 909   score: 1.0   memory length: 172324   epsilon: 0.8567945200031089    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 910   score: 0.0   memory length: 172447   epsilon: 0.8565509800031141    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 911   score: 2.0   memory length: 172627   epsilon: 0.8561945800031219    steps: 180    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 912   score: 7.0   memory length: 173017   epsilon: 0.8554223800031386    steps: 390    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 913   score: 2.0   memory length: 173198   epsilon: 0.8550640000031464    steps: 181    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 914   score: 2.0   memory length: 173395   epsilon: 0.8546739400031549    steps: 197    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 915   score: 3.0   memory length: 173642   epsilon: 0.8541848800031655    steps: 247    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 916   score: 0.0   memory length: 173765   epsilon: 0.8539413400031708    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 917   score: 2.0   memory length: 173982   epsilon: 0.8535116800031801    steps: 217    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 918   score: 2.0   memory length: 174200   epsilon: 0.8530800400031895    steps: 218    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 919   score: 0.0   memory length: 174322   epsilon: 0.8528384800031947    steps: 122    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 920   score: 3.0   memory length: 174551   epsilon: 0.8523850600032046    steps: 229    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 921   score: 4.0   memory length: 174808   epsilon: 0.8518762000032156    steps: 257    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 922   score: 2.0   memory length: 175006   epsilon: 0.8514841600032241    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 923   score: 3.0   memory length: 175252   epsilon: 0.8509970800032347    steps: 246    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 924   score: 3.0   memory length: 175501   epsilon: 0.8505040600032454    steps: 249    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 925   score: 2.0   memory length: 175699   epsilon: 0.8501120200032539    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 926   score: 1.0   memory length: 175850   epsilon: 0.8498130400032604    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 927   score: 2.0   memory length: 176049   epsilon: 0.849419020003269    steps: 199    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 928   score: 2.0   memory length: 176249   epsilon: 0.8490230200032776    steps: 200    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 929   score: 0.0   memory length: 176372   epsilon: 0.8487794800032828    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 930   score: 2.0   memory length: 176592   epsilon: 0.8483438800032923    steps: 220    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 931   score: 1.0   memory length: 176760   epsilon: 0.8480112400032995    steps: 168    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 932   score: 2.0   memory length: 176976   epsilon: 0.8475835600033088    steps: 216    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 933   score: 3.0   memory length: 177223   epsilon: 0.8470945000033194    steps: 247    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 934   score: 3.0   memory length: 177470   epsilon: 0.84660544000333    steps: 247    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 935   score: 2.0   memory length: 177668   epsilon: 0.8462134000033386    steps: 198    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 936   score: 2.0   memory length: 177890   epsilon: 0.8457738400033481    steps: 222    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 937   score: 0.0   memory length: 178013   epsilon: 0.8455303000033534    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 938   score: 2.0   memory length: 178211   epsilon: 0.8451382600033619    steps: 198    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 939   score: 1.0   memory length: 178380   epsilon: 0.8448036400033692    steps: 169    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 940   score: 4.0   memory length: 178694   epsilon: 0.8441819200033827    steps: 314    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 941   score: 1.0   memory length: 178863   epsilon: 0.8438473000033899    steps: 169    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 942   score: 1.0   memory length: 179014   epsilon: 0.8435483200033964    steps: 151    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 943   score: 2.0   memory length: 179212   epsilon: 0.8431562800034049    steps: 198    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 944   score: 2.0   memory length: 179393   epsilon: 0.8427979000034127    steps: 181    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 945   score: 1.0   memory length: 179561   epsilon: 0.8424652600034199    steps: 168    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 946   score: 3.0   memory length: 179808   epsilon: 0.8419762000034305    steps: 247    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 947   score: 2.0   memory length: 180025   epsilon: 0.8415465400034399    steps: 217    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 948   score: 1.0   memory length: 180194   epsilon: 0.8412119200034471    steps: 169    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 949   score: 2.0   memory length: 180393   epsilon: 0.8408179000034557    steps: 199    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 950   score: 2.0   memory length: 180590   epsilon: 0.8404278400034642    steps: 197    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 951   score: 1.0   memory length: 180741   epsilon: 0.8401288600034706    steps: 151    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 952   score: 3.0   memory length: 180988   epsilon: 0.8396398000034813    steps: 247    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 953   score: 5.0   memory length: 181331   epsilon: 0.838960660003496    steps: 343    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 954   score: 4.0   memory length: 181625   epsilon: 0.8383785400035086    steps: 294    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 955   score: 4.0   memory length: 181922   epsilon: 0.8377904800035214    steps: 297    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 956   score: 3.0   memory length: 182148   epsilon: 0.8373430000035311    steps: 226    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 957   score: 2.0   memory length: 182346   epsilon: 0.8369509600035396    steps: 198    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 958   score: 1.0   memory length: 182515   epsilon: 0.8366163400035469    steps: 169    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 959   score: 3.0   memory length: 182782   epsilon: 0.8360876800035584    steps: 267    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 960   score: 0.0   memory length: 182905   epsilon: 0.8358441400035637    steps: 123    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 961   score: 1.0   memory length: 183056   epsilon: 0.8355451600035702    steps: 151    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 962   score: 0.0   memory length: 183179   epsilon: 0.8353016200035754    steps: 123    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 963   score: 2.0   memory length: 183396   epsilon: 0.8348719600035848    steps: 217    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 964   score: 0.0   memory length: 183519   epsilon: 0.83462842000359    steps: 123    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 965   score: 2.0   memory length: 183740   epsilon: 0.8341908400035996    steps: 221    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 966   score: 1.0   memory length: 183912   epsilon: 0.833850280003607    steps: 172    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 967   score: 1.0   memory length: 184083   epsilon: 0.8335117000036143    steps: 171    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 968   score: 6.0   memory length: 184439   epsilon: 0.8328068200036296    steps: 356    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 969   score: 4.0   memory length: 184733   epsilon: 0.8322247000036422    steps: 294    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 970   score: 1.0   memory length: 184884   epsilon: 0.8319257200036487    steps: 151    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 971   score: 4.0   memory length: 185139   epsilon: 0.8314208200036597    steps: 255    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 972   score: 0.0   memory length: 185262   epsilon: 0.831177280003665    steps: 123    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 973   score: 1.0   memory length: 185413   epsilon: 0.8308783000036715    steps: 151    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 974   score: 4.0   memory length: 185709   epsilon: 0.8302922200036842    steps: 296    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 975   score: 2.0   memory length: 185929   epsilon: 0.8298566200036936    steps: 220    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 976   score: 2.0   memory length: 186129   epsilon: 0.8294606200037022    steps: 200    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 977   score: 2.0   memory length: 186327   epsilon: 0.8290685800037108    steps: 198    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 978   score: 2.0   memory length: 186547   epsilon: 0.8286329800037202    steps: 220    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 979   score: 0.0   memory length: 186670   epsilon: 0.8283894400037255    steps: 123    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 980   score: 1.0   memory length: 186821   epsilon: 0.828090460003732    steps: 151    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 981   score: 3.0   memory length: 187065   epsilon: 0.8276073400037425    steps: 244    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 982   score: 3.0   memory length: 187311   epsilon: 0.827120260003753    steps: 246    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 983   score: 1.0   memory length: 187462   epsilon: 0.8268212800037595    steps: 151    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 984   score: 5.0   memory length: 187800   epsilon: 0.8261520400037741    steps: 338    lr: 0.0001     evaluation reward: 1.87\n",
      "episode: 985   score: 3.0   memory length: 188048   epsilon: 0.8256610000037847    steps: 248    lr: 0.0001     evaluation reward: 1.9\n",
      "episode: 986   score: 3.0   memory length: 188294   epsilon: 0.8251739200037953    steps: 246    lr: 0.0001     evaluation reward: 1.92\n",
      "episode: 987   score: 0.0   memory length: 188417   epsilon: 0.8249303800038006    steps: 123    lr: 0.0001     evaluation reward: 1.92\n",
      "episode: 988   score: 0.0   memory length: 188540   epsilon: 0.8246868400038059    steps: 123    lr: 0.0001     evaluation reward: 1.92\n",
      "episode: 989   score: 0.0   memory length: 188663   epsilon: 0.8244433000038112    steps: 123    lr: 0.0001     evaluation reward: 1.89\n",
      "episode: 990   score: 3.0   memory length: 188930   epsilon: 0.8239146400038226    steps: 267    lr: 0.0001     evaluation reward: 1.9\n",
      "episode: 991   score: 3.0   memory length: 189177   epsilon: 0.8234255800038333    steps: 247    lr: 0.0001     evaluation reward: 1.91\n",
      "episode: 992   score: 3.0   memory length: 189423   epsilon: 0.8229385000038438    steps: 246    lr: 0.0001     evaluation reward: 1.91\n",
      "episode: 993   score: 2.0   memory length: 189641   epsilon: 0.8225068600038532    steps: 218    lr: 0.0001     evaluation reward: 1.93\n",
      "episode: 994   score: 5.0   memory length: 189969   epsilon: 0.8218574200038673    steps: 328    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 995   score: 1.0   memory length: 190119   epsilon: 0.8215604200038737    steps: 150    lr: 0.0001     evaluation reward: 1.96\n",
      "episode: 996   score: 4.0   memory length: 190395   epsilon: 0.8210139400038856    steps: 276    lr: 0.0001     evaluation reward: 1.99\n",
      "episode: 997   score: 1.0   memory length: 190564   epsilon: 0.8206793200038929    steps: 169    lr: 0.0001     evaluation reward: 1.96\n",
      "episode: 998   score: 1.0   memory length: 190734   epsilon: 0.8203427200039002    steps: 170    lr: 0.0001     evaluation reward: 1.97\n",
      "episode: 999   score: 3.0   memory length: 190960   epsilon: 0.8198952400039099    steps: 226    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 1000   score: 2.0   memory length: 191157   epsilon: 0.8195051800039184    steps: 197    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 1001   score: 0.0   memory length: 191279   epsilon: 0.8192636200039236    steps: 122    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 1002   score: 2.0   memory length: 191477   epsilon: 0.8188715800039321    steps: 198    lr: 0.0001     evaluation reward: 1.96\n",
      "episode: 1003   score: 0.0   memory length: 191600   epsilon: 0.8186280400039374    steps: 123    lr: 0.0001     evaluation reward: 1.96\n",
      "episode: 1004   score: 1.0   memory length: 191771   epsilon: 0.8182894600039448    steps: 171    lr: 0.0001     evaluation reward: 1.97\n",
      "episode: 1005   score: 2.0   memory length: 191972   epsilon: 0.8178914800039534    steps: 201    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 1006   score: 2.0   memory length: 192152   epsilon: 0.8175350800039611    steps: 180    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 1007   score: 3.0   memory length: 192401   epsilon: 0.8170420600039718    steps: 249    lr: 0.0001     evaluation reward: 2.01\n",
      "episode: 1008   score: 1.0   memory length: 192551   epsilon: 0.8167450600039783    steps: 150    lr: 0.0001     evaluation reward: 2.01\n",
      "episode: 1009   score: 2.0   memory length: 192749   epsilon: 0.8163530200039868    steps: 198    lr: 0.0001     evaluation reward: 2.02\n",
      "episode: 1010   score: 0.0   memory length: 192871   epsilon: 0.816111460003992    steps: 122    lr: 0.0001     evaluation reward: 2.02\n",
      "episode: 1011   score: 2.0   memory length: 193087   epsilon: 0.8156837800040013    steps: 216    lr: 0.0001     evaluation reward: 2.02\n",
      "episode: 1012   score: 1.0   memory length: 193238   epsilon: 0.8153848000040078    steps: 151    lr: 0.0001     evaluation reward: 1.96\n",
      "episode: 1013   score: 1.0   memory length: 193389   epsilon: 0.8150858200040143    steps: 151    lr: 0.0001     evaluation reward: 1.95\n",
      "episode: 1014   score: 3.0   memory length: 193637   epsilon: 0.814594780004025    steps: 248    lr: 0.0001     evaluation reward: 1.96\n",
      "episode: 1015   score: 0.0   memory length: 193760   epsilon: 0.8143512400040303    steps: 123    lr: 0.0001     evaluation reward: 1.93\n",
      "episode: 1016   score: 2.0   memory length: 193976   epsilon: 0.8139235600040395    steps: 216    lr: 0.0001     evaluation reward: 1.95\n",
      "episode: 1017   score: 1.0   memory length: 194127   epsilon: 0.813624580004046    steps: 151    lr: 0.0001     evaluation reward: 1.94\n",
      "episode: 1018   score: 2.0   memory length: 194306   epsilon: 0.8132701600040537    steps: 179    lr: 0.0001     evaluation reward: 1.94\n",
      "episode: 1019   score: 2.0   memory length: 194504   epsilon: 0.8128781200040622    steps: 198    lr: 0.0001     evaluation reward: 1.96\n",
      "episode: 1020   score: 2.0   memory length: 194705   epsilon: 0.8124801400040709    steps: 201    lr: 0.0001     evaluation reward: 1.95\n",
      "episode: 1021   score: 0.0   memory length: 194828   epsilon: 0.8122366000040762    steps: 123    lr: 0.0001     evaluation reward: 1.91\n",
      "episode: 1022   score: 2.0   memory length: 195046   epsilon: 0.8118049600040855    steps: 218    lr: 0.0001     evaluation reward: 1.91\n",
      "episode: 1023   score: 1.0   memory length: 195215   epsilon: 0.8114703400040928    steps: 169    lr: 0.0001     evaluation reward: 1.89\n",
      "episode: 1024   score: 4.0   memory length: 195490   epsilon: 0.8109258400041046    steps: 275    lr: 0.0001     evaluation reward: 1.9\n",
      "episode: 1025   score: 3.0   memory length: 195736   epsilon: 0.8104387600041152    steps: 246    lr: 0.0001     evaluation reward: 1.91\n",
      "episode: 1026   score: 2.0   memory length: 195954   epsilon: 0.8100071200041246    steps: 218    lr: 0.0001     evaluation reward: 1.92\n",
      "episode: 1027   score: 3.0   memory length: 196182   epsilon: 0.8095556800041344    steps: 228    lr: 0.0001     evaluation reward: 1.93\n",
      "episode: 1028   score: 3.0   memory length: 196408   epsilon: 0.8091082000041441    steps: 226    lr: 0.0001     evaluation reward: 1.94\n",
      "episode: 1029   score: 1.0   memory length: 196578   epsilon: 0.8087716000041514    steps: 170    lr: 0.0001     evaluation reward: 1.95\n",
      "episode: 1030   score: 0.0   memory length: 196701   epsilon: 0.8085280600041567    steps: 123    lr: 0.0001     evaluation reward: 1.93\n",
      "episode: 1031   score: 0.0   memory length: 196824   epsilon: 0.808284520004162    steps: 123    lr: 0.0001     evaluation reward: 1.92\n",
      "episode: 1032   score: 3.0   memory length: 197089   epsilon: 0.8077598200041733    steps: 265    lr: 0.0001     evaluation reward: 1.93\n",
      "episode: 1033   score: 0.0   memory length: 197212   epsilon: 0.8075162800041786    steps: 123    lr: 0.0001     evaluation reward: 1.9\n",
      "episode: 1034   score: 1.0   memory length: 197362   epsilon: 0.8072192800041851    steps: 150    lr: 0.0001     evaluation reward: 1.88\n",
      "episode: 1035   score: 1.0   memory length: 197531   epsilon: 0.8068846600041923    steps: 169    lr: 0.0001     evaluation reward: 1.87\n",
      "episode: 1036   score: 2.0   memory length: 197749   epsilon: 0.8064530200042017    steps: 218    lr: 0.0001     evaluation reward: 1.87\n",
      "episode: 1037   score: 1.0   memory length: 197900   epsilon: 0.8061540400042082    steps: 151    lr: 0.0001     evaluation reward: 1.88\n",
      "episode: 1038   score: 3.0   memory length: 198145   epsilon: 0.8056689400042187    steps: 245    lr: 0.0001     evaluation reward: 1.89\n",
      "episode: 1039   score: 1.0   memory length: 198298   epsilon: 0.8053660000042253    steps: 153    lr: 0.0001     evaluation reward: 1.89\n",
      "episode: 1040   score: 0.0   memory length: 198420   epsilon: 0.8051244400042306    steps: 122    lr: 0.0001     evaluation reward: 1.85\n",
      "episode: 1041   score: 1.0   memory length: 198592   epsilon: 0.804783880004238    steps: 172    lr: 0.0001     evaluation reward: 1.85\n",
      "episode: 1042   score: 0.0   memory length: 198715   epsilon: 0.8045403400042432    steps: 123    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 1043   score: 2.0   memory length: 198913   epsilon: 0.8041483000042517    steps: 198    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 1044   score: 3.0   memory length: 199157   epsilon: 0.8036651800042622    steps: 244    lr: 0.0001     evaluation reward: 1.85\n",
      "episode: 1045   score: 1.0   memory length: 199308   epsilon: 0.8033662000042687    steps: 151    lr: 0.0001     evaluation reward: 1.85\n",
      "episode: 1046   score: 2.0   memory length: 199505   epsilon: 0.8029761400042772    steps: 197    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 1047   score: 1.0   memory length: 199677   epsilon: 0.8026355800042846    steps: 172    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 1048   score: 1.0   memory length: 199827   epsilon: 0.802338580004291    steps: 150    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 1049   score: 2.0   memory length: 200025   epsilon: 0.8019465400042995    steps: 198    lr: 4e-05     evaluation reward: 1.83\n",
      "episode: 1050   score: 3.0   memory length: 200251   epsilon: 0.8014990600043093    steps: 226    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 1051   score: 0.0   memory length: 200374   epsilon: 0.8012555200043145    steps: 123    lr: 4e-05     evaluation reward: 1.83\n",
      "episode: 1052   score: 2.0   memory length: 200572   epsilon: 0.8008634800043231    steps: 198    lr: 4e-05     evaluation reward: 1.82\n",
      "episode: 1053   score: 3.0   memory length: 200817   epsilon: 0.8003783800043336    steps: 245    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 1054   score: 2.0   memory length: 201015   epsilon: 0.7999863400043421    steps: 198    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 1055   score: 2.0   memory length: 201213   epsilon: 0.7995943000043506    steps: 198    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 1056   score: 3.0   memory length: 201439   epsilon: 0.7991468200043603    steps: 226    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 1057   score: 0.0   memory length: 201562   epsilon: 0.7989032800043656    steps: 123    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 1058   score: 2.0   memory length: 201760   epsilon: 0.7985112400043741    steps: 198    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 1059   score: 3.0   memory length: 202005   epsilon: 0.7980261400043847    steps: 245    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 1060   score: 3.0   memory length: 202275   epsilon: 0.7974915400043963    steps: 270    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 1061   score: 3.0   memory length: 202520   epsilon: 0.7970064400044068    steps: 245    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 1062   score: 3.0   memory length: 202746   epsilon: 0.7965589600044165    steps: 226    lr: 4e-05     evaluation reward: 1.83\n",
      "episode: 1063   score: 3.0   memory length: 202993   epsilon: 0.7960699000044271    steps: 247    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 1064   score: 2.0   memory length: 203211   epsilon: 0.7956382600044365    steps: 218    lr: 4e-05     evaluation reward: 1.86\n",
      "episode: 1065   score: 0.0   memory length: 203334   epsilon: 0.7953947200044418    steps: 123    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 1066   score: 2.0   memory length: 203552   epsilon: 0.7949630800044512    steps: 218    lr: 4e-05     evaluation reward: 1.85\n",
      "episode: 1067   score: 3.0   memory length: 203800   epsilon: 0.7944720400044618    steps: 248    lr: 4e-05     evaluation reward: 1.87\n",
      "episode: 1068   score: 1.0   memory length: 203951   epsilon: 0.7941730600044683    steps: 151    lr: 4e-05     evaluation reward: 1.82\n",
      "episode: 1069   score: 4.0   memory length: 204246   epsilon: 0.793588960004481    steps: 295    lr: 4e-05     evaluation reward: 1.82\n",
      "episode: 1070   score: 0.0   memory length: 204368   epsilon: 0.7933474000044862    steps: 122    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 1071   score: 1.0   memory length: 204519   epsilon: 0.7930484200044927    steps: 151    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 1072   score: 1.0   memory length: 204687   epsilon: 0.7927157800044999    steps: 168    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1073   score: 4.0   memory length: 204941   epsilon: 0.7922128600045109    steps: 254    lr: 4e-05     evaluation reward: 1.82\n",
      "episode: 1074   score: 1.0   memory length: 205110   epsilon: 0.7918782400045181    steps: 169    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1075   score: 2.0   memory length: 205326   epsilon: 0.7914505600045274    steps: 216    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1076   score: 2.0   memory length: 205524   epsilon: 0.7910585200045359    steps: 198    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1077   score: 0.0   memory length: 205647   epsilon: 0.7908149800045412    steps: 123    lr: 4e-05     evaluation reward: 1.77\n",
      "episode: 1078   score: 2.0   memory length: 205845   epsilon: 0.7904229400045497    steps: 198    lr: 4e-05     evaluation reward: 1.77\n",
      "episode: 1079   score: 2.0   memory length: 206045   epsilon: 0.7900269400045583    steps: 200    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1080   score: 1.0   memory length: 206195   epsilon: 0.7897299400045648    steps: 150    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1081   score: 0.0   memory length: 206318   epsilon: 0.78948640000457    steps: 123    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 1082   score: 3.0   memory length: 206543   epsilon: 0.7890409000045797    steps: 225    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 1083   score: 1.0   memory length: 206694   epsilon: 0.7887419200045862    steps: 151    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 1084   score: 1.0   memory length: 206865   epsilon: 0.7884033400045936    steps: 171    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 1085   score: 2.0   memory length: 207063   epsilon: 0.7880113000046021    steps: 198    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 1086   score: 3.0   memory length: 207309   epsilon: 0.7875242200046126    steps: 246    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 1087   score: 4.0   memory length: 207586   epsilon: 0.7869757600046245    steps: 277    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 1088   score: 4.0   memory length: 207885   epsilon: 0.7863837400046374    steps: 299    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1089   score: 2.0   memory length: 208104   epsilon: 0.7859501200046468    steps: 219    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 1090   score: 3.0   memory length: 208335   epsilon: 0.7854927400046567    steps: 231    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 1091   score: 2.0   memory length: 208533   epsilon: 0.7851007000046653    steps: 198    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 1092   score: 3.0   memory length: 208759   epsilon: 0.784653220004675    steps: 226    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 1093   score: 1.0   memory length: 208928   epsilon: 0.7843186000046822    steps: 169    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1094   score: 1.0   memory length: 209079   epsilon: 0.7840196200046887    steps: 151    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 1095   score: 2.0   memory length: 209276   epsilon: 0.7836295600046972    steps: 197    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 1096   score: 1.0   memory length: 209447   epsilon: 0.7832909800047045    steps: 171    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 1097   score: 4.0   memory length: 209743   epsilon: 0.7827049000047173    steps: 296    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 1098   score: 6.0   memory length: 210103   epsilon: 0.7819921000047327    steps: 360    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 1099   score: 4.0   memory length: 210375   epsilon: 0.7814535400047444    steps: 272    lr: 4e-05     evaluation reward: 1.82\n",
      "episode: 1100   score: 2.0   memory length: 210594   epsilon: 0.7810199200047538    steps: 219    lr: 4e-05     evaluation reward: 1.82\n",
      "episode: 1101   score: 2.0   memory length: 210792   epsilon: 0.7806278800047624    steps: 198    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 1102   score: 3.0   memory length: 211044   epsilon: 0.7801289200047732    steps: 252    lr: 4e-05     evaluation reward: 1.85\n",
      "episode: 1103   score: 0.0   memory length: 211167   epsilon: 0.7798853800047785    steps: 123    lr: 4e-05     evaluation reward: 1.85\n",
      "episode: 1104   score: 3.0   memory length: 211413   epsilon: 0.779398300004789    steps: 246    lr: 4e-05     evaluation reward: 1.87\n",
      "episode: 1105   score: 0.0   memory length: 211536   epsilon: 0.7791547600047943    steps: 123    lr: 4e-05     evaluation reward: 1.85\n",
      "episode: 1106   score: 6.0   memory length: 211890   epsilon: 0.7784538400048095    steps: 354    lr: 4e-05     evaluation reward: 1.89\n",
      "episode: 1107   score: 4.0   memory length: 212186   epsilon: 0.7778677600048223    steps: 296    lr: 4e-05     evaluation reward: 1.9\n",
      "episode: 1108   score: 4.0   memory length: 212429   epsilon: 0.7773866200048327    steps: 243    lr: 4e-05     evaluation reward: 1.93\n",
      "episode: 1109   score: 6.0   memory length: 212823   epsilon: 0.7766065000048497    steps: 394    lr: 4e-05     evaluation reward: 1.97\n",
      "episode: 1110   score: 6.0   memory length: 213137   epsilon: 0.7759847800048632    steps: 314    lr: 4e-05     evaluation reward: 2.03\n",
      "episode: 1111   score: 0.0   memory length: 213260   epsilon: 0.7757412400048684    steps: 123    lr: 4e-05     evaluation reward: 2.01\n",
      "episode: 1112   score: 0.0   memory length: 213383   epsilon: 0.7754977000048737    steps: 123    lr: 4e-05     evaluation reward: 2.0\n",
      "episode: 1113   score: 0.0   memory length: 213505   epsilon: 0.775256140004879    steps: 122    lr: 4e-05     evaluation reward: 1.99\n",
      "episode: 1114   score: 2.0   memory length: 213687   epsilon: 0.7748957800048868    steps: 182    lr: 4e-05     evaluation reward: 1.98\n",
      "episode: 1115   score: 2.0   memory length: 213885   epsilon: 0.7745037400048953    steps: 198    lr: 4e-05     evaluation reward: 2.0\n",
      "episode: 1116   score: 3.0   memory length: 214111   epsilon: 0.774056260004905    steps: 226    lr: 4e-05     evaluation reward: 2.01\n",
      "episode: 1117   score: 3.0   memory length: 214337   epsilon: 0.7736087800049147    steps: 226    lr: 4e-05     evaluation reward: 2.03\n",
      "episode: 1118   score: 5.0   memory length: 214683   epsilon: 0.7729237000049296    steps: 346    lr: 4e-05     evaluation reward: 2.06\n",
      "episode: 1119   score: 1.0   memory length: 214834   epsilon: 0.7726247200049361    steps: 151    lr: 4e-05     evaluation reward: 2.05\n",
      "episode: 1120   score: 3.0   memory length: 215081   epsilon: 0.7721356600049467    steps: 247    lr: 4e-05     evaluation reward: 2.06\n",
      "episode: 1121   score: 0.0   memory length: 215204   epsilon: 0.771892120004952    steps: 123    lr: 4e-05     evaluation reward: 2.06\n",
      "episode: 1122   score: 3.0   memory length: 215430   epsilon: 0.7714446400049617    steps: 226    lr: 4e-05     evaluation reward: 2.07\n",
      "episode: 1123   score: 2.0   memory length: 215648   epsilon: 0.7710130000049711    steps: 218    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 1124   score: 0.0   memory length: 215771   epsilon: 0.7707694600049764    steps: 123    lr: 4e-05     evaluation reward: 2.04\n",
      "episode: 1125   score: 5.0   memory length: 216136   epsilon: 0.7700467600049921    steps: 365    lr: 4e-05     evaluation reward: 2.06\n",
      "episode: 1126   score: 3.0   memory length: 216361   epsilon: 0.7696012600050017    steps: 225    lr: 4e-05     evaluation reward: 2.07\n",
      "episode: 1127   score: 0.0   memory length: 216483   epsilon: 0.769359700005007    steps: 122    lr: 4e-05     evaluation reward: 2.04\n",
      "episode: 1128   score: 3.0   memory length: 216750   epsilon: 0.7688310400050185    steps: 267    lr: 4e-05     evaluation reward: 2.04\n",
      "episode: 1129   score: 2.0   memory length: 216968   epsilon: 0.7683994000050278    steps: 218    lr: 4e-05     evaluation reward: 2.05\n",
      "episode: 1130   score: 4.0   memory length: 217245   epsilon: 0.7678509400050397    steps: 277    lr: 4e-05     evaluation reward: 2.09\n",
      "episode: 1131   score: 2.0   memory length: 217463   epsilon: 0.7674193000050491    steps: 218    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 1132   score: 4.0   memory length: 217757   epsilon: 0.7668371800050617    steps: 294    lr: 4e-05     evaluation reward: 2.12\n",
      "episode: 1133   score: 3.0   memory length: 217982   epsilon: 0.7663916800050714    steps: 225    lr: 4e-05     evaluation reward: 2.15\n",
      "episode: 1134   score: 3.0   memory length: 218230   epsilon: 0.7659006400050821    steps: 248    lr: 4e-05     evaluation reward: 2.17\n",
      "episode: 1135   score: 3.0   memory length: 218478   epsilon: 0.7654096000050927    steps: 248    lr: 4e-05     evaluation reward: 2.19\n",
      "episode: 1136   score: 2.0   memory length: 218678   epsilon: 0.7650136000051013    steps: 200    lr: 4e-05     evaluation reward: 2.19\n",
      "episode: 1137   score: 4.0   memory length: 218956   epsilon: 0.7644631600051133    steps: 278    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1138   score: 3.0   memory length: 219202   epsilon: 0.7639760800051238    steps: 246    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1139   score: 3.0   memory length: 219447   epsilon: 0.7634909800051344    steps: 245    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 1140   score: 2.0   memory length: 219645   epsilon: 0.7630989400051429    steps: 198    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 1141   score: 0.0   memory length: 219768   epsilon: 0.7628554000051482    steps: 123    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 1142   score: 0.0   memory length: 219890   epsilon: 0.7626138400051534    steps: 122    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 1143   score: 1.0   memory length: 220060   epsilon: 0.7622772400051607    steps: 170    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 1144   score: 3.0   memory length: 220306   epsilon: 0.7617901600051713    steps: 246    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 1145   score: 4.0   memory length: 220585   epsilon: 0.7612377400051833    steps: 279    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1146   score: 3.0   memory length: 220811   epsilon: 0.760790260005193    steps: 226    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1147   score: 0.0   memory length: 220934   epsilon: 0.7605467200051983    steps: 123    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1148   score: 3.0   memory length: 221144   epsilon: 0.7601309200052073    steps: 210    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1149   score: 2.0   memory length: 221342   epsilon: 0.7597388800052158    steps: 198    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1150   score: 1.0   memory length: 221492   epsilon: 0.7594418800052223    steps: 150    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1151   score: 1.0   memory length: 221644   epsilon: 0.7591409200052288    steps: 152    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1152   score: 6.0   memory length: 221999   epsilon: 0.7584380200052441    steps: 355    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1153   score: 3.0   memory length: 222245   epsilon: 0.7579509400052546    steps: 246    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1154   score: 0.0   memory length: 222368   epsilon: 0.7577074000052599    steps: 123    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1155   score: 5.0   memory length: 222688   epsilon: 0.7570738000052737    steps: 320    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1156   score: 4.0   memory length: 222986   epsilon: 0.7564837600052865    steps: 298    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1157   score: 3.0   memory length: 223212   epsilon: 0.7560362800052962    steps: 226    lr: 4e-05     evaluation reward: 2.37\n",
      "episode: 1158   score: 1.0   memory length: 223383   epsilon: 0.7556977000053036    steps: 171    lr: 4e-05     evaluation reward: 2.36\n",
      "episode: 1159   score: 0.0   memory length: 223506   epsilon: 0.7554541600053089    steps: 123    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1160   score: 3.0   memory length: 223732   epsilon: 0.7550066800053186    steps: 226    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1161   score: 5.0   memory length: 224061   epsilon: 0.7543552600053327    steps: 329    lr: 4e-05     evaluation reward: 2.35\n",
      "episode: 1162   score: 2.0   memory length: 224259   epsilon: 0.7539632200053412    steps: 198    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1163   score: 2.0   memory length: 224439   epsilon: 0.753606820005349    steps: 180    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1164   score: 3.0   memory length: 224687   epsilon: 0.7531157800053596    steps: 248    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1165   score: 3.0   memory length: 224932   epsilon: 0.7526306800053701    steps: 245    lr: 4e-05     evaluation reward: 2.37\n",
      "episode: 1166   score: 2.0   memory length: 225147   epsilon: 0.7522049800053794    steps: 215    lr: 4e-05     evaluation reward: 2.37\n",
      "episode: 1167   score: 2.0   memory length: 225344   epsilon: 0.7518149200053879    steps: 197    lr: 4e-05     evaluation reward: 2.36\n",
      "episode: 1168   score: 6.0   memory length: 225730   epsilon: 0.7510506400054044    steps: 386    lr: 4e-05     evaluation reward: 2.41\n",
      "episode: 1169   score: 4.0   memory length: 226022   epsilon: 0.750472480005417    steps: 292    lr: 4e-05     evaluation reward: 2.41\n",
      "episode: 1170   score: 0.0   memory length: 226145   epsilon: 0.7502289400054223    steps: 123    lr: 4e-05     evaluation reward: 2.41\n",
      "episode: 1171   score: 3.0   memory length: 226371   epsilon: 0.749781460005432    steps: 226    lr: 4e-05     evaluation reward: 2.43\n",
      "episode: 1172   score: 2.0   memory length: 226571   epsilon: 0.7493854600054406    steps: 200    lr: 4e-05     evaluation reward: 2.44\n",
      "episode: 1173   score: 6.0   memory length: 226926   epsilon: 0.7486825600054559    steps: 355    lr: 4e-05     evaluation reward: 2.46\n",
      "episode: 1174   score: 0.0   memory length: 227049   epsilon: 0.7484390200054611    steps: 123    lr: 4e-05     evaluation reward: 2.45\n",
      "episode: 1175   score: 0.0   memory length: 227172   epsilon: 0.7481954800054664    steps: 123    lr: 4e-05     evaluation reward: 2.43\n",
      "episode: 1176   score: 3.0   memory length: 227418   epsilon: 0.747708400005477    steps: 246    lr: 4e-05     evaluation reward: 2.44\n",
      "episode: 1177   score: 3.0   memory length: 227651   epsilon: 0.747247060005487    steps: 233    lr: 4e-05     evaluation reward: 2.47\n",
      "episode: 1178   score: 3.0   memory length: 227901   epsilon: 0.7467520600054978    steps: 250    lr: 4e-05     evaluation reward: 2.48\n",
      "episode: 1179   score: 3.0   memory length: 228127   epsilon: 0.7463045800055075    steps: 226    lr: 4e-05     evaluation reward: 2.49\n",
      "episode: 1180   score: 2.0   memory length: 228348   epsilon: 0.745867000005517    steps: 221    lr: 4e-05     evaluation reward: 2.5\n",
      "episode: 1181   score: 8.0   memory length: 228788   epsilon: 0.7449958000055359    steps: 440    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1182   score: 3.0   memory length: 229057   epsilon: 0.7444631800055475    steps: 269    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1183   score: 5.0   memory length: 229365   epsilon: 0.7438533400055607    steps: 308    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1184   score: 3.0   memory length: 229594   epsilon: 0.7433999200055705    steps: 229    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1185   score: 3.0   memory length: 229822   epsilon: 0.7429484800055803    steps: 228    lr: 4e-05     evaluation reward: 2.65\n",
      "episode: 1186   score: 1.0   memory length: 229973   epsilon: 0.7426495000055868    steps: 151    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1187   score: 3.0   memory length: 230186   epsilon: 0.742227760005596    steps: 213    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1188   score: 5.0   memory length: 230505   epsilon: 0.7415961400056097    steps: 319    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1189   score: 0.0   memory length: 230627   epsilon: 0.7413545800056149    steps: 122    lr: 4e-05     evaluation reward: 2.61\n",
      "episode: 1190   score: 4.0   memory length: 230915   epsilon: 0.7407843400056273    steps: 288    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1191   score: 3.0   memory length: 231141   epsilon: 0.740336860005637    steps: 226    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1192   score: 4.0   memory length: 231436   epsilon: 0.7397527600056497    steps: 295    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1193   score: 1.0   memory length: 231587   epsilon: 0.7394537800056562    steps: 151    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1194   score: 0.0   memory length: 231710   epsilon: 0.7392102400056615    steps: 123    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1195   score: 3.0   memory length: 231936   epsilon: 0.7387627600056712    steps: 226    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1196   score: 5.0   memory length: 232231   epsilon: 0.7381786600056839    steps: 295    lr: 4e-05     evaluation reward: 2.68\n",
      "episode: 1197   score: 3.0   memory length: 232439   epsilon: 0.7377668200056928    steps: 208    lr: 4e-05     evaluation reward: 2.67\n",
      "episode: 1198   score: 3.0   memory length: 232665   epsilon: 0.7373193400057025    steps: 226    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1199   score: 2.0   memory length: 232863   epsilon: 0.736927300005711    steps: 198    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1200   score: 2.0   memory length: 233063   epsilon: 0.7365313000057196    steps: 200    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1201   score: 2.0   memory length: 233280   epsilon: 0.736101640005729    steps: 217    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1202   score: 4.0   memory length: 233555   epsilon: 0.7355571400057408    steps: 275    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1203   score: 5.0   memory length: 233878   epsilon: 0.7349176000057547    steps: 323    lr: 4e-05     evaluation reward: 2.68\n",
      "episode: 1204   score: 2.0   memory length: 234076   epsilon: 0.7345255600057632    steps: 198    lr: 4e-05     evaluation reward: 2.67\n",
      "episode: 1205   score: 4.0   memory length: 234351   epsilon: 0.733981060005775    steps: 275    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1206   score: 4.0   memory length: 234610   epsilon: 0.7334682400057861    steps: 259    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1207   score: 4.0   memory length: 234920   epsilon: 0.7328544400057995    steps: 310    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1208   score: 3.0   memory length: 235145   epsilon: 0.7324089400058091    steps: 225    lr: 4e-05     evaluation reward: 2.68\n",
      "episode: 1209   score: 3.0   memory length: 235391   epsilon: 0.7319218600058197    steps: 246    lr: 4e-05     evaluation reward: 2.65\n",
      "episode: 1210   score: 3.0   memory length: 235618   epsilon: 0.7314724000058295    steps: 227    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1211   score: 1.0   memory length: 235786   epsilon: 0.7311397600058367    steps: 168    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1212   score: 3.0   memory length: 236033   epsilon: 0.7306507000058473    steps: 247    lr: 4e-05     evaluation reward: 2.66\n",
      "episode: 1213   score: 4.0   memory length: 236299   epsilon: 0.7301240200058587    steps: 266    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1214   score: 2.0   memory length: 236516   epsilon: 0.7296943600058681    steps: 217    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1215   score: 4.0   memory length: 236776   epsilon: 0.7291795600058792    steps: 260    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1216   score: 2.0   memory length: 236975   epsilon: 0.7287855400058878    steps: 199    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1217   score: 5.0   memory length: 237255   epsilon: 0.7282311400058998    steps: 280    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1218   score: 3.0   memory length: 237465   epsilon: 0.7278153400059089    steps: 210    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1219   score: 1.0   memory length: 237616   epsilon: 0.7275163600059154    steps: 151    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1220   score: 5.0   memory length: 237961   epsilon: 0.7268332600059302    steps: 345    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1221   score: 4.0   memory length: 238236   epsilon: 0.726288760005942    steps: 275    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1222   score: 1.0   memory length: 238386   epsilon: 0.7259917600059484    steps: 150    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1223   score: 3.0   memory length: 238631   epsilon: 0.725506660005959    steps: 245    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1224   score: 4.0   memory length: 238908   epsilon: 0.7249582000059709    steps: 277    lr: 4e-05     evaluation reward: 2.8\n",
      "episode: 1225   score: 2.0   memory length: 239088   epsilon: 0.7246018000059786    steps: 180    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1226   score: 3.0   memory length: 239335   epsilon: 0.7241127400059892    steps: 247    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1227   score: 3.0   memory length: 239604   epsilon: 0.7235801200060008    steps: 269    lr: 4e-05     evaluation reward: 2.8\n",
      "episode: 1228   score: 2.0   memory length: 239802   epsilon: 0.7231880800060093    steps: 198    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1229   score: 2.0   memory length: 240001   epsilon: 0.7227940600060179    steps: 199    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1230   score: 2.0   memory length: 240199   epsilon: 0.7224020200060264    steps: 198    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1231   score: 3.0   memory length: 240430   epsilon: 0.7219446400060363    steps: 231    lr: 4e-05     evaluation reward: 2.78\n",
      "episode: 1232   score: 7.0   memory length: 240823   epsilon: 0.7211665000060532    steps: 393    lr: 4e-05     evaluation reward: 2.81\n",
      "episode: 1233   score: 1.0   memory length: 240974   epsilon: 0.7208675200060597    steps: 151    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1234   score: 2.0   memory length: 241172   epsilon: 0.7204754800060682    steps: 198    lr: 4e-05     evaluation reward: 2.78\n",
      "episode: 1235   score: 3.0   memory length: 241417   epsilon: 0.7199903800060787    steps: 245    lr: 4e-05     evaluation reward: 2.78\n",
      "episode: 1236   score: 4.0   memory length: 241692   epsilon: 0.7194458800060906    steps: 275    lr: 4e-05     evaluation reward: 2.8\n",
      "episode: 1237   score: 1.0   memory length: 241843   epsilon: 0.719146900006097    steps: 151    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1238   score: 3.0   memory length: 242071   epsilon: 0.7186954600061068    steps: 228    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1239   score: 3.0   memory length: 242319   epsilon: 0.7182044200061175    steps: 248    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1240   score: 3.0   memory length: 242564   epsilon: 0.717719320006128    steps: 245    lr: 4e-05     evaluation reward: 2.78\n",
      "episode: 1241   score: 1.0   memory length: 242735   epsilon: 0.7173807400061354    steps: 171    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1242   score: 3.0   memory length: 242962   epsilon: 0.7169312800061451    steps: 227    lr: 4e-05     evaluation reward: 2.82\n",
      "episode: 1243   score: 4.0   memory length: 243238   epsilon: 0.716384800006157    steps: 276    lr: 4e-05     evaluation reward: 2.85\n",
      "episode: 1244   score: 0.0   memory length: 243361   epsilon: 0.7161412600061623    steps: 123    lr: 4e-05     evaluation reward: 2.82\n",
      "episode: 1245   score: 5.0   memory length: 243705   epsilon: 0.7154601400061771    steps: 344    lr: 4e-05     evaluation reward: 2.83\n",
      "episode: 1246   score: 0.0   memory length: 243828   epsilon: 0.7152166000061824    steps: 123    lr: 4e-05     evaluation reward: 2.8\n",
      "episode: 1247   score: 3.0   memory length: 244055   epsilon: 0.7147671400061921    steps: 227    lr: 4e-05     evaluation reward: 2.83\n",
      "episode: 1248   score: 3.0   memory length: 244268   epsilon: 0.7143454000062013    steps: 213    lr: 4e-05     evaluation reward: 2.83\n",
      "episode: 1249   score: 3.0   memory length: 244516   epsilon: 0.7138543600062119    steps: 248    lr: 4e-05     evaluation reward: 2.84\n",
      "episode: 1250   score: 1.0   memory length: 244666   epsilon: 0.7135573600062184    steps: 150    lr: 4e-05     evaluation reward: 2.84\n",
      "episode: 1251   score: 3.0   memory length: 244892   epsilon: 0.7131098800062281    steps: 226    lr: 4e-05     evaluation reward: 2.86\n",
      "episode: 1252   score: 2.0   memory length: 245091   epsilon: 0.7127158600062367    steps: 199    lr: 4e-05     evaluation reward: 2.82\n",
      "episode: 1253   score: 6.0   memory length: 245428   epsilon: 0.7120486000062511    steps: 337    lr: 4e-05     evaluation reward: 2.85\n",
      "episode: 1254   score: 5.0   memory length: 245733   epsilon: 0.7114447000062643    steps: 305    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1255   score: 2.0   memory length: 245930   epsilon: 0.7110546400062727    steps: 197    lr: 4e-05     evaluation reward: 2.87\n",
      "episode: 1256   score: 6.0   memory length: 246327   epsilon: 0.7102685800062898    steps: 397    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1257   score: 2.0   memory length: 246543   epsilon: 0.7098409000062991    steps: 216    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1258   score: 2.0   memory length: 246740   epsilon: 0.7094508400063075    steps: 197    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1259   score: 2.0   memory length: 246956   epsilon: 0.7090231600063168    steps: 216    lr: 4e-05     evaluation reward: 2.91\n",
      "episode: 1260   score: 2.0   memory length: 247136   epsilon: 0.7086667600063246    steps: 180    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1261   score: 5.0   memory length: 247454   epsilon: 0.7080371200063382    steps: 318    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1262   score: 1.0   memory length: 247606   epsilon: 0.7077361600063448    steps: 152    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1263   score: 1.0   memory length: 247757   epsilon: 0.7074371800063513    steps: 151    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1264   score: 3.0   memory length: 247985   epsilon: 0.706985740006361    steps: 228    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1265   score: 3.0   memory length: 248195   epsilon: 0.7065699400063701    steps: 210    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1266   score: 3.0   memory length: 248422   epsilon: 0.7061204800063798    steps: 227    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1267   score: 3.0   memory length: 248649   epsilon: 0.7056710200063896    steps: 227    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1268   score: 2.0   memory length: 248847   epsilon: 0.7052789800063981    steps: 198    lr: 4e-05     evaluation reward: 2.86\n",
      "episode: 1269   score: 1.0   memory length: 248998   epsilon: 0.7049800000064046    steps: 151    lr: 4e-05     evaluation reward: 2.83\n",
      "episode: 1270   score: 5.0   memory length: 249306   epsilon: 0.7043701600064178    steps: 308    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1271   score: 3.0   memory length: 249515   epsilon: 0.7039563400064268    steps: 209    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1272   score: 3.0   memory length: 249784   epsilon: 0.7034237200064384    steps: 269    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1273   score: 4.0   memory length: 250044   epsilon: 0.7029089200064496    steps: 260    lr: 4e-05     evaluation reward: 2.87\n",
      "episode: 1274   score: 3.0   memory length: 250290   epsilon: 0.7024218400064601    steps: 246    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1275   score: 2.0   memory length: 250490   epsilon: 0.7020258400064687    steps: 200    lr: 4e-05     evaluation reward: 2.92\n",
      "episode: 1276   score: 4.0   memory length: 250768   epsilon: 0.7014754000064807    steps: 278    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1277   score: 3.0   memory length: 250995   epsilon: 0.7010259400064904    steps: 227    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1278   score: 8.0   memory length: 251484   epsilon: 0.7000577200065115    steps: 489    lr: 4e-05     evaluation reward: 2.98\n",
      "episode: 1279   score: 2.0   memory length: 251682   epsilon: 0.69966568000652    steps: 198    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1280   score: 1.0   memory length: 251851   epsilon: 0.6993310600065272    steps: 169    lr: 4e-05     evaluation reward: 2.96\n",
      "episode: 1281   score: 3.0   memory length: 252080   epsilon: 0.6988776400065371    steps: 229    lr: 4e-05     evaluation reward: 2.91\n",
      "episode: 1282   score: 2.0   memory length: 252280   epsilon: 0.6984816400065457    steps: 200    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1283   score: 3.0   memory length: 252526   epsilon: 0.6979945600065562    steps: 246    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1284   score: 1.0   memory length: 252676   epsilon: 0.6976975600065627    steps: 150    lr: 4e-05     evaluation reward: 2.86\n",
      "episode: 1285   score: 3.0   memory length: 252889   epsilon: 0.6972758200065718    steps: 213    lr: 4e-05     evaluation reward: 2.86\n",
      "episode: 1286   score: 4.0   memory length: 253166   epsilon: 0.6967273600065838    steps: 277    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1287   score: 3.0   memory length: 253413   epsilon: 0.6962383000065944    steps: 247    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1288   score: 3.0   memory length: 253639   epsilon: 0.6957908200066041    steps: 226    lr: 4e-05     evaluation reward: 2.87\n",
      "episode: 1289   score: 3.0   memory length: 253886   epsilon: 0.6953017600066147    steps: 247    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1290   score: 1.0   memory length: 254037   epsilon: 0.6950027800066212    steps: 151    lr: 4e-05     evaluation reward: 2.87\n",
      "episode: 1291   score: 5.0   memory length: 254345   epsilon: 0.6943929400066344    steps: 308    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1292   score: 0.0   memory length: 254468   epsilon: 0.6941494000066397    steps: 123    lr: 4e-05     evaluation reward: 2.85\n",
      "episode: 1293   score: 3.0   memory length: 254715   epsilon: 0.6936603400066503    steps: 247    lr: 4e-05     evaluation reward: 2.87\n",
      "episode: 1294   score: 2.0   memory length: 254897   epsilon: 0.6932999800066582    steps: 182    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1295   score: 3.0   memory length: 255127   epsilon: 0.692844580006668    steps: 230    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1296   score: 4.0   memory length: 255402   epsilon: 0.6923000800066799    steps: 275    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1297   score: 3.0   memory length: 255648   epsilon: 0.6918130000066904    steps: 246    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1298   score: 6.0   memory length: 256023   epsilon: 0.6910705000067066    steps: 375    lr: 4e-05     evaluation reward: 2.91\n",
      "episode: 1299   score: 2.0   memory length: 256205   epsilon: 0.6907101400067144    steps: 182    lr: 4e-05     evaluation reward: 2.91\n",
      "episode: 1300   score: 4.0   memory length: 256482   epsilon: 0.6901616800067263    steps: 277    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1301   score: 4.0   memory length: 256737   epsilon: 0.6896567800067372    steps: 255    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1302   score: 3.0   memory length: 256985   epsilon: 0.6891657400067479    steps: 248    lr: 4e-05     evaluation reward: 2.94\n",
      "episode: 1303   score: 4.0   memory length: 257275   epsilon: 0.6885915400067604    steps: 290    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1304   score: 6.0   memory length: 257652   epsilon: 0.6878450800067766    steps: 377    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1305   score: 1.0   memory length: 257803   epsilon: 0.6875461000067831    steps: 151    lr: 4e-05     evaluation reward: 2.94\n",
      "episode: 1306   score: 1.0   memory length: 257972   epsilon: 0.6872114800067903    steps: 169    lr: 4e-05     evaluation reward: 2.91\n",
      "episode: 1307   score: 3.0   memory length: 258199   epsilon: 0.6867620200068001    steps: 227    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1308   score: 3.0   memory length: 258430   epsilon: 0.68630464000681    steps: 231    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1309   score: 4.0   memory length: 258704   epsilon: 0.6857621200068218    steps: 274    lr: 4e-05     evaluation reward: 2.91\n",
      "episode: 1310   score: 5.0   memory length: 259029   epsilon: 0.6851186200068358    steps: 325    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1311   score: 5.0   memory length: 259357   epsilon: 0.6844691800068499    steps: 328    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1312   score: 5.0   memory length: 259683   epsilon: 0.6838237000068639    steps: 326    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1313   score: 3.0   memory length: 259912   epsilon: 0.6833702800068737    steps: 229    lr: 4e-05     evaluation reward: 2.98\n",
      "episode: 1314   score: 7.0   memory length: 260294   epsilon: 0.6826139200068901    steps: 382    lr: 4e-05     evaluation reward: 3.03\n",
      "episode: 1315   score: 4.0   memory length: 260587   epsilon: 0.6820337800069027    steps: 293    lr: 4e-05     evaluation reward: 3.03\n",
      "episode: 1316   score: 4.0   memory length: 260841   epsilon: 0.6815308600069137    steps: 254    lr: 4e-05     evaluation reward: 3.05\n",
      "episode: 1317   score: 4.0   memory length: 261104   epsilon: 0.681010120006925    steps: 263    lr: 4e-05     evaluation reward: 3.04\n",
      "episode: 1318   score: 3.0   memory length: 261317   epsilon: 0.6805883800069341    steps: 213    lr: 4e-05     evaluation reward: 3.04\n",
      "episode: 1319   score: 6.0   memory length: 261664   epsilon: 0.679901320006949    steps: 347    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1320   score: 3.0   memory length: 261893   epsilon: 0.6794479000069589    steps: 229    lr: 4e-05     evaluation reward: 3.07\n",
      "episode: 1321   score: 0.0   memory length: 262016   epsilon: 0.6792043600069642    steps: 123    lr: 4e-05     evaluation reward: 3.03\n",
      "episode: 1322   score: 4.0   memory length: 262313   epsilon: 0.6786163000069769    steps: 297    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1323   score: 3.0   memory length: 262559   epsilon: 0.6781292200069875    steps: 246    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1324   score: 1.0   memory length: 262728   epsilon: 0.6777946000069948    steps: 169    lr: 4e-05     evaluation reward: 3.03\n",
      "episode: 1325   score: 5.0   memory length: 263023   epsilon: 0.6772105000070074    steps: 295    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1326   score: 1.0   memory length: 263192   epsilon: 0.6768758800070147    steps: 169    lr: 4e-05     evaluation reward: 3.04\n",
      "episode: 1327   score: 3.0   memory length: 263402   epsilon: 0.6764600800070237    steps: 210    lr: 4e-05     evaluation reward: 3.04\n",
      "episode: 1328   score: 5.0   memory length: 263722   epsilon: 0.6758264800070375    steps: 320    lr: 4e-05     evaluation reward: 3.07\n",
      "episode: 1329   score: 1.0   memory length: 263873   epsilon: 0.675527500007044    steps: 151    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1330   score: 2.0   memory length: 264093   epsilon: 0.6750919000070534    steps: 220    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1331   score: 2.0   memory length: 264278   epsilon: 0.6747256000070614    steps: 185    lr: 4e-05     evaluation reward: 3.05\n",
      "episode: 1332   score: 6.0   memory length: 264585   epsilon: 0.6741177400070746    steps: 307    lr: 4e-05     evaluation reward: 3.04\n",
      "episode: 1333   score: 5.0   memory length: 264866   epsilon: 0.6735613600070867    steps: 281    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1334   score: 3.0   memory length: 265112   epsilon: 0.6730742800070972    steps: 246    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1335   score: 3.0   memory length: 265339   epsilon: 0.672624820007107    steps: 227    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1336   score: 1.0   memory length: 265490   epsilon: 0.6723258400071135    steps: 151    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1337   score: 4.0   memory length: 265786   epsilon: 0.6717397600071262    steps: 296    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1338   score: 4.0   memory length: 266030   epsilon: 0.6712566400071367    steps: 244    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1339   score: 3.0   memory length: 266260   epsilon: 0.6708012400071466    steps: 230    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1340   score: 0.0   memory length: 266383   epsilon: 0.6705577000071519    steps: 123    lr: 4e-05     evaluation reward: 3.07\n",
      "episode: 1341   score: 1.0   memory length: 266534   epsilon: 0.6702587200071584    steps: 151    lr: 4e-05     evaluation reward: 3.07\n",
      "episode: 1342   score: 2.0   memory length: 266731   epsilon: 0.6698686600071668    steps: 197    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1343   score: 4.0   memory length: 267007   epsilon: 0.6693221800071787    steps: 276    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1344   score: 4.0   memory length: 267287   epsilon: 0.6687677800071907    steps: 280    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1345   score: 0.0   memory length: 267410   epsilon: 0.668524240007196    steps: 123    lr: 4e-05     evaluation reward: 3.05\n",
      "episode: 1346   score: 4.0   memory length: 267652   epsilon: 0.6680450800072064    steps: 242    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1347   score: 2.0   memory length: 267833   epsilon: 0.6676867000072142    steps: 181    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1348   score: 5.0   memory length: 268161   epsilon: 0.6670372600072283    steps: 328    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1349   score: 4.0   memory length: 268436   epsilon: 0.6664927600072401    steps: 275    lr: 4e-05     evaluation reward: 3.11\n",
      "episode: 1350   score: 4.0   memory length: 268714   epsilon: 0.6659423200072521    steps: 278    lr: 4e-05     evaluation reward: 3.14\n",
      "episode: 1351   score: 3.0   memory length: 268943   epsilon: 0.6654889000072619    steps: 229    lr: 4e-05     evaluation reward: 3.14\n",
      "episode: 1352   score: 2.0   memory length: 269141   epsilon: 0.6650968600072704    steps: 198    lr: 4e-05     evaluation reward: 3.14\n",
      "episode: 1353   score: 5.0   memory length: 269464   epsilon: 0.6644573200072843    steps: 323    lr: 4e-05     evaluation reward: 3.13\n",
      "episode: 1354   score: 5.0   memory length: 269786   epsilon: 0.6638197600072981    steps: 322    lr: 4e-05     evaluation reward: 3.13\n",
      "episode: 1355   score: 1.0   memory length: 269936   epsilon: 0.6635227600073046    steps: 150    lr: 4e-05     evaluation reward: 3.12\n",
      "episode: 1356   score: 3.0   memory length: 270165   epsilon: 0.6630693400073144    steps: 229    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1357   score: 7.0   memory length: 270595   epsilon: 0.6622179400073329    steps: 430    lr: 4e-05     evaluation reward: 3.14\n",
      "episode: 1358   score: 3.0   memory length: 270808   epsilon: 0.6617962000073421    steps: 213    lr: 4e-05     evaluation reward: 3.15\n",
      "episode: 1359   score: 4.0   memory length: 271068   epsilon: 0.6612814000073532    steps: 260    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1360   score: 1.0   memory length: 271238   epsilon: 0.6609448000073606    steps: 170    lr: 4e-05     evaluation reward: 3.16\n",
      "episode: 1361   score: 3.0   memory length: 271451   epsilon: 0.6605230600073697    steps: 213    lr: 4e-05     evaluation reward: 3.14\n",
      "episode: 1362   score: 7.0   memory length: 271844   epsilon: 0.6597449200073866    steps: 393    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1363   score: 4.0   memory length: 272119   epsilon: 0.6592004200073984    steps: 275    lr: 4e-05     evaluation reward: 3.23\n",
      "episode: 1364   score: 3.0   memory length: 272332   epsilon: 0.6587786800074076    steps: 213    lr: 4e-05     evaluation reward: 3.23\n",
      "episode: 1365   score: 2.0   memory length: 272511   epsilon: 0.6584242600074153    steps: 179    lr: 4e-05     evaluation reward: 3.22\n",
      "episode: 1366   score: 1.0   memory length: 272661   epsilon: 0.6581272600074217    steps: 150    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1367   score: 1.0   memory length: 272811   epsilon: 0.6578302600074282    steps: 150    lr: 4e-05     evaluation reward: 3.18\n",
      "episode: 1368   score: 5.0   memory length: 273135   epsilon: 0.6571887400074421    steps: 324    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1369   score: 2.0   memory length: 273336   epsilon: 0.6567907600074507    steps: 201    lr: 4e-05     evaluation reward: 3.22\n",
      "episode: 1370   score: 3.0   memory length: 273549   epsilon: 0.6563690200074599    steps: 213    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1371   score: 2.0   memory length: 273747   epsilon: 0.6559769800074684    steps: 198    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1372   score: 1.0   memory length: 273919   epsilon: 0.6556364200074758    steps: 172    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1373   score: 5.0   memory length: 274224   epsilon: 0.6550325200074889    steps: 305    lr: 4e-05     evaluation reward: 3.18\n",
      "episode: 1374   score: 1.0   memory length: 274375   epsilon: 0.6547335400074954    steps: 151    lr: 4e-05     evaluation reward: 3.16\n",
      "episode: 1375   score: 3.0   memory length: 274588   epsilon: 0.6543118000075046    steps: 213    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1376   score: 4.0   memory length: 274864   epsilon: 0.6537653200075164    steps: 276    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1377   score: 5.0   memory length: 275209   epsilon: 0.6530822200075312    steps: 345    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1378   score: 4.0   memory length: 275499   epsilon: 0.6525080200075437    steps: 290    lr: 4e-05     evaluation reward: 3.15\n",
      "episode: 1379   score: 4.0   memory length: 275774   epsilon: 0.6519635200075555    steps: 275    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1380   score: 3.0   memory length: 276000   epsilon: 0.6515160400075652    steps: 226    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1381   score: 3.0   memory length: 276228   epsilon: 0.651064600007575    steps: 228    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1382   score: 3.0   memory length: 276441   epsilon: 0.6506428600075842    steps: 213    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1383   score: 4.0   memory length: 276736   epsilon: 0.6500587600075969    steps: 295    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1384   score: 3.0   memory length: 276965   epsilon: 0.6496053400076067    steps: 229    lr: 4e-05     evaluation reward: 3.23\n",
      "episode: 1385   score: 1.0   memory length: 277136   epsilon: 0.6492667600076141    steps: 171    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1386   score: 4.0   memory length: 277413   epsilon: 0.648718300007626    steps: 277    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1387   score: 3.0   memory length: 277624   epsilon: 0.648300520007635    steps: 211    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1388   score: 1.0   memory length: 277775   epsilon: 0.6480015400076415    steps: 151    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1389   score: 1.0   memory length: 277946   epsilon: 0.6476629600076489    steps: 171    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1390   score: 3.0   memory length: 278175   epsilon: 0.6472095400076587    steps: 229    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1391   score: 3.0   memory length: 278401   epsilon: 0.6467620600076684    steps: 226    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1392   score: 1.0   memory length: 278552   epsilon: 0.6464630800076749    steps: 151    lr: 4e-05     evaluation reward: 3.18\n",
      "episode: 1393   score: 8.0   memory length: 279006   epsilon: 0.6455641600076945    steps: 454    lr: 4e-05     evaluation reward: 3.23\n",
      "episode: 1394   score: 7.0   memory length: 279386   epsilon: 0.6448117600077108    steps: 380    lr: 4e-05     evaluation reward: 3.28\n",
      "episode: 1395   score: 3.0   memory length: 279614   epsilon: 0.6443603200077206    steps: 228    lr: 4e-05     evaluation reward: 3.28\n",
      "episode: 1396   score: 4.0   memory length: 279909   epsilon: 0.6437762200077333    steps: 295    lr: 4e-05     evaluation reward: 3.28\n",
      "episode: 1397   score: 0.0   memory length: 280032   epsilon: 0.6435326800077386    steps: 123    lr: 4e-05     evaluation reward: 3.25\n",
      "episode: 1398   score: 3.0   memory length: 280245   epsilon: 0.6431109400077477    steps: 213    lr: 4e-05     evaluation reward: 3.22\n",
      "episode: 1399   score: 5.0   memory length: 280535   epsilon: 0.6425367400077602    steps: 290    lr: 4e-05     evaluation reward: 3.25\n",
      "episode: 1400   score: 1.0   memory length: 280687   epsilon: 0.6422357800077667    steps: 152    lr: 4e-05     evaluation reward: 3.22\n",
      "episode: 1401   score: 3.0   memory length: 280952   epsilon: 0.6417110800077781    steps: 265    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1402   score: 2.0   memory length: 281134   epsilon: 0.6413507200077859    steps: 182    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1403   score: 3.0   memory length: 281364   epsilon: 0.6408953200077958    steps: 230    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1404   score: 3.0   memory length: 281612   epsilon: 0.6404042800078065    steps: 248    lr: 4e-05     evaluation reward: 3.16\n",
      "episode: 1405   score: 6.0   memory length: 281988   epsilon: 0.6396598000078226    steps: 376    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1406   score: 2.0   memory length: 282167   epsilon: 0.6393053800078303    steps: 179    lr: 4e-05     evaluation reward: 3.22\n",
      "episode: 1407   score: 2.0   memory length: 282348   epsilon: 0.6389470000078381    steps: 181    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1408   score: 4.0   memory length: 282607   epsilon: 0.6384341800078492    steps: 259    lr: 4e-05     evaluation reward: 3.22\n",
      "episode: 1409   score: 4.0   memory length: 282885   epsilon: 0.6378837400078612    steps: 278    lr: 4e-05     evaluation reward: 3.22\n",
      "episode: 1410   score: 3.0   memory length: 283110   epsilon: 0.6374382400078709    steps: 225    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1411   score: 6.0   memory length: 283465   epsilon: 0.6367353400078861    steps: 355    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1412   score: 3.0   memory length: 283711   epsilon: 0.6362482600078967    steps: 246    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1413   score: 3.0   memory length: 283955   epsilon: 0.6357651400079072    steps: 244    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1414   score: 1.0   memory length: 284106   epsilon: 0.6354661600079137    steps: 151    lr: 4e-05     evaluation reward: 3.13\n",
      "episode: 1415   score: 5.0   memory length: 284446   epsilon: 0.6347929600079283    steps: 340    lr: 4e-05     evaluation reward: 3.14\n",
      "episode: 1416   score: 1.0   memory length: 284615   epsilon: 0.6344583400079356    steps: 169    lr: 4e-05     evaluation reward: 3.11\n",
      "episode: 1417   score: 3.0   memory length: 284843   epsilon: 0.6340069000079454    steps: 228    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1418   score: 2.0   memory length: 285025   epsilon: 0.6336465400079532    steps: 182    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1419   score: 0.0   memory length: 285148   epsilon: 0.6334030000079585    steps: 123    lr: 4e-05     evaluation reward: 3.03\n",
      "episode: 1420   score: 5.0   memory length: 285452   epsilon: 0.6328010800079715    steps: 304    lr: 4e-05     evaluation reward: 3.05\n",
      "episode: 1421   score: 4.0   memory length: 285732   epsilon: 0.6322466800079836    steps: 280    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1422   score: 3.0   memory length: 285963   epsilon: 0.6317893000079935    steps: 231    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1423   score: 5.0   memory length: 286270   epsilon: 0.6311814400080067    steps: 307    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1424   score: 3.0   memory length: 286500   epsilon: 0.6307260400080166    steps: 230    lr: 4e-05     evaluation reward: 3.12\n",
      "episode: 1425   score: 3.0   memory length: 286730   epsilon: 0.6302706400080265    steps: 230    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1426   score: 3.0   memory length: 286943   epsilon: 0.6298489000080356    steps: 213    lr: 4e-05     evaluation reward: 3.12\n",
      "episode: 1427   score: 3.0   memory length: 287193   epsilon: 0.6293539000080464    steps: 250    lr: 4e-05     evaluation reward: 3.12\n",
      "episode: 1428   score: 3.0   memory length: 287438   epsilon: 0.6288688000080569    steps: 245    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1429   score: 2.0   memory length: 287639   epsilon: 0.6284708200080655    steps: 201    lr: 4e-05     evaluation reward: 3.11\n",
      "episode: 1430   score: 2.0   memory length: 287837   epsilon: 0.628078780008074    steps: 198    lr: 4e-05     evaluation reward: 3.11\n",
      "episode: 1431   score: 4.0   memory length: 288115   epsilon: 0.627528340008086    steps: 278    lr: 4e-05     evaluation reward: 3.13\n",
      "episode: 1432   score: 5.0   memory length: 288424   epsilon: 0.6269165200080993    steps: 309    lr: 4e-05     evaluation reward: 3.12\n",
      "episode: 1433   score: 3.0   memory length: 288671   epsilon: 0.6264274600081099    steps: 247    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1434   score: 2.0   memory length: 288871   epsilon: 0.6260314600081185    steps: 200    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1435   score: 4.0   memory length: 289169   epsilon: 0.6254414200081313    steps: 298    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1436   score: 1.0   memory length: 289320   epsilon: 0.6251424400081378    steps: 151    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1437   score: 4.0   memory length: 289636   epsilon: 0.6245167600081514    steps: 316    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1438   score: 3.0   memory length: 289882   epsilon: 0.624029680008162    steps: 246    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1439   score: 3.0   memory length: 290110   epsilon: 0.6235782400081717    steps: 228    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1440   score: 1.0   memory length: 290278   epsilon: 0.623245600008179    steps: 168    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1441   score: 2.0   memory length: 290476   epsilon: 0.6228535600081875    steps: 198    lr: 4e-05     evaluation reward: 3.11\n",
      "episode: 1442   score: 3.0   memory length: 290722   epsilon: 0.622366480008198    steps: 246    lr: 4e-05     evaluation reward: 3.12\n",
      "episode: 1443   score: 5.0   memory length: 291066   epsilon: 0.6216853600082128    steps: 344    lr: 4e-05     evaluation reward: 3.13\n",
      "episode: 1444   score: 4.0   memory length: 291321   epsilon: 0.6211804600082238    steps: 255    lr: 4e-05     evaluation reward: 3.13\n",
      "episode: 1445   score: 2.0   memory length: 291502   epsilon: 0.6208220800082316    steps: 181    lr: 4e-05     evaluation reward: 3.15\n",
      "episode: 1446   score: 2.0   memory length: 291684   epsilon: 0.6204617200082394    steps: 182    lr: 4e-05     evaluation reward: 3.13\n",
      "episode: 1447   score: 2.0   memory length: 291882   epsilon: 0.6200696800082479    steps: 198    lr: 4e-05     evaluation reward: 3.13\n",
      "episode: 1448   score: 3.0   memory length: 292092   epsilon: 0.6196538800082569    steps: 210    lr: 4e-05     evaluation reward: 3.11\n",
      "episode: 1449   score: 4.0   memory length: 292393   epsilon: 0.6190579000082699    steps: 301    lr: 4e-05     evaluation reward: 3.11\n",
      "episode: 1450   score: 2.0   memory length: 292591   epsilon: 0.6186658600082784    steps: 198    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1451   score: 4.0   memory length: 292850   epsilon: 0.6181530400082895    steps: 259    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1452   score: 2.0   memory length: 293048   epsilon: 0.617761000008298    steps: 198    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1453   score: 3.0   memory length: 293260   epsilon: 0.6173412400083071    steps: 212    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1454   score: 11.0   memory length: 293745   epsilon: 0.616380940008328    steps: 485    lr: 4e-05     evaluation reward: 3.14\n",
      "episode: 1455   score: 4.0   memory length: 294005   epsilon: 0.6158661400083392    steps: 260    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1456   score: 6.0   memory length: 294352   epsilon: 0.6151790800083541    steps: 347    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1457   score: 4.0   memory length: 294628   epsilon: 0.614632600008366    steps: 276    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1458   score: 3.0   memory length: 294840   epsilon: 0.6142128400083751    steps: 212    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1459   score: 3.0   memory length: 295106   epsilon: 0.6136861600083865    steps: 266    lr: 4e-05     evaluation reward: 3.16\n",
      "episode: 1460   score: 4.0   memory length: 295381   epsilon: 0.6131416600083983    steps: 275    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1461   score: 5.0   memory length: 295702   epsilon: 0.6125060800084121    steps: 321    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1462   score: 2.0   memory length: 295883   epsilon: 0.6121477000084199    steps: 181    lr: 4e-05     evaluation reward: 3.16\n",
      "episode: 1463   score: 6.0   memory length: 296239   epsilon: 0.6114428200084352    steps: 356    lr: 4e-05     evaluation reward: 3.18\n",
      "episode: 1464   score: 5.0   memory length: 296569   epsilon: 0.6107894200084494    steps: 330    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1465   score: 1.0   memory length: 296720   epsilon: 0.6104904400084559    steps: 151    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1466   score: 6.0   memory length: 297080   epsilon: 0.6097776400084713    steps: 360    lr: 4e-05     evaluation reward: 3.24\n",
      "episode: 1467   score: 4.0   memory length: 297355   epsilon: 0.6092331400084832    steps: 275    lr: 4e-05     evaluation reward: 3.27\n",
      "episode: 1468   score: 6.0   memory length: 297683   epsilon: 0.6085837000084973    steps: 328    lr: 4e-05     evaluation reward: 3.28\n",
      "episode: 1469   score: 12.0   memory length: 298219   epsilon: 0.6075224200085203    steps: 536    lr: 4e-05     evaluation reward: 3.38\n",
      "episode: 1470   score: 3.0   memory length: 298467   epsilon: 0.607031380008531    steps: 248    lr: 4e-05     evaluation reward: 3.38\n",
      "episode: 1471   score: 3.0   memory length: 298696   epsilon: 0.6065779600085408    steps: 229    lr: 4e-05     evaluation reward: 3.39\n",
      "episode: 1472   score: 6.0   memory length: 299071   epsilon: 0.6058354600085569    steps: 375    lr: 4e-05     evaluation reward: 3.44\n",
      "episode: 1473   score: 3.0   memory length: 299298   epsilon: 0.6053860000085667    steps: 227    lr: 4e-05     evaluation reward: 3.42\n",
      "episode: 1474   score: 3.0   memory length: 299542   epsilon: 0.6049028800085772    steps: 244    lr: 4e-05     evaluation reward: 3.44\n",
      "episode: 1475   score: 3.0   memory length: 299769   epsilon: 0.6044534200085869    steps: 227    lr: 4e-05     evaluation reward: 3.44\n",
      "episode: 1476   score: 3.0   memory length: 299998   epsilon: 0.6040000000085968    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1477   score: 4.0   memory length: 300282   epsilon: 0.603437680008609    steps: 284    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n",
      "episode: 1478   score: 6.0   memory length: 300646   epsilon: 0.6027169600086246    steps: 364    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1479   score: 4.0   memory length: 300942   epsilon: 0.6021308800086373    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1480   score: 2.0   memory length: 301124   epsilon: 0.6017705200086452    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1481   score: 3.0   memory length: 301335   epsilon: 0.6013527400086542    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1482   score: 3.0   memory length: 301562   epsilon: 0.600903280008664    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1483   score: 2.0   memory length: 301762   epsilon: 0.6005072800086726    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.41\n",
      "episode: 1484   score: 5.0   memory length: 302085   epsilon: 0.5998677400086865    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1485   score: 3.0   memory length: 302295   epsilon: 0.5994519400086955    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n",
      "episode: 1486   score: 5.0   memory length: 302641   epsilon: 0.5987668600087104    steps: 346    lr: 1.6000000000000003e-05     evaluation reward: 3.46\n",
      "episode: 1487   score: 5.0   memory length: 302943   epsilon: 0.5981689000087234    steps: 302    lr: 1.6000000000000003e-05     evaluation reward: 3.48\n",
      "episode: 1488   score: 6.0   memory length: 303290   epsilon: 0.5974818400087383    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 3.53\n",
      "episode: 1489   score: 5.0   memory length: 303578   epsilon: 0.5969116000087507    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1490   score: 4.0   memory length: 303837   epsilon: 0.5963987800087618    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1491   score: 3.0   memory length: 304083   epsilon: 0.5959117000087724    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1492   score: 3.0   memory length: 304313   epsilon: 0.5954563000087822    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1493   score: 4.0   memory length: 304610   epsilon: 0.594868240008795    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n",
      "episode: 1494   score: 3.0   memory length: 304835   epsilon: 0.5944227400088047    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 3.52\n",
      "episode: 1495   score: 4.0   memory length: 305131   epsilon: 0.5938366600088174    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.53\n",
      "episode: 1496   score: 7.0   memory length: 305553   epsilon: 0.5930011000088355    steps: 422    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n",
      "episode: 1497   score: 6.0   memory length: 305906   epsilon: 0.5923021600088507    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n",
      "episode: 1498   score: 3.0   memory length: 306156   epsilon: 0.5918071600088615    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n",
      "episode: 1499   score: 4.0   memory length: 306448   epsilon: 0.591229000008874    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1500   score: 3.0   memory length: 306674   epsilon: 0.5907815200088837    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1501   score: 3.0   memory length: 306926   epsilon: 0.5902825600088946    steps: 252    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1502   score: 4.0   memory length: 307166   epsilon: 0.5898073600089049    steps: 240    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1503   score: 2.0   memory length: 307387   epsilon: 0.5893697800089144    steps: 221    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1504   score: 8.0   memory length: 307841   epsilon: 0.5884708600089339    steps: 454    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n",
      "episode: 1505   score: 3.0   memory length: 308071   epsilon: 0.5880154600089438    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1506   score: 5.0   memory length: 308397   epsilon: 0.5873699800089578    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n",
      "episode: 1507   score: 8.0   memory length: 308859   epsilon: 0.5864552200089777    steps: 462    lr: 1.6000000000000003e-05     evaluation reward: 3.75\n",
      "episode: 1508   score: 5.0   memory length: 309163   epsilon: 0.5858533000089907    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 3.76\n",
      "episode: 1509   score: 3.0   memory length: 309376   epsilon: 0.5854315600089999    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.75\n",
      "episode: 1510   score: 4.0   memory length: 309635   epsilon: 0.584918740009011    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.76\n",
      "episode: 1511   score: 1.0   memory length: 309785   epsilon: 0.5846217400090175    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1512   score: 3.0   memory length: 309998   epsilon: 0.5842000000090266    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1513   score: 4.0   memory length: 310273   epsilon: 0.5836555000090384    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1514   score: 1.0   memory length: 310424   epsilon: 0.5833565200090449    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1515   score: 2.0   memory length: 310606   epsilon: 0.5829961600090527    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n",
      "episode: 1516   score: 1.0   memory length: 310757   epsilon: 0.5826971800090592    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n",
      "episode: 1517   score: 3.0   memory length: 310986   epsilon: 0.5822437600090691    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n",
      "episode: 1518   score: 3.0   memory length: 311217   epsilon: 0.581786380009079    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n",
      "episode: 1519   score: 3.0   memory length: 311445   epsilon: 0.5813349400090888    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1520   score: 5.0   memory length: 311780   epsilon: 0.5806716400091032    steps: 335    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1521   score: 3.0   memory length: 312006   epsilon: 0.5802241600091129    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1522   score: 4.0   memory length: 312305   epsilon: 0.5796321400091258    steps: 299    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1523   score: 4.0   memory length: 312601   epsilon: 0.5790460600091385    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1524   score: 3.0   memory length: 312831   epsilon: 0.5785906600091484    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1525   score: 5.0   memory length: 313106   epsilon: 0.5780461600091602    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n",
      "episode: 1526   score: 3.0   memory length: 313357   epsilon: 0.577549180009171    steps: 251    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n",
      "episode: 1527   score: 6.0   memory length: 313729   epsilon: 0.576812620009187    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n",
      "episode: 1528   score: 4.0   memory length: 313985   epsilon: 0.576305740009198    steps: 256    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n",
      "episode: 1529   score: 4.0   memory length: 314225   epsilon: 0.5758305400092083    steps: 240    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n",
      "episode: 1530   score: 4.0   memory length: 314504   epsilon: 0.5752781200092203    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 3.82\n",
      "episode: 1531   score: 3.0   memory length: 314729   epsilon: 0.57483262000923    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n",
      "episode: 1532   score: 2.0   memory length: 314911   epsilon: 0.5744722600092378    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n",
      "episode: 1533   score: 2.0   memory length: 315111   epsilon: 0.5740762600092464    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n",
      "episode: 1534   score: 4.0   memory length: 315388   epsilon: 0.5735278000092583    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n",
      "episode: 1535   score: 5.0   memory length: 315695   epsilon: 0.5729199400092715    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n",
      "episode: 1536   score: 4.0   memory length: 315949   epsilon: 0.5724170200092824    steps: 254    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n",
      "episode: 1537   score: 4.0   memory length: 316225   epsilon: 0.5718705400092943    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n",
      "episode: 1538   score: 3.0   memory length: 316454   epsilon: 0.5714171200093041    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n",
      "episode: 1539   score: 7.0   memory length: 316857   epsilon: 0.5706191800093214    steps: 403    lr: 1.6000000000000003e-05     evaluation reward: 3.87\n",
      "episode: 1540   score: 8.0   memory length: 317287   epsilon: 0.5697677800093399    steps: 430    lr: 1.6000000000000003e-05     evaluation reward: 3.94\n",
      "episode: 1541   score: 5.0   memory length: 317585   epsilon: 0.5691777400093527    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1542   score: 6.0   memory length: 317957   epsilon: 0.5684411800093687    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 4.0\n",
      "episode: 1543   score: 3.0   memory length: 318186   epsilon: 0.5679877600093786    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.98\n",
      "episode: 1544   score: 5.0   memory length: 318492   epsilon: 0.5673818800093917    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 3.99\n",
      "episode: 1545   score: 2.0   memory length: 318711   epsilon: 0.5669482600094011    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 3.99\n",
      "episode: 1546   score: 8.0   memory length: 319184   epsilon: 0.5660117200094215    steps: 473    lr: 1.6000000000000003e-05     evaluation reward: 4.05\n",
      "episode: 1547   score: 5.0   memory length: 319487   epsilon: 0.5654117800094345    steps: 303    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1548   score: 3.0   memory length: 319697   epsilon: 0.5649959800094435    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1549   score: 3.0   memory length: 319910   epsilon: 0.5645742400094527    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1550   score: 3.0   memory length: 320139   epsilon: 0.5641208200094625    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1551   score: 5.0   memory length: 320470   epsilon: 0.5634654400094767    steps: 331    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1552   score: 3.0   memory length: 320696   epsilon: 0.5630179600094865    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1553   score: 3.0   memory length: 320946   epsilon: 0.5625229600094972    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1554   score: 1.0   memory length: 321096   epsilon: 0.5622259600095036    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 4.0\n",
      "episode: 1555   score: 3.0   memory length: 321308   epsilon: 0.5618062000095128    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.99\n",
      "episode: 1556   score: 12.0   memory length: 321796   epsilon: 0.5608399600095337    steps: 488    lr: 1.6000000000000003e-05     evaluation reward: 4.05\n",
      "episode: 1557   score: 5.0   memory length: 322121   epsilon: 0.5601964600095477    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1558   score: 4.0   memory length: 322420   epsilon: 0.5596044400095606    steps: 299    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1559   score: 4.0   memory length: 322718   epsilon: 0.5590144000095734    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1560   score: 3.0   memory length: 322944   epsilon: 0.5585669200095831    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1561   score: 10.0   memory length: 323289   epsilon: 0.5578838200095979    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1562   score: 5.0   memory length: 323585   epsilon: 0.5572977400096106    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1563   score: 3.0   memory length: 323815   epsilon: 0.5568423400096205    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1564   score: 4.0   memory length: 324057   epsilon: 0.5563631800096309    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1565   score: 2.0   memory length: 324255   epsilon: 0.5559711400096394    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1566   score: 6.0   memory length: 324612   epsilon: 0.5552642800096548    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1567   score: 6.0   memory length: 325003   epsilon: 0.5544901000096716    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1568   score: 4.0   memory length: 325262   epsilon: 0.5539772800096827    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1569   score: 3.0   memory length: 325475   epsilon: 0.5535555400096919    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.03\n",
      "episode: 1570   score: 4.0   memory length: 325755   epsilon: 0.5530011400097039    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 4.04\n",
      "episode: 1571   score: 6.0   memory length: 326107   epsilon: 0.552304180009719    steps: 352    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1572   score: 6.0   memory length: 326448   epsilon: 0.5516290000097337    steps: 341    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1573   score: 3.0   memory length: 326661   epsilon: 0.5512072600097428    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1574   score: 6.0   memory length: 327014   epsilon: 0.550508320009758    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1575   score: 3.0   memory length: 327223   epsilon: 0.550094500009767    steps: 209    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1576   score: 4.0   memory length: 327482   epsilon: 0.5495816800097781    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1577   score: 5.0   memory length: 327804   epsilon: 0.548944120009792    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1578   score: 4.0   memory length: 328047   epsilon: 0.5484629800098024    steps: 243    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1579   score: 3.0   memory length: 328273   epsilon: 0.5480155000098121    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1580   score: 1.0   memory length: 328423   epsilon: 0.5477185000098186    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1581   score: 3.0   memory length: 328652   epsilon: 0.5472650800098284    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1582   score: 4.0   memory length: 328930   epsilon: 0.5467146400098404    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1583   score: 6.0   memory length: 329287   epsilon: 0.5460077800098557    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n",
      "episode: 1584   score: 1.0   memory length: 329438   epsilon: 0.5457088000098622    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1585   score: 3.0   memory length: 329651   epsilon: 0.5452870600098714    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1586   score: 6.0   memory length: 330043   epsilon: 0.5445109000098882    steps: 392    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1587   score: 5.0   memory length: 330348   epsilon: 0.5439070000099013    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1588   score: 5.0   memory length: 330655   epsilon: 0.5432991400099145    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1589   score: 4.0   memory length: 330948   epsilon: 0.5427190000099271    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1590   score: 4.0   memory length: 331243   epsilon: 0.5421349000099398    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1591   score: 3.0   memory length: 331472   epsilon: 0.5416814800099496    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1592   score: 4.0   memory length: 331716   epsilon: 0.5411983600099601    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1593   score: 3.0   memory length: 331926   epsilon: 0.5407825600099692    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1594   score: 5.0   memory length: 332214   epsilon: 0.5402123200099815    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1595   score: 6.0   memory length: 332599   epsilon: 0.5394500200099981    steps: 385    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1596   score: 3.0   memory length: 332810   epsilon: 0.5390322400100072    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1597   score: 4.0   memory length: 333088   epsilon: 0.5384818000100191    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1598   score: 3.0   memory length: 333335   epsilon: 0.5379927400100297    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1599   score: 4.0   memory length: 333633   epsilon: 0.5374027000100425    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1600   score: 7.0   memory length: 333984   epsilon: 0.5367077200100576    steps: 351    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1601   score: 5.0   memory length: 334271   epsilon: 0.53613946001007    steps: 287    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1602   score: 3.0   memory length: 334482   epsilon: 0.535721680010079    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1603   score: 5.0   memory length: 334771   epsilon: 0.5351494600100914    steps: 289    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1604   score: 3.0   memory length: 335020   epsilon: 0.5346564400101022    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1605   score: 5.0   memory length: 335316   epsilon: 0.5340703600101149    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1606   score: 3.0   memory length: 335541   epsilon: 0.5336248600101245    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1607   score: 3.0   memory length: 335770   epsilon: 0.5331714400101344    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.04\n",
      "episode: 1608   score: 5.0   memory length: 336118   epsilon: 0.5324824000101493    steps: 348    lr: 1.6000000000000003e-05     evaluation reward: 4.04\n",
      "episode: 1609   score: 6.0   memory length: 336470   epsilon: 0.5317854400101645    steps: 352    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1610   score: 5.0   memory length: 336743   epsilon: 0.5312449000101762    steps: 273    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1611   score: 5.0   memory length: 337089   epsilon: 0.5305598200101911    steps: 346    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1612   score: 3.0   memory length: 337300   epsilon: 0.5301420400102002    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1613   score: 3.0   memory length: 337547   epsilon: 0.5296529800102108    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1614   score: 6.0   memory length: 337874   epsilon: 0.5290055200102248    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n",
      "episode: 1615   score: 6.0   memory length: 338253   epsilon: 0.5282551000102411    steps: 379    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1616   score: 3.0   memory length: 338482   epsilon: 0.527801680010251    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1617   score: 3.0   memory length: 338713   epsilon: 0.5273443000102609    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1618   score: 1.0   memory length: 338864   epsilon: 0.5270453200102674    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1619   score: 4.0   memory length: 339158   epsilon: 0.52646320001028    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1620   score: 3.0   memory length: 339388   epsilon: 0.5260078000102899    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1621   score: 3.0   memory length: 339617   epsilon: 0.5255543800102997    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1622   score: 5.0   memory length: 339925   epsilon: 0.524944540010313    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1623   score: 3.0   memory length: 340138   epsilon: 0.5245228000103221    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1624   score: 3.0   memory length: 340347   epsilon: 0.5241089800103311    steps: 209    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1625   score: 5.0   memory length: 340672   epsilon: 0.5234654800103451    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1626   score: 5.0   memory length: 340980   epsilon: 0.5228556400103583    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1627   score: 3.0   memory length: 341192   epsilon: 0.5224358800103674    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1628   score: 6.0   memory length: 341549   epsilon: 0.5217290200103828    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1629   score: 3.0   memory length: 341778   epsilon: 0.5212756000103926    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1630   score: 5.0   memory length: 342088   epsilon: 0.520661800010406    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1631   score: 4.0   memory length: 342344   epsilon: 0.520154920010417    steps: 256    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1632   score: 7.0   memory length: 342763   epsilon: 0.519325300010435    steps: 419    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1633   score: 4.0   memory length: 343038   epsilon: 0.5187808000104468    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1634   score: 6.0   memory length: 343376   epsilon: 0.5181115600104613    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1635   score: 4.0   memory length: 343636   epsilon: 0.5175967600104725    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1636   score: 5.0   memory length: 343943   epsilon: 0.5169889000104857    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1637   score: 6.0   memory length: 344280   epsilon: 0.5163216400105002    steps: 337    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1638   score: 2.0   memory length: 344480   epsilon: 0.5159256400105088    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1639   score: 3.0   memory length: 344712   epsilon: 0.5154662800105188    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1640   score: 5.0   memory length: 345037   epsilon: 0.5148227800105327    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.24\n",
      "episode: 1641   score: 3.0   memory length: 345264   epsilon: 0.5143733200105425    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1642   score: 6.0   memory length: 345646   epsilon: 0.5136169600105589    steps: 382    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1643   score: 6.0   memory length: 345972   epsilon: 0.5129714800105729    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1644   score: 8.0   memory length: 346461   epsilon: 0.5120032600105939    steps: 489    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1645   score: 5.0   memory length: 346789   epsilon: 0.511353820010608    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1646   score: 3.0   memory length: 346998   epsilon: 0.510940000010617    steps: 209    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1647   score: 6.0   memory length: 347357   epsilon: 0.5102291800106324    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1648   score: 4.0   memory length: 347599   epsilon: 0.5097500200106428    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1649   score: 2.0   memory length: 347800   epsilon: 0.5093520400106515    steps: 201    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1650   score: 3.0   memory length: 348026   epsilon: 0.5089045600106612    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1651   score: 3.0   memory length: 348237   epsilon: 0.5084867800106703    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1652   score: 4.0   memory length: 348495   epsilon: 0.5079759400106814    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1653   score: 3.0   memory length: 348724   epsilon: 0.5075225200106912    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1654   score: 7.0   memory length: 349119   epsilon: 0.5067404200107082    steps: 395    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1655   score: 3.0   memory length: 349329   epsilon: 0.5063246200107172    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1656   score: 7.0   memory length: 349754   epsilon: 0.5054831200107355    steps: 425    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1657   score: 3.0   memory length: 350019   epsilon: 0.5049584200107469    steps: 265    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1658   score: 3.0   memory length: 350267   epsilon: 0.5044673800107575    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 4.24\n",
      "episode: 1659   score: 3.0   memory length: 350478   epsilon: 0.5040496000107666    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1660   score: 5.0   memory length: 350806   epsilon: 0.5034001600107807    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1661   score: 3.0   memory length: 351036   epsilon: 0.5029447600107906    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1662   score: 5.0   memory length: 351376   epsilon: 0.5022715600108052    steps: 340    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1663   score: 3.0   memory length: 351602   epsilon: 0.5018240800108149    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1664   score: 4.0   memory length: 351842   epsilon: 0.5013488800108252    steps: 240    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1665   score: 2.0   memory length: 352040   epsilon: 0.5009568400108337    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1666   score: 3.0   memory length: 352251   epsilon: 0.5005390600108428    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1667   score: 4.0   memory length: 352526   epsilon: 0.49999456001085446    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n",
      "episode: 1668   score: 3.0   memory length: 352756   epsilon: 0.4995391600108516    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1669   score: 3.0   memory length: 352982   epsilon: 0.49909168001084875    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1670   score: 4.0   memory length: 353260   epsilon: 0.49854124001084527    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1671   score: 4.0   memory length: 353521   epsilon: 0.498024460010842    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1672   score: 2.0   memory length: 353703   epsilon: 0.4976641000108397    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1673   score: 5.0   memory length: 354010   epsilon: 0.49705624001083587    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1674   score: 2.0   memory length: 354207   epsilon: 0.4966661800108334    steps: 197    lr: 1.6000000000000003e-05     evaluation reward: 4.04\n",
      "episode: 1675   score: 5.0   memory length: 354495   epsilon: 0.4960959400108298    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1676   score: 4.0   memory length: 354753   epsilon: 0.49558510001082656    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1677   score: 6.0   memory length: 355113   epsilon: 0.49487230001082205    steps: 360    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1678   score: 5.0   memory length: 355399   epsilon: 0.49430602001081847    steps: 286    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1679   score: 3.0   memory length: 355628   epsilon: 0.4938526000108156    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1680   score: 6.0   memory length: 355983   epsilon: 0.49314970001081115    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n",
      "episode: 1681   score: 3.0   memory length: 356213   epsilon: 0.4926943000108083    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n",
      "episode: 1682   score: 4.0   memory length: 356490   epsilon: 0.4921458400108048    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n",
      "episode: 1683   score: 6.0   memory length: 356848   epsilon: 0.4914370000108003    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n",
      "episode: 1684   score: 3.0   memory length: 357079   epsilon: 0.4909796200107974    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1685   score: 4.0   memory length: 357336   epsilon: 0.4904707600107942    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n",
      "episode: 1686   score: 4.0   memory length: 357596   epsilon: 0.48995596001079095    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1687   score: 3.0   memory length: 357809   epsilon: 0.4895342200107883    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1688   score: 2.0   memory length: 357991   epsilon: 0.489173860010786    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1689   score: 3.0   memory length: 358219   epsilon: 0.48872242001078314    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1690   score: 2.0   memory length: 358417   epsilon: 0.48833038001078066    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1691   score: 5.0   memory length: 358713   epsilon: 0.48774430001077695    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1692   score: 1.0   memory length: 358883   epsilon: 0.4874077000107748    steps: 170    lr: 1.6000000000000003e-05     evaluation reward: 4.05\n",
      "episode: 1693   score: 6.0   memory length: 359217   epsilon: 0.48674638001077064    steps: 334    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1694   score: 6.0   memory length: 359600   epsilon: 0.48598804001076584    steps: 383    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1695   score: 3.0   memory length: 359829   epsilon: 0.485534620010763    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1696   score: 3.0   memory length: 360056   epsilon: 0.48508516001076013    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1697   score: 4.0   memory length: 360333   epsilon: 0.48453670001075666    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1698   score: 3.0   memory length: 360546   epsilon: 0.484114960010754    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1699   score: 6.0   memory length: 360906   epsilon: 0.4834021600107495    steps: 360    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1700   score: 4.0   memory length: 361181   epsilon: 0.48285766001074604    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.05\n",
      "episode: 1701   score: 2.0   memory length: 361363   epsilon: 0.48249730001074376    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n",
      "episode: 1702   score: 3.0   memory length: 361591   epsilon: 0.4820458600107409    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n",
      "episode: 1703   score: 5.0   memory length: 361899   epsilon: 0.48143602001073704    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n",
      "episode: 1704   score: 7.0   memory length: 362309   epsilon: 0.4806242200107319    steps: 410    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1705   score: 6.0   memory length: 362680   epsilon: 0.47988964001072726    steps: 371    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1706   score: 5.0   memory length: 362985   epsilon: 0.47928574001072344    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1707   score: 4.0   memory length: 363280   epsilon: 0.47870164001071974    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1708   score: 4.0   memory length: 363556   epsilon: 0.4781551600107163    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1709   score: 4.0   memory length: 363815   epsilon: 0.47764234001071304    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1710   score: 4.0   memory length: 364111   epsilon: 0.47705626001070933    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1711   score: 5.0   memory length: 364419   epsilon: 0.4764464200107055    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1712   score: 3.0   memory length: 364665   epsilon: 0.4759593400107024    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1713   score: 4.0   memory length: 364924   epsilon: 0.47544652001069915    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1714   score: 4.0   memory length: 365177   epsilon: 0.474945580010696    steps: 253    lr: 1.6000000000000003e-05     evaluation reward: 4.05\n",
      "episode: 1715   score: 4.0   memory length: 365419   epsilon: 0.47446642001069295    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.03\n",
      "episode: 1716   score: 3.0   memory length: 365649   epsilon: 0.47401102001069007    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.03\n",
      "episode: 1717   score: 3.0   memory length: 365877   epsilon: 0.4735595800106872    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.03\n",
      "episode: 1718   score: 5.0   memory length: 366184   epsilon: 0.47295172001068336    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1719   score: 4.0   memory length: 366460   epsilon: 0.4724052400106799    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1720   score: 5.0   memory length: 366786   epsilon: 0.4717597600106758    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1721   score: 5.0   memory length: 367095   epsilon: 0.47114794001067195    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1722   score: 6.0   memory length: 367491   epsilon: 0.470363860010667    steps: 396    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1723   score: 4.0   memory length: 367733   epsilon: 0.46988470001066396    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n",
      "episode: 1724   score: 5.0   memory length: 368059   epsilon: 0.4692392200106599    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1725   score: 7.0   memory length: 368448   epsilon: 0.468469000010655    steps: 389    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n",
      "episode: 1726   score: 5.0   memory length: 368773   epsilon: 0.46782550001065093    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n",
      "episode: 1727   score: 5.0   memory length: 369100   epsilon: 0.46717804001064683    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1728   score: 3.0   memory length: 369330   epsilon: 0.46672264001064395    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n",
      "episode: 1729   score: 1.0   memory length: 369502   epsilon: 0.4663820800106418    steps: 172    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1730   score: 6.0   memory length: 369812   epsilon: 0.4657682800106379    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1731   score: 3.0   memory length: 370058   epsilon: 0.46528120001063483    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1732   score: 3.0   memory length: 370271   epsilon: 0.46485946001063216    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1733   score: 4.0   memory length: 370532   epsilon: 0.4643426800106289    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1734   score: 4.0   memory length: 370810   epsilon: 0.4637922400106254    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1735   score: 4.0   memory length: 371068   epsilon: 0.4632814000106222    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1736   score: 3.0   memory length: 371296   epsilon: 0.4628299600106193    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1737   score: 3.0   memory length: 371525   epsilon: 0.46237654001061645    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.03\n",
      "episode: 1738   score: 1.0   memory length: 371695   epsilon: 0.4620399400106143    steps: 170    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n",
      "episode: 1739   score: 2.0   memory length: 371877   epsilon: 0.46167958001061205    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.01\n",
      "episode: 1740   score: 2.0   memory length: 372059   epsilon: 0.46131922001060977    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.98\n",
      "episode: 1741   score: 3.0   memory length: 372290   epsilon: 0.46086184001060687    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 3.98\n",
      "episode: 1742   score: 3.0   memory length: 372519   epsilon: 0.460408420010604    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.95\n",
      "episode: 1743   score: 3.0   memory length: 372732   epsilon: 0.45998668001060133    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.92\n",
      "episode: 1744   score: 7.0   memory length: 373138   epsilon: 0.45918280001059625    steps: 406    lr: 1.6000000000000003e-05     evaluation reward: 3.91\n",
      "episode: 1745   score: 3.0   memory length: 373364   epsilon: 0.4587353200105934    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.89\n",
      "episode: 1746   score: 5.0   memory length: 373691   epsilon: 0.4580878600105893    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 3.91\n",
      "episode: 1747   score: 2.0   memory length: 373873   epsilon: 0.45772750001058704    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.87\n",
      "episode: 1748   score: 5.0   memory length: 374196   epsilon: 0.457087960010583    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 3.88\n",
      "episode: 1749   score: 5.0   memory length: 374488   epsilon: 0.45650980001057934    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 3.91\n",
      "episode: 1750   score: 7.0   memory length: 374909   epsilon: 0.45567622001057406    steps: 421    lr: 1.6000000000000003e-05     evaluation reward: 3.95\n",
      "episode: 1751   score: 4.0   memory length: 375168   epsilon: 0.4551634000105708    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n",
      "episode: 1752   score: 5.0   memory length: 375474   epsilon: 0.454557520010567    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1753   score: 1.0   memory length: 375625   epsilon: 0.4542585400105651    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.95\n",
      "episode: 1754   score: 4.0   memory length: 375876   epsilon: 0.45376156001056195    steps: 251    lr: 1.6000000000000003e-05     evaluation reward: 3.92\n",
      "episode: 1755   score: 4.0   memory length: 376134   epsilon: 0.4532507200105587    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 3.93\n",
      "episode: 1756   score: 7.0   memory length: 376517   epsilon: 0.4524923800105539    steps: 383    lr: 1.6000000000000003e-05     evaluation reward: 3.93\n",
      "episode: 1757   score: 5.0   memory length: 376825   epsilon: 0.45188254001055006    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 3.95\n",
      "episode: 1758   score: 5.0   memory length: 377136   epsilon: 0.45126676001054616    steps: 311    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1759   score: 3.0   memory length: 377346   epsilon: 0.45085096001054353    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1760   score: 4.0   memory length: 377605   epsilon: 0.4503381400105403    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n",
      "episode: 1761   score: 4.0   memory length: 377882   epsilon: 0.4497896800105368    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1762   score: 5.0   memory length: 378170   epsilon: 0.4492194400105332    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1763   score: 3.0   memory length: 378379   epsilon: 0.4488056200105306    steps: 209    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1764   score: 5.0   memory length: 378728   epsilon: 0.4481146000105262    steps: 349    lr: 1.6000000000000003e-05     evaluation reward: 3.98\n",
      "episode: 1765   score: 3.0   memory length: 378941   epsilon: 0.44769286001052355    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.99\n",
      "episode: 1766   score: 13.0   memory length: 379480   epsilon: 0.4466256400105168    steps: 539    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1767   score: 8.0   memory length: 379863   epsilon: 0.445867300010512    steps: 383    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n",
      "episode: 1768   score: 5.0   memory length: 380154   epsilon: 0.44529112001050836    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1769   score: 3.0   memory length: 380385   epsilon: 0.44483374001050546    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1770   score: 5.0   memory length: 380658   epsilon: 0.44429320001050204    steps: 273    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n",
      "episode: 1771   score: 4.0   memory length: 380915   epsilon: 0.4437843400104988    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n",
      "episode: 1772   score: 6.0   memory length: 381250   epsilon: 0.4431210400104946    steps: 335    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1773   score: 5.0   memory length: 381596   epsilon: 0.4424359600104903    steps: 346    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1774   score: 5.0   memory length: 381877   epsilon: 0.44187958001048677    steps: 281    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1775   score: 5.0   memory length: 382185   epsilon: 0.4412697400104829    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1776   score: 4.0   memory length: 382481   epsilon: 0.4406836600104792    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1777   score: 5.0   memory length: 382828   epsilon: 0.43999660001047486    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1778   score: 5.0   memory length: 383118   epsilon: 0.4394224000104712    steps: 290    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1779   score: 3.0   memory length: 383348   epsilon: 0.43896700001046834    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1780   score: 6.0   memory length: 383693   epsilon: 0.438283900010464    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1781   score: 6.0   memory length: 384049   epsilon: 0.43757902001045956    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1782   score: 6.0   memory length: 384402   epsilon: 0.43688008001045514    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1783   score: 3.0   memory length: 384632   epsilon: 0.43642468001045226    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.24\n",
      "episode: 1784   score: 6.0   memory length: 384990   epsilon: 0.4357158400104478    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1785   score: 3.0   memory length: 385203   epsilon: 0.4352941000104451    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1786   score: 5.0   memory length: 385527   epsilon: 0.43465258001044105    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1787   score: 6.0   memory length: 385884   epsilon: 0.4339457200104366    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1788   score: 4.0   memory length: 386144   epsilon: 0.4334309200104333    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1789   score: 10.0   memory length: 386681   epsilon: 0.4323676600104266    steps: 537    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n",
      "episode: 1790   score: 3.0   memory length: 386910   epsilon: 0.4319142400104237    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.4\n",
      "episode: 1791   score: 4.0   memory length: 387150   epsilon: 0.4314390400104207    steps: 240    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n",
      "episode: 1792   score: 6.0   memory length: 387468   epsilon: 0.43080940001041673    steps: 318    lr: 1.6000000000000003e-05     evaluation reward: 4.44\n",
      "episode: 1793   score: 1.0   memory length: 387639   epsilon: 0.4304708200104146    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n",
      "episode: 1794   score: 6.0   memory length: 387975   epsilon: 0.4298055400104104    steps: 336    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n",
      "episode: 1795   score: 6.0   memory length: 388312   epsilon: 0.42913828001040616    steps: 337    lr: 1.6000000000000003e-05     evaluation reward: 4.42\n",
      "episode: 1796   score: 4.0   memory length: 388554   epsilon: 0.4286591200104031    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.43\n",
      "episode: 1797   score: 4.0   memory length: 388811   epsilon: 0.4281502600103999    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 4.43\n",
      "episode: 1798   score: 3.0   memory length: 389040   epsilon: 0.42769684001039704    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.43\n",
      "episode: 1799   score: 5.0   memory length: 389348   epsilon: 0.4270870000103932    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.42\n",
      "episode: 1800   score: 4.0   memory length: 389607   epsilon: 0.42657418001038994    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.42\n",
      "episode: 1801   score: 5.0   memory length: 389910   epsilon: 0.42597424001038614    steps: 303    lr: 1.6000000000000003e-05     evaluation reward: 4.45\n",
      "episode: 1802   score: 6.0   memory length: 390274   epsilon: 0.4252535200103816    steps: 364    lr: 1.6000000000000003e-05     evaluation reward: 4.48\n",
      "episode: 1803   score: 4.0   memory length: 390552   epsilon: 0.4247030800103781    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.47\n",
      "episode: 1804   score: 3.0   memory length: 390799   epsilon: 0.424214020010375    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.43\n",
      "episode: 1805   score: 7.0   memory length: 391164   epsilon: 0.42349132001037043    steps: 365    lr: 1.6000000000000003e-05     evaluation reward: 4.44\n",
      "episode: 1806   score: 6.0   memory length: 391519   epsilon: 0.422788420010366    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 4.45\n",
      "episode: 1807   score: 3.0   memory length: 391748   epsilon: 0.4223350000103631    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.44\n",
      "episode: 1808   score: 5.0   memory length: 392053   epsilon: 0.4217311000103593    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 4.45\n",
      "episode: 1809   score: 3.0   memory length: 392298   epsilon: 0.4212460000103562    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 4.44\n",
      "episode: 1810   score: 5.0   memory length: 392565   epsilon: 0.4207173400103529    steps: 267    lr: 1.6000000000000003e-05     evaluation reward: 4.45\n",
      "episode: 1811   score: 7.0   memory length: 392989   epsilon: 0.41987782001034757    steps: 424    lr: 1.6000000000000003e-05     evaluation reward: 4.47\n",
      "episode: 1812   score: 4.0   memory length: 393286   epsilon: 0.41928976001034385    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 4.48\n",
      "episode: 1813   score: 3.0   memory length: 393515   epsilon: 0.418836340010341    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.47\n",
      "episode: 1814   score: 6.0   memory length: 393909   epsilon: 0.41805622001033604    steps: 394    lr: 1.6000000000000003e-05     evaluation reward: 4.49\n",
      "episode: 1815   score: 5.0   memory length: 394198   epsilon: 0.4174840000103324    steps: 289    lr: 1.6000000000000003e-05     evaluation reward: 4.5\n",
      "episode: 1816   score: 4.0   memory length: 394471   epsilon: 0.416943460010329    steps: 273    lr: 1.6000000000000003e-05     evaluation reward: 4.51\n",
      "episode: 1817   score: 4.0   memory length: 394712   epsilon: 0.416466280010326    steps: 241    lr: 1.6000000000000003e-05     evaluation reward: 4.52\n",
      "episode: 1818   score: 4.0   memory length: 394970   epsilon: 0.41595544001032275    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.51\n",
      "episode: 1819   score: 4.0   memory length: 395245   epsilon: 0.4154109400103193    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.51\n",
      "episode: 1820   score: 6.0   memory length: 395583   epsilon: 0.4147417000103151    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 4.52\n",
      "episode: 1821   score: 3.0   memory length: 395851   epsilon: 0.4142110600103117    steps: 268    lr: 1.6000000000000003e-05     evaluation reward: 4.5\n",
      "episode: 1822   score: 4.0   memory length: 396128   epsilon: 0.41366260001030825    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.48\n",
      "episode: 1823   score: 7.0   memory length: 396518   epsilon: 0.41289040001030336    steps: 390    lr: 1.6000000000000003e-05     evaluation reward: 4.51\n",
      "episode: 1824   score: 6.0   memory length: 396890   epsilon: 0.4121538400102987    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 4.52\n",
      "episode: 1825   score: 5.0   memory length: 397217   epsilon: 0.4115063800102946    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 4.5\n",
      "episode: 1826   score: 3.0   memory length: 397445   epsilon: 0.41105494001029175    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.48\n",
      "episode: 1827   score: 6.0   memory length: 397823   epsilon: 0.410306500010287    steps: 378    lr: 1.6000000000000003e-05     evaluation reward: 4.49\n",
      "episode: 1828   score: 2.0   memory length: 398023   epsilon: 0.4099105000102845    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.48\n",
      "episode: 1829   score: 6.0   memory length: 398398   epsilon: 0.4091680000102798    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 4.53\n",
      "episode: 1830   score: 3.0   memory length: 398626   epsilon: 0.40871656001027695    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.5\n",
      "episode: 1831   score: 3.0   memory length: 398855   epsilon: 0.4082631400102741    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.5\n",
      "episode: 1832   score: 6.0   memory length: 399195   epsilon: 0.4075899400102698    steps: 340    lr: 1.6000000000000003e-05     evaluation reward: 4.53\n",
      "episode: 1833   score: 4.0   memory length: 399456   epsilon: 0.40707316001026655    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 4.53\n",
      "episode: 1834   score: 4.0   memory length: 399716   epsilon: 0.4065583600102633    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.53\n",
      "episode: 1835   score: 5.0   memory length: 400058   epsilon: 0.405881200010259    steps: 342    lr: 6.400000000000001e-06     evaluation reward: 4.54\n",
      "episode: 1836   score: 6.0   memory length: 400402   epsilon: 0.4052000800102547    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 4.57\n",
      "episode: 1837   score: 3.0   memory length: 400632   epsilon: 0.4047446800102518    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.57\n",
      "episode: 1838   score: 5.0   memory length: 400957   epsilon: 0.40410118001024775    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.61\n",
      "episode: 1839   score: 4.0   memory length: 401236   epsilon: 0.40354876001024426    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 4.63\n",
      "episode: 1840   score: 11.0   memory length: 401745   epsilon: 0.4025409400102379    steps: 509    lr: 6.400000000000001e-06     evaluation reward: 4.72\n",
      "episode: 1841   score: 3.0   memory length: 401975   epsilon: 0.402085540010235    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.72\n",
      "episode: 1842   score: 4.0   memory length: 402259   epsilon: 0.40152322001023144    steps: 284    lr: 6.400000000000001e-06     evaluation reward: 4.73\n",
      "episode: 1843   score: 5.0   memory length: 402584   epsilon: 0.40087972001022737    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.75\n",
      "episode: 1844   score: 7.0   memory length: 402924   epsilon: 0.4002065200102231    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 4.75\n",
      "episode: 1845   score: 4.0   memory length: 403202   epsilon: 0.3996560800102196    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 4.76\n",
      "episode: 1846   score: 4.0   memory length: 403480   epsilon: 0.39910564001021614    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 4.75\n",
      "episode: 1847   score: 4.0   memory length: 403776   epsilon: 0.39851956001021244    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 4.77\n",
      "episode: 1848   score: 5.0   memory length: 404085   epsilon: 0.39790774001020857    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 4.77\n",
      "episode: 1849   score: 5.0   memory length: 404374   epsilon: 0.39733552001020495    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 4.77\n",
      "episode: 1850   score: 5.0   memory length: 404681   epsilon: 0.3967276600102011    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 4.75\n",
      "episode: 1851   score: 6.0   memory length: 405016   epsilon: 0.3960643600101969    steps: 335    lr: 6.400000000000001e-06     evaluation reward: 4.77\n",
      "episode: 1852   score: 5.0   memory length: 405306   epsilon: 0.39549016001019327    steps: 290    lr: 6.400000000000001e-06     evaluation reward: 4.77\n",
      "episode: 1853   score: 6.0   memory length: 405661   epsilon: 0.3947872600101888    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1854   score: 4.0   memory length: 405920   epsilon: 0.3942744400101856    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1855   score: 4.0   memory length: 406175   epsilon: 0.3937695400101824    steps: 255    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1856   score: 5.0   memory length: 406479   epsilon: 0.3931676200101786    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 4.8\n",
      "episode: 1857   score: 5.0   memory length: 406802   epsilon: 0.39252808001017453    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 4.8\n",
      "episode: 1858   score: 5.0   memory length: 407075   epsilon: 0.3919875400101711    steps: 273    lr: 6.400000000000001e-06     evaluation reward: 4.8\n",
      "episode: 1859   score: 4.0   memory length: 407356   epsilon: 0.3914311600101676    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 4.81\n",
      "episode: 1860   score: 5.0   memory length: 407680   epsilon: 0.39078964001016353    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1861   score: 4.0   memory length: 407957   epsilon: 0.39024118001016006    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1862   score: 6.0   memory length: 408311   epsilon: 0.3895402600101556    steps: 354    lr: 6.400000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1863   score: 3.0   memory length: 408539   epsilon: 0.38908882001015277    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1864   score: 3.0   memory length: 408769   epsilon: 0.3886334200101499    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.81\n",
      "episode: 1865   score: 6.0   memory length: 409123   epsilon: 0.38793250001014545    steps: 354    lr: 6.400000000000001e-06     evaluation reward: 4.84\n",
      "episode: 1866   score: 3.0   memory length: 409352   epsilon: 0.3874790800101426    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.74\n",
      "episode: 1867   score: 6.0   memory length: 409695   epsilon: 0.3867999400101383    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 4.72\n",
      "episode: 1868   score: 4.0   memory length: 409971   epsilon: 0.38625346001013483    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.71\n",
      "episode: 1869   score: 4.0   memory length: 410246   epsilon: 0.3857089600101314    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 4.72\n",
      "episode: 1870   score: 6.0   memory length: 410610   epsilon: 0.3849882400101268    steps: 364    lr: 6.400000000000001e-06     evaluation reward: 4.73\n",
      "episode: 1871   score: 4.0   memory length: 410904   epsilon: 0.38440612001012314    steps: 294    lr: 6.400000000000001e-06     evaluation reward: 4.73\n",
      "episode: 1872   score: 2.0   memory length: 411086   epsilon: 0.38404576001012086    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.69\n",
      "episode: 1873   score: 8.0   memory length: 411508   epsilon: 0.3832102000101156    steps: 422    lr: 6.400000000000001e-06     evaluation reward: 4.72\n",
      "episode: 1874   score: 11.0   memory length: 411955   epsilon: 0.38232514001011    steps: 447    lr: 6.400000000000001e-06     evaluation reward: 4.78\n",
      "episode: 1875   score: 3.0   memory length: 412184   epsilon: 0.3818717200101071    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.76\n",
      "episode: 1876   score: 3.0   memory length: 412414   epsilon: 0.3814163200101042    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.75\n",
      "episode: 1877   score: 5.0   memory length: 412726   epsilon: 0.3807985600101003    steps: 312    lr: 6.400000000000001e-06     evaluation reward: 4.75\n",
      "episode: 1878   score: 5.0   memory length: 413035   epsilon: 0.38018674001009645    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 4.75\n",
      "episode: 1879   score: 4.0   memory length: 413276   epsilon: 0.3797095600100934    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.76\n",
      "episode: 1880   score: 6.0   memory length: 413632   epsilon: 0.37900468001008897    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 4.76\n",
      "episode: 1881   score: 5.0   memory length: 413923   epsilon: 0.3784285000100853    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 4.75\n",
      "episode: 1882   score: 4.0   memory length: 414164   epsilon: 0.3779513200100823    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.73\n",
      "episode: 1883   score: 5.0   memory length: 414489   epsilon: 0.37730782001007823    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.75\n",
      "episode: 1884   score: 4.0   memory length: 414731   epsilon: 0.3768286600100752    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.73\n",
      "episode: 1885   score: 4.0   memory length: 414972   epsilon: 0.3763514800100722    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.74\n",
      "episode: 1886   score: 4.0   memory length: 415213   epsilon: 0.37587430001006916    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.73\n",
      "episode: 1887   score: 4.0   memory length: 415490   epsilon: 0.3753258400100657    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.71\n",
      "episode: 1888   score: 3.0   memory length: 415721   epsilon: 0.3748684600100628    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.7\n",
      "episode: 1889   score: 6.0   memory length: 416071   epsilon: 0.3741754600100584    steps: 350    lr: 6.400000000000001e-06     evaluation reward: 4.66\n",
      "episode: 1890   score: 5.0   memory length: 416359   epsilon: 0.3736052200100548    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 4.68\n",
      "episode: 1891   score: 4.0   memory length: 416636   epsilon: 0.37305676001005134    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.68\n",
      "episode: 1892   score: 8.0   memory length: 417111   epsilon: 0.3721162600100454    steps: 475    lr: 6.400000000000001e-06     evaluation reward: 4.7\n",
      "episode: 1893   score: 9.0   memory length: 417457   epsilon: 0.37143118001004105    steps: 346    lr: 6.400000000000001e-06     evaluation reward: 4.78\n",
      "episode: 1894   score: 5.0   memory length: 417781   epsilon: 0.370789660010037    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 4.77\n",
      "episode: 1895   score: 7.0   memory length: 418165   epsilon: 0.3700293400100322    steps: 384    lr: 6.400000000000001e-06     evaluation reward: 4.78\n",
      "episode: 1896   score: 5.0   memory length: 418471   epsilon: 0.36942346001002835    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 4.79\n",
      "episode: 1897   score: 5.0   memory length: 418785   epsilon: 0.3688017400100244    steps: 314    lr: 6.400000000000001e-06     evaluation reward: 4.8\n",
      "episode: 1898   score: 5.0   memory length: 419066   epsilon: 0.3682453600100209    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1899   score: 6.0   memory length: 419421   epsilon: 0.36754246001001645    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1900   score: 4.0   memory length: 419721   epsilon: 0.3669484600100127    steps: 300    lr: 6.400000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1901   score: 3.0   memory length: 419968   epsilon: 0.3664594000100096    steps: 247    lr: 6.400000000000001e-06     evaluation reward: 4.81\n",
      "episode: 1902   score: 3.0   memory length: 420180   epsilon: 0.36603964001000694    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 4.78\n",
      "episode: 1903   score: 4.0   memory length: 420437   epsilon: 0.3655307800100037    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 4.78\n",
      "episode: 1904   score: 5.0   memory length: 420725   epsilon: 0.3649605400100001    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 4.8\n",
      "episode: 1905   score: 4.0   memory length: 420984   epsilon: 0.36444772000999687    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.77\n",
      "episode: 1906   score: 4.0   memory length: 421244   epsilon: 0.3639329200099936    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.75\n",
      "episode: 1907   score: 4.0   memory length: 421485   epsilon: 0.3634557400099906    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.76\n",
      "episode: 1908   score: 8.0   memory length: 421908   epsilon: 0.3626182000099853    steps: 423    lr: 6.400000000000001e-06     evaluation reward: 4.79\n",
      "episode: 1909   score: 5.0   memory length: 422213   epsilon: 0.36201430000998147    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 4.81\n",
      "episode: 1910   score: 6.0   memory length: 422565   epsilon: 0.36131734000997706    steps: 352    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1911   score: 6.0   memory length: 422901   epsilon: 0.36065206000997285    steps: 336    lr: 6.400000000000001e-06     evaluation reward: 4.81\n",
      "episode: 1912   score: 9.0   memory length: 423260   epsilon: 0.35994124000996836    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1913   score: 3.0   memory length: 423491   epsilon: 0.35948386000996546    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1914   score: 3.0   memory length: 423700   epsilon: 0.35907004000996284    steps: 209    lr: 6.400000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1915   score: 3.0   memory length: 423912   epsilon: 0.3586502800099602    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 4.81\n",
      "episode: 1916   score: 3.0   memory length: 424139   epsilon: 0.35820082000995734    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.8\n",
      "episode: 1917   score: 5.0   memory length: 424448   epsilon: 0.3575890000099535    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 4.81\n",
      "episode: 1918   score: 7.0   memory length: 424839   epsilon: 0.3568148200099486    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 4.84\n",
      "episode: 1919   score: 3.0   memory length: 425084   epsilon: 0.3563297200099455    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1920   score: 6.0   memory length: 425442   epsilon: 0.355620880009941    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1921   score: 4.0   memory length: 425740   epsilon: 0.3550308400099373    steps: 298    lr: 6.400000000000001e-06     evaluation reward: 4.84\n",
      "episode: 1922   score: 6.0   memory length: 426058   epsilon: 0.3544012000099333    steps: 318    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1923   score: 8.0   memory length: 426501   epsilon: 0.35352406000992775    steps: 443    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 1924   score: 5.0   memory length: 426815   epsilon: 0.3529023400099238    steps: 314    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1925   score: 5.0   memory length: 427088   epsilon: 0.3523618000099204    steps: 273    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1926   score: 5.0   memory length: 427398   epsilon: 0.3517480000099165    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 1927   score: 3.0   memory length: 427628   epsilon: 0.35129260000991364    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 1928   score: 4.0   memory length: 427905   epsilon: 0.35074414000991017    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 1929   score: 3.0   memory length: 428118   epsilon: 0.3503224000099075    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.84\n",
      "episode: 1930   score: 6.0   memory length: 428458   epsilon: 0.34964920000990324    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 1931   score: 11.0   memory length: 429010   epsilon: 0.3485562400098963    steps: 552    lr: 6.400000000000001e-06     evaluation reward: 4.95\n",
      "episode: 1932   score: 6.0   memory length: 429385   epsilon: 0.3478137400098916    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 4.95\n",
      "episode: 1933   score: 3.0   memory length: 429631   epsilon: 0.34732666000988854    steps: 246    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 1934   score: 5.0   memory length: 429938   epsilon: 0.3467188000098847    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 4.95\n",
      "episode: 1935   score: 4.0   memory length: 430195   epsilon: 0.3462099400098815    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 1936   score: 6.0   memory length: 430555   epsilon: 0.34549714000987697    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 1937   score: 6.0   memory length: 430889   epsilon: 0.3448358200098728    steps: 334    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 1938   score: 3.0   memory length: 431118   epsilon: 0.3443824000098699    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.95\n",
      "episode: 1939   score: 5.0   memory length: 431421   epsilon: 0.3437824600098661    steps: 303    lr: 6.400000000000001e-06     evaluation reward: 4.96\n",
      "episode: 1940   score: 5.0   memory length: 431748   epsilon: 0.343135000009862    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 1941   score: 5.0   memory length: 432078   epsilon: 0.3424816000098579    steps: 330    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 1942   score: 4.0   memory length: 432320   epsilon: 0.34200244000985486    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 1943   score: 3.0   memory length: 432569   epsilon: 0.34150942000985174    steps: 249    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 1944   score: 3.0   memory length: 432818   epsilon: 0.3410164000098486    steps: 249    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1945   score: 4.0   memory length: 433116   epsilon: 0.3404263600098449    steps: 298    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1946   score: 6.0   memory length: 433490   epsilon: 0.3396858400098402    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 1947   score: 5.0   memory length: 433827   epsilon: 0.339018580009836    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 1948   score: 4.0   memory length: 434067   epsilon: 0.338543380009833    steps: 240    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 1949   score: 6.0   memory length: 434406   epsilon: 0.3378721600098287    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 1950   score: 3.0   memory length: 434652   epsilon: 0.33738508000982564    steps: 246    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 1951   score: 5.0   memory length: 434982   epsilon: 0.3367316800098215    steps: 330    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1952   score: 5.0   memory length: 435315   epsilon: 0.33607234000981734    steps: 333    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1953   score: 4.0   memory length: 435556   epsilon: 0.3355951600098143    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.84\n",
      "episode: 1954   score: 8.0   memory length: 435977   epsilon: 0.33476158000980905    steps: 421    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 1955   score: 3.0   memory length: 436207   epsilon: 0.33430618000980616    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 1956   score: 8.0   memory length: 436663   epsilon: 0.33340330000980045    steps: 456    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 1957   score: 4.0   memory length: 436950   epsilon: 0.33283504000979686    steps: 287    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 1958   score: 4.0   memory length: 437229   epsilon: 0.33228262000979336    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 1959   score: 8.0   memory length: 437648   epsilon: 0.3314530000097881    steps: 419    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 1960   score: 3.0   memory length: 437861   epsilon: 0.33103126000978544    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 1961   score: 3.0   memory length: 438091   epsilon: 0.33057586000978256    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 1962   score: 4.0   memory length: 438332   epsilon: 0.33009868000977954    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 1963   score: 4.0   memory length: 438592   epsilon: 0.3295838800097763    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 1964   score: 4.0   memory length: 438851   epsilon: 0.32907106000977304    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 1965   score: 6.0   memory length: 439226   epsilon: 0.32832856000976834    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 1966   score: 6.0   memory length: 439605   epsilon: 0.3275781400097636    steps: 379    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 1967   score: 5.0   memory length: 439932   epsilon: 0.3269306800097595    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 1968   score: 5.0   memory length: 440259   epsilon: 0.3262832200097554    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 1969   score: 6.0   memory length: 440584   epsilon: 0.32563972000975133    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 1970   score: 5.0   memory length: 440889   epsilon: 0.3250358200097475    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 1971   score: 7.0   memory length: 441256   epsilon: 0.3243091600097429    steps: 367    lr: 6.400000000000001e-06     evaluation reward: 4.96\n",
      "episode: 1972   score: 3.0   memory length: 441486   epsilon: 0.32385376000974003    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 1973   score: 8.0   memory length: 441900   epsilon: 0.32303404000973485    steps: 414    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 1974   score: 5.0   memory length: 442188   epsilon: 0.32246380000973124    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 1975   score: 4.0   memory length: 442446   epsilon: 0.321952960009728    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 1976   score: 6.0   memory length: 442805   epsilon: 0.3212421400097235    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 4.95\n",
      "episode: 1977   score: 4.0   memory length: 443066   epsilon: 0.32072536000972024    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 1978   score: 6.0   memory length: 443402   epsilon: 0.32006008000971603    steps: 336    lr: 6.400000000000001e-06     evaluation reward: 4.95\n",
      "episode: 1979   score: 6.0   memory length: 443778   epsilon: 0.3193156000097113    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 1980   score: 4.0   memory length: 444035   epsilon: 0.3188067400097081    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 4.95\n",
      "episode: 1981   score: 7.0   memory length: 444403   epsilon: 0.3180781000097035    steps: 368    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 1982   score: 8.0   memory length: 444802   epsilon: 0.3172880800096985    steps: 399    lr: 6.400000000000001e-06     evaluation reward: 5.01\n",
      "episode: 1983   score: 5.0   memory length: 445131   epsilon: 0.31663666000969437    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 5.01\n",
      "episode: 1984   score: 6.0   memory length: 445484   epsilon: 0.31593772000968995    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 5.03\n",
      "episode: 1985   score: 5.0   memory length: 445808   epsilon: 0.3152962000096859    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 5.04\n",
      "episode: 1986   score: 3.0   memory length: 446020   epsilon: 0.31487644000968323    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 5.03\n",
      "episode: 1987   score: 3.0   memory length: 446251   epsilon: 0.31441906000968034    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 5.02\n",
      "episode: 1988   score: 4.0   memory length: 446491   epsilon: 0.31394386000967733    steps: 240    lr: 6.400000000000001e-06     evaluation reward: 5.03\n",
      "episode: 1989   score: 4.0   memory length: 446749   epsilon: 0.3134330200096741    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 5.01\n",
      "episode: 1990   score: 5.0   memory length: 447065   epsilon: 0.31280734000967014    steps: 316    lr: 6.400000000000001e-06     evaluation reward: 5.01\n",
      "episode: 1991   score: 4.0   memory length: 447322   epsilon: 0.3122984800096669    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 5.01\n",
      "episode: 1992   score: 7.0   memory length: 447706   epsilon: 0.3115381600096621    steps: 384    lr: 6.400000000000001e-06     evaluation reward: 5.0\n",
      "episode: 1993   score: 3.0   memory length: 447935   epsilon: 0.31108474000965924    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 1994   score: 8.0   memory length: 448355   epsilon: 0.310253140009654    steps: 420    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 1995   score: 3.0   memory length: 448568   epsilon: 0.3098314000096513    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 1996   score: 4.0   memory length: 448848   epsilon: 0.3092770000096478    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 1997   score: 3.0   memory length: 449077   epsilon: 0.30882358000964494    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 1998   score: 3.0   memory length: 449287   epsilon: 0.3084077800096423    steps: 210    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 1999   score: 3.0   memory length: 449516   epsilon: 0.30795436000963944    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 2000   score: 4.0   memory length: 449793   epsilon: 0.30740590000963597    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 2001   score: 5.0   memory length: 450094   epsilon: 0.3068099200096322    steps: 301    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 2002   score: 7.0   memory length: 450464   epsilon: 0.30607732000962756    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 2003   score: 5.0   memory length: 450793   epsilon: 0.30542590000962344    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 2004   score: 4.0   memory length: 451072   epsilon: 0.30487348000961995    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 2005   score: 5.0   memory length: 451396   epsilon: 0.3042319600096159    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 2006   score: 5.0   memory length: 451700   epsilon: 0.3036300400096121    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2007   score: 4.0   memory length: 451960   epsilon: 0.3031152400096088    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2008   score: 3.0   memory length: 452189   epsilon: 0.30266182000960595    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 2009   score: 5.0   memory length: 452478   epsilon: 0.30208960000960233    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 2010   score: 5.0   memory length: 452782   epsilon: 0.3014876800095985    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 2011   score: 5.0   memory length: 453112   epsilon: 0.3008342800095944    steps: 330    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2012   score: 6.0   memory length: 453480   epsilon: 0.3001056400095898    steps: 368    lr: 6.400000000000001e-06     evaluation reward: 4.83\n",
      "episode: 2013   score: 5.0   memory length: 453785   epsilon: 0.29950174000958596    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 2014   score: 6.0   memory length: 454137   epsilon: 0.29880478000958155    steps: 352    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 2015   score: 5.0   memory length: 454464   epsilon: 0.29815732000957745    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 2016   score: 6.0   memory length: 454838   epsilon: 0.29741680000957277    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2017   score: 6.0   memory length: 455217   epsilon: 0.296666380009568    steps: 379    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 2018   score: 6.0   memory length: 455554   epsilon: 0.2959991200095638    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2019   score: 4.0   memory length: 455814   epsilon: 0.29548432000956054    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 2020   score: 4.0   memory length: 456091   epsilon: 0.29493586000955707    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 2021   score: 4.0   memory length: 456366   epsilon: 0.2943913600095536    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 2022   score: 4.0   memory length: 456642   epsilon: 0.29384488000955017    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 2023   score: 4.0   memory length: 456901   epsilon: 0.2933320600095469    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2024   score: 9.0   memory length: 457266   epsilon: 0.29260936000954235    steps: 365    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 2025   score: 6.0   memory length: 457602   epsilon: 0.29194408000953814    steps: 336    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 2026   score: 3.0   memory length: 457813   epsilon: 0.2915263000095355    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 2027   score: 6.0   memory length: 458123   epsilon: 0.2909125000095316    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 2028   score: 4.0   memory length: 458364   epsilon: 0.2904353200095286    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 2029   score: 5.0   memory length: 458690   epsilon: 0.2897898400095245    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 2030   score: 3.0   memory length: 458920   epsilon: 0.28933444000952163    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 2031   score: 6.0   memory length: 459224   epsilon: 0.2887325200095178    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2032   score: 4.0   memory length: 459501   epsilon: 0.28818406000951435    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.84\n",
      "episode: 2033   score: 5.0   memory length: 459773   epsilon: 0.28764550000951095    steps: 272    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2034   score: 4.0   memory length: 460033   epsilon: 0.2871307000095077    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 2035   score: 5.0   memory length: 460315   epsilon: 0.28657234000950416    steps: 282    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2036   score: 2.0   memory length: 460515   epsilon: 0.28617634000950165    steps: 200    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 2037   score: 4.0   memory length: 460774   epsilon: 0.2856635200094984    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.8\n",
      "episode: 2038   score: 5.0   memory length: 461062   epsilon: 0.2850932800094948    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 2039   score: 6.0   memory length: 461435   epsilon: 0.2843547400094901    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 4.83\n",
      "episode: 2040   score: 3.0   memory length: 461665   epsilon: 0.28389934000948724    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.81\n",
      "episode: 2041   score: 5.0   memory length: 461971   epsilon: 0.2832934600094834    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 4.81\n",
      "episode: 2042   score: 5.0   memory length: 462260   epsilon: 0.2827212400094798    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 2043   score: 6.0   memory length: 462622   epsilon: 0.28200448000947526    steps: 362    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 2044   score: 5.0   memory length: 462953   epsilon: 0.2813491000094711    steps: 331    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 2045   score: 4.0   memory length: 463211   epsilon: 0.2808382600094679    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 2046   score: 4.0   memory length: 463490   epsilon: 0.2802858400094644    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 2047   score: 3.0   memory length: 463720   epsilon: 0.2798304400094615    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.83\n",
      "episode: 2048   score: 5.0   memory length: 464025   epsilon: 0.2792265400094577    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 4.84\n",
      "episode: 2049   score: 4.0   memory length: 464302   epsilon: 0.2786780800094542    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 2050   score: 5.0   memory length: 464632   epsilon: 0.2780246800094501    steps: 330    lr: 6.400000000000001e-06     evaluation reward: 4.84\n",
      "episode: 2051   score: 7.0   memory length: 465033   epsilon: 0.27723070000944505    steps: 401    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2052   score: 5.0   memory length: 465346   epsilon: 0.27661096000944113    steps: 313    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2053   score: 8.0   memory length: 465786   epsilon: 0.2757397600094356    steps: 440    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 2054   score: 3.0   memory length: 466017   epsilon: 0.2752823800094327    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 2055   score: 6.0   memory length: 466352   epsilon: 0.27461908000942853    steps: 335    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 2056   score: 4.0   memory length: 466611   epsilon: 0.2741062600094253    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.84\n",
      "episode: 2057   score: 6.0   memory length: 466970   epsilon: 0.2733954400094208    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2058   score: 5.0   memory length: 467294   epsilon: 0.27275392000941673    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 2059   score: 6.0   memory length: 467688   epsilon: 0.2719738000094118    steps: 394    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 2060   score: 4.0   memory length: 467930   epsilon: 0.27149464000940876    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2061   score: 4.0   memory length: 468190   epsilon: 0.2709798400094055    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 2062   score: 9.0   memory length: 468660   epsilon: 0.2700492400093996    steps: 470    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 2063   score: 5.0   memory length: 468964   epsilon: 0.2694473200093958    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2064   score: 5.0   memory length: 469277   epsilon: 0.2688275800093919    steps: 313    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 2065   score: 5.0   memory length: 469614   epsilon: 0.26816032000938766    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2066   score: 5.0   memory length: 469941   epsilon: 0.26751286000938357    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 2067   score: 4.0   memory length: 470183   epsilon: 0.26703370000938054    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 2068   score: 4.0   memory length: 470459   epsilon: 0.2664872200093771    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 2069   score: 3.0   memory length: 470687   epsilon: 0.2660357800093742    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 2070   score: 4.0   memory length: 470928   epsilon: 0.2655586000093712    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2071   score: 6.0   memory length: 471248   epsilon: 0.2649250000093672    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 2072   score: 3.0   memory length: 471478   epsilon: 0.2644696000093643    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 2073   score: 6.0   memory length: 471831   epsilon: 0.2637706600093599    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 4.83\n",
      "episode: 2074   score: 8.0   memory length: 472253   epsilon: 0.2629351000093546    steps: 422    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2075   score: 5.0   memory length: 472576   epsilon: 0.26229556000935056    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 2076   score: 5.0   memory length: 472903   epsilon: 0.26164810000934646    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2077   score: 4.0   memory length: 473201   epsilon: 0.26105806000934273    steps: 298    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2078   score: 4.0   memory length: 473443   epsilon: 0.2605789000093397    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.84\n",
      "episode: 2079   score: 8.0   memory length: 473859   epsilon: 0.2597552200093345    steps: 416    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 2080   score: 6.0   memory length: 474202   epsilon: 0.2590760800093302    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 2081   score: 3.0   memory length: 474449   epsilon: 0.2585870200093271    steps: 247    lr: 6.400000000000001e-06     evaluation reward: 4.84\n",
      "episode: 2082   score: 2.0   memory length: 474649   epsilon: 0.2581910200093246    steps: 200    lr: 6.400000000000001e-06     evaluation reward: 4.78\n",
      "episode: 2083   score: 8.0   memory length: 474965   epsilon: 0.25756534000932063    steps: 316    lr: 6.400000000000001e-06     evaluation reward: 4.81\n",
      "episode: 2084   score: 7.0   memory length: 475341   epsilon: 0.2568208600093159    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 2085   score: 5.0   memory length: 475665   epsilon: 0.25617934000931186    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 4.82\n",
      "episode: 2086   score: 9.0   memory length: 476064   epsilon: 0.25538932000930686    steps: 399    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 2087   score: 5.0   memory length: 476390   epsilon: 0.2547438400093028    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 2088   score: 5.0   memory length: 476721   epsilon: 0.25408846000929863    steps: 331    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 2089   score: 3.0   memory length: 476951   epsilon: 0.25363306000929575    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 2090   score: 5.0   memory length: 477258   epsilon: 0.2530252000092919    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 2091   score: 5.0   memory length: 477572   epsilon: 0.252403480009288    steps: 314    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 2092   score: 5.0   memory length: 477876   epsilon: 0.25180156000928416    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 2093   score: 4.0   memory length: 478135   epsilon: 0.2512887400092809    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 2094   score: 5.0   memory length: 478465   epsilon: 0.2506353400092768    steps: 330    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 2095   score: 4.0   memory length: 478765   epsilon: 0.250041340009273    steps: 300    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 2096   score: 6.0   memory length: 479123   epsilon: 0.24933250000926854    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 2097   score: 4.0   memory length: 479402   epsilon: 0.24878008000926505    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 2098   score: 5.0   memory length: 479706   epsilon: 0.24817816000926124    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2099   score: 7.0   memory length: 480070   epsilon: 0.24745744000925668    steps: 364    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 2100   score: 5.0   memory length: 480377   epsilon: 0.24684958000925283    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 4.98\n",
      "episode: 2101   score: 4.0   memory length: 480619   epsilon: 0.2463704200092498    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 2102   score: 4.0   memory length: 480896   epsilon: 0.24582196000924633    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 2103   score: 4.0   memory length: 481140   epsilon: 0.24533884000924328    steps: 244    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2104   score: 5.0   memory length: 481431   epsilon: 0.24476266000923963    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 2105   score: 5.0   memory length: 481740   epsilon: 0.24415084000923576    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 2106   score: 4.0   memory length: 481981   epsilon: 0.24367366000923274    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2107   score: 9.0   memory length: 482455   epsilon: 0.2427351400092268    steps: 474    lr: 6.400000000000001e-06     evaluation reward: 4.98\n",
      "episode: 2108   score: 9.0   memory length: 482932   epsilon: 0.24179068000922083    steps: 477    lr: 6.400000000000001e-06     evaluation reward: 5.04\n",
      "episode: 2109   score: 5.0   memory length: 483205   epsilon: 0.2412501400092174    steps: 273    lr: 6.400000000000001e-06     evaluation reward: 5.04\n",
      "episode: 2110   score: 7.0   memory length: 483579   epsilon: 0.24050962000921272    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 5.06\n",
      "episode: 2111   score: 4.0   memory length: 483839   epsilon: 0.23999482000920946    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 5.05\n",
      "episode: 2112   score: 3.0   memory length: 484069   epsilon: 0.23953942000920658    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 5.02\n",
      "episode: 2113   score: 4.0   memory length: 484348   epsilon: 0.2389870000092031    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 5.01\n",
      "episode: 2114   score: 3.0   memory length: 484578   epsilon: 0.2385316000092002    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.98\n",
      "episode: 2115   score: 4.0   memory length: 484837   epsilon: 0.23801878000919696    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 2116   score: 4.0   memory length: 485133   epsilon: 0.23743270000919325    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 4.95\n",
      "episode: 2117   score: 5.0   memory length: 485461   epsilon: 0.23678326000918914    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 2118   score: 5.0   memory length: 485766   epsilon: 0.23617936000918532    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2119   score: 4.0   memory length: 486042   epsilon: 0.23563288000918187    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2120   score: 5.0   memory length: 486346   epsilon: 0.23503096000917806    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 2121   score: 5.0   memory length: 486651   epsilon: 0.23442706000917424    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 4.95\n",
      "episode: 2122   score: 4.0   memory length: 486909   epsilon: 0.233916220009171    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 4.95\n",
      "episode: 2123   score: 5.0   memory length: 487190   epsilon: 0.23335984000916749    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 4.96\n",
      "episode: 2124   score: 7.0   memory length: 487599   epsilon: 0.23255002000916236    steps: 409    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 2125   score: 8.0   memory length: 488022   epsilon: 0.23171248000915706    steps: 423    lr: 6.400000000000001e-06     evaluation reward: 4.96\n",
      "episode: 2126   score: 10.0   memory length: 488414   epsilon: 0.23093632000915215    steps: 392    lr: 6.400000000000001e-06     evaluation reward: 5.03\n",
      "episode: 2127   score: 3.0   memory length: 488645   epsilon: 0.23047894000914926    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 5.0\n",
      "episode: 2128   score: 4.0   memory length: 488885   epsilon: 0.23000374000914625    steps: 240    lr: 6.400000000000001e-06     evaluation reward: 5.0\n",
      "episode: 2129   score: 4.0   memory length: 489146   epsilon: 0.22948696000914298    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 4.99\n",
      "episode: 2130   score: 3.0   memory length: 489358   epsilon: 0.22906720000914033    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 4.99\n",
      "episode: 2131   score: 4.0   memory length: 489657   epsilon: 0.22847518000913658    steps: 299    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 2132   score: 6.0   memory length: 489990   epsilon: 0.2278158400091324    steps: 333    lr: 6.400000000000001e-06     evaluation reward: 4.99\n",
      "episode: 2133   score: 4.0   memory length: 490231   epsilon: 0.2273386600091294    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.98\n",
      "episode: 2134   score: 3.0   memory length: 490461   epsilon: 0.2268832600091265    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 2135   score: 6.0   memory length: 490820   epsilon: 0.226172440009122    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 4.98\n",
      "episode: 2136   score: 4.0   memory length: 491095   epsilon: 0.22562794000911857    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 5.0\n",
      "episode: 2137   score: 3.0   memory length: 491304   epsilon: 0.22521412000911595    steps: 209    lr: 6.400000000000001e-06     evaluation reward: 4.99\n",
      "episode: 2138   score: 5.0   memory length: 491626   epsilon: 0.22457656000911191    steps: 322    lr: 6.400000000000001e-06     evaluation reward: 4.99\n",
      "episode: 2139   score: 5.0   memory length: 491931   epsilon: 0.2239726600091081    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 4.98\n",
      "episode: 2140   score: 6.0   memory length: 492305   epsilon: 0.2232321400091034    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 5.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_3272/2166826527.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Start training after random sample generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtrain_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_policy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;31m# Update the target network only for Double DQN only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdouble_dqn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mupdate_target_network_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/agent.py\u001b[0m in \u001b[0;36mtrain_policy_net\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Compute Q function of next state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "rewards, episodes = [], []\n",
    "best_eval_reward = 0\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "    step = 0\n",
    "    state = env.reset()\n",
    "    next_state = state\n",
    "    life = number_lives\n",
    "\n",
    "    get_init_state(history, state[0], HISTORY_SIZE)\n",
    "\n",
    "    while not done:\n",
    "        step += 1\n",
    "        frame += 1\n",
    "\n",
    "        # Perform a fire action if ball is no longer on screen to continue onto next life\n",
    "        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "        state = next_state\n",
    "        #next_state, reward, done, info = env.step(action + 1)\n",
    "        observation, reward, terminated, truncated, info = env.step(action + 1)\n",
    "        next_state = observation\n",
    "        done = terminated\n",
    "        \n",
    "        \n",
    "        frame_next_state = get_frame(next_state)\n",
    "        history[4, :, :] = frame_next_state\n",
    "        terminal_state = check_live(life, info['lives'])\n",
    "\n",
    "        life = info['lives']\n",
    "        r = reward\n",
    "\n",
    "        # Store the transition in memory \n",
    "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "        # Start training after random sample generation\n",
    "        if(frame >= train_frame):\n",
    "            agent.train_policy_net(frame)\n",
    "            # Update the target network only for Double DQN only\n",
    "            if double_dqn and (frame % update_target_network_frequency)== 0:\n",
    "                agent.update_target_net()\n",
    "        score += reward\n",
    "        history[:4, :, :] = history[1:, :, :]\n",
    "            \n",
    "        if done:\n",
    "            evaluation_reward.append(score)\n",
    "            rewards.append(np.mean(evaluation_reward))\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, rewards, 'b')\n",
    "            pylab.xlabel('Episodes')\n",
    "            pylab.ylabel('Rewards') \n",
    "            pylab.title('Episodes vs Reward')\n",
    "            \n",
    "            ####\n",
    "            save_graph_dir = './save_graph'\n",
    "            if not os.path.exists(save_graph_dir):\n",
    "                os.makedirs(save_graph_dir)\n",
    "            ####\n",
    "            pylab.savefig(\"./save_graph/breakout_onlydqn.png\") # save graph for training visualization\n",
    "            \n",
    "            # every episode, plot the play time\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n",
    "                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n",
    "\n",
    "            # if the mean of scores of last 100 episode is bigger than 5 save model\n",
    "            ### Change this save condition to whatever you prefer ###\n",
    "            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n",
    "                torch.save(agent.policy_net, \"./save_model/breakout_onlydqn.pth\")\n",
    "                best_eval_reward = np.mean(evaluation_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.06"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_eval_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 6.0   memory length: 353   epsilon: 1.0    steps: 353    lr: 0.0001     evaluation reward: 6.0\n",
      "episode: 1   score: 3.0   memory length: 601   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 4.5\n",
      "episode: 2   score: 2.0   memory length: 799   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 3.6666666666666665\n",
      "episode: 3   score: 3.0   memory length: 1026   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 3.5\n",
      "episode: 4   score: 2.0   memory length: 1223   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 3.2\n",
      "episode: 5   score: 0.0   memory length: 1346   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 2.6666666666666665\n",
      "episode: 6   score: 2.0   memory length: 1530   epsilon: 1.0    steps: 184    lr: 0.0001     evaluation reward: 2.5714285714285716\n",
      "episode: 7   score: 1.0   memory length: 1699   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 2.375\n",
      "episode: 8   score: 1.0   memory length: 1869   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 2.2222222222222223\n",
      "episode: 9   score: 0.0   memory length: 1992   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 10   score: 0.0   memory length: 2114   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.8181818181818181\n",
      "episode: 11   score: 0.0   memory length: 2237   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6666666666666667\n",
      "episode: 12   score: 2.0   memory length: 2454   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.6923076923076923\n",
      "episode: 13   score: 1.0   memory length: 2623   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.6428571428571428\n",
      "episode: 14   score: 0.0   memory length: 2745   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5333333333333334\n",
      "episode: 15   score: 4.0   memory length: 3040   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.6875\n",
      "episode: 16   score: 0.0   memory length: 3163   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.588235294117647\n",
      "episode: 17   score: 1.0   memory length: 3314   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5555555555555556\n",
      "episode: 18   score: 1.0   memory length: 3465   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5263157894736843\n",
      "episode: 19   score: 0.0   memory length: 3588   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 20   score: 0.0   memory length: 3711   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.380952380952381\n",
      "episode: 21   score: 2.0   memory length: 3908   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.4090909090909092\n",
      "episode: 22   score: 0.0   memory length: 4030   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.3478260869565217\n",
      "episode: 23   score: 2.0   memory length: 4248   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.375\n",
      "episode: 24   score: 0.0   memory length: 4371   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 25   score: 1.0   memory length: 4523   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.3076923076923077\n",
      "episode: 26   score: 1.0   memory length: 4692   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.2962962962962963\n",
      "episode: 27   score: 0.0   memory length: 4815   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 28   score: 0.0   memory length: 4937   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.206896551724138\n",
      "episode: 29   score: 2.0   memory length: 5136   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.2333333333333334\n",
      "episode: 30   score: 3.0   memory length: 5384   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.2903225806451613\n",
      "episode: 31   score: 1.0   memory length: 5535   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.28125\n",
      "episode: 32   score: 2.0   memory length: 5752   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.303030303030303\n",
      "episode: 33   score: 0.0   memory length: 5874   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.2647058823529411\n",
      "episode: 34   score: 1.0   memory length: 6025   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.2571428571428571\n",
      "episode: 35   score: 0.0   memory length: 6148   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2222222222222223\n",
      "episode: 36   score: 0.0   memory length: 6271   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1891891891891893\n",
      "episode: 37   score: 0.0   memory length: 6394   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1578947368421053\n",
      "episode: 38   score: 0.0   memory length: 6517   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1282051282051282\n",
      "episode: 39   score: 1.0   memory length: 6668   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.125\n",
      "episode: 40   score: 0.0   memory length: 6790   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.0975609756097562\n",
      "episode: 41   score: 0.0   memory length: 6912   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.0714285714285714\n",
      "episode: 42   score: 2.0   memory length: 7110   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.0930232558139534\n",
      "episode: 43   score: 1.0   memory length: 7279   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.0909090909090908\n",
      "episode: 44   score: 1.0   memory length: 7430   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.0888888888888888\n",
      "episode: 45   score: 1.0   memory length: 7602   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.0869565217391304\n",
      "episode: 46   score: 1.0   memory length: 7771   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.0851063829787233\n",
      "episode: 47   score: 5.0   memory length: 8095   epsilon: 1.0    steps: 324    lr: 0.0001     evaluation reward: 1.1666666666666667\n",
      "episode: 48   score: 0.0   memory length: 8218   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1428571428571428\n",
      "episode: 49   score: 1.0   memory length: 8387   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.14\n",
      "episode: 50   score: 2.0   memory length: 8585   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.1568627450980393\n",
      "episode: 51   score: 2.0   memory length: 8783   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.1730769230769231\n",
      "episode: 52   score: 3.0   memory length: 9030   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.2075471698113207\n",
      "episode: 53   score: 3.0   memory length: 9294   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.2407407407407407\n",
      "episode: 54   score: 5.0   memory length: 9635   epsilon: 1.0    steps: 341    lr: 0.0001     evaluation reward: 1.309090909090909\n",
      "episode: 55   score: 4.0   memory length: 9929   epsilon: 1.0    steps: 294    lr: 0.0001     evaluation reward: 1.3571428571428572\n",
      "episode: 56   score: 2.0   memory length: 10148   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.368421052631579\n",
      "episode: 57   score: 2.0   memory length: 10348   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.3793103448275863\n",
      "episode: 58   score: 1.0   memory length: 10520   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.3728813559322033\n",
      "episode: 59   score: 0.0   memory length: 10642   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 60   score: 0.0   memory length: 10765   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3278688524590163\n",
      "episode: 61   score: 0.0   memory length: 10887   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.3064516129032258\n",
      "episode: 62   score: 4.0   memory length: 11176   epsilon: 1.0    steps: 289    lr: 0.0001     evaluation reward: 1.3492063492063493\n",
      "episode: 63   score: 1.0   memory length: 11347   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.34375\n",
      "episode: 64   score: 1.0   memory length: 11516   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.3384615384615384\n",
      "episode: 65   score: 1.0   memory length: 11685   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.3333333333333333\n",
      "episode: 66   score: 1.0   memory length: 11854   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.328358208955224\n",
      "episode: 67   score: 0.0   memory length: 11976   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.3088235294117647\n",
      "episode: 68   score: 2.0   memory length: 12177   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.318840579710145\n",
      "episode: 69   score: 0.0   memory length: 12299   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 70   score: 0.0   memory length: 12421   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.2816901408450705\n",
      "episode: 71   score: 1.0   memory length: 12589   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.2777777777777777\n",
      "episode: 72   score: 1.0   memory length: 12758   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.273972602739726\n",
      "episode: 73   score: 0.0   memory length: 12881   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2567567567567568\n",
      "episode: 74   score: 0.0   memory length: 13004   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 75   score: 2.0   memory length: 13220   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 76   score: 3.0   memory length: 13450   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.2727272727272727\n",
      "episode: 77   score: 3.0   memory length: 13697   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.294871794871795\n",
      "episode: 78   score: 5.0   memory length: 13996   epsilon: 1.0    steps: 299    lr: 0.0001     evaluation reward: 1.3417721518987342\n",
      "episode: 79   score: 3.0   memory length: 14222   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.3625\n",
      "episode: 80   score: 0.0   memory length: 14344   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.345679012345679\n",
      "episode: 81   score: 0.0   memory length: 14467   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.329268292682927\n",
      "episode: 82   score: 4.0   memory length: 14780   epsilon: 1.0    steps: 313    lr: 0.0001     evaluation reward: 1.3614457831325302\n",
      "episode: 83   score: 2.0   memory length: 14978   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.369047619047619\n",
      "episode: 84   score: 1.0   memory length: 15147   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.3647058823529412\n",
      "episode: 85   score: 2.0   memory length: 15366   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.372093023255814\n",
      "episode: 86   score: 2.0   memory length: 15546   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.3793103448275863\n",
      "episode: 87   score: 1.0   memory length: 15715   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.375\n",
      "episode: 88   score: 2.0   memory length: 15917   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.3820224719101124\n",
      "episode: 89   score: 2.0   memory length: 16137   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.3888888888888888\n",
      "episode: 90   score: 1.0   memory length: 16307   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.3846153846153846\n",
      "episode: 91   score: 4.0   memory length: 16601   epsilon: 1.0    steps: 294    lr: 0.0001     evaluation reward: 1.4130434782608696\n",
      "episode: 92   score: 1.0   memory length: 16772   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.4086021505376345\n",
      "episode: 93   score: 1.0   memory length: 16941   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.4042553191489362\n",
      "episode: 94   score: 2.0   memory length: 17123   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.4105263157894736\n",
      "episode: 95   score: 0.0   memory length: 17246   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3958333333333333\n",
      "episode: 96   score: 1.0   memory length: 17416   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.3917525773195876\n",
      "episode: 97   score: 1.0   memory length: 17568   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.3877551020408163\n",
      "episode: 98   score: 2.0   memory length: 17766   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.393939393939394\n",
      "episode: 99   score: 4.0   memory length: 18061   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 100   score: 1.0   memory length: 18231   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 101   score: 1.0   memory length: 18399   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 102   score: 2.0   memory length: 18597   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 103   score: 0.0   memory length: 18719   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 104   score: 1.0   memory length: 18889   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 105   score: 2.0   memory length: 19108   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 106   score: 0.0   memory length: 19231   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 107   score: 0.0   memory length: 19354   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 108   score: 2.0   memory length: 19533   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 109   score: 0.0   memory length: 19656   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 110   score: 2.0   memory length: 19875   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 111   score: 3.0   memory length: 20142   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 112   score: 0.0   memory length: 20265   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 113   score: 1.0   memory length: 20435   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 114   score: 2.0   memory length: 20653   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 115   score: 0.0   memory length: 20776   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 116   score: 3.0   memory length: 21020   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 117   score: 2.0   memory length: 21237   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 118   score: 3.0   memory length: 21483   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 119   score: 2.0   memory length: 21682   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 120   score: 3.0   memory length: 21927   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 121   score: 5.0   memory length: 22221   epsilon: 1.0    steps: 294    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 122   score: 2.0   memory length: 22419   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 123   score: 3.0   memory length: 22689   epsilon: 1.0    steps: 270    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 124   score: 1.0   memory length: 22860   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 125   score: 2.0   memory length: 23077   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 126   score: 3.0   memory length: 23322   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 127   score: 2.0   memory length: 23520   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 128   score: 3.0   memory length: 23748   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 129   score: 5.0   memory length: 24075   epsilon: 1.0    steps: 327    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 130   score: 2.0   memory length: 24296   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 131   score: 0.0   memory length: 24419   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 132   score: 0.0   memory length: 24542   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 133   score: 1.0   memory length: 24711   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 134   score: 1.0   memory length: 24863   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 135   score: 3.0   memory length: 25110   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 136   score: 0.0   memory length: 25233   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 137   score: 3.0   memory length: 25470   epsilon: 1.0    steps: 237    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 138   score: 1.0   memory length: 25620   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 139   score: 1.0   memory length: 25791   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 140   score: 2.0   memory length: 25992   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 141   score: 2.0   memory length: 26190   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 142   score: 2.0   memory length: 26409   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 143   score: 2.0   memory length: 26606   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 144   score: 0.0   memory length: 26729   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 145   score: 0.0   memory length: 26852   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 146   score: 2.0   memory length: 27051   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 147   score: 2.0   memory length: 27231   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 148   score: 0.0   memory length: 27354   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 149   score: 1.0   memory length: 27523   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 150   score: 1.0   memory length: 27694   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 151   score: 2.0   memory length: 27912   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 152   score: 0.0   memory length: 28035   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 153   score: 0.0   memory length: 28158   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 154   score: 0.0   memory length: 28281   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 155   score: 0.0   memory length: 28404   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 156   score: 0.0   memory length: 28527   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 157   score: 0.0   memory length: 28650   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 158   score: 1.0   memory length: 28819   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 159   score: 0.0   memory length: 28942   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 160   score: 0.0   memory length: 29065   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 161   score: 0.0   memory length: 29188   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 162   score: 1.0   memory length: 29338   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 163   score: 1.0   memory length: 29506   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 164   score: 2.0   memory length: 29725   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 165   score: 0.0   memory length: 29847   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 166   score: 1.0   memory length: 29998   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 167   score: 0.0   memory length: 30120   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 168   score: 4.0   memory length: 30415   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 169   score: 1.0   memory length: 30584   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 170   score: 1.0   memory length: 30754   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 171   score: 2.0   memory length: 30972   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 172   score: 2.0   memory length: 31190   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 173   score: 1.0   memory length: 31358   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 174   score: 0.0   memory length: 31481   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 175   score: 0.0   memory length: 31604   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 176   score: 3.0   memory length: 31831   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 177   score: 1.0   memory length: 32001   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 178   score: 0.0   memory length: 32124   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 179   score: 1.0   memory length: 32276   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 180   score: 0.0   memory length: 32399   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 181   score: 3.0   memory length: 32667   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 182   score: 2.0   memory length: 32865   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 183   score: 2.0   memory length: 33080   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 184   score: 3.0   memory length: 33342   epsilon: 1.0    steps: 262    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 185   score: 2.0   memory length: 33540   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 186   score: 3.0   memory length: 33807   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 187   score: 2.0   memory length: 34005   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 188   score: 0.0   memory length: 34127   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 189   score: 1.0   memory length: 34296   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 190   score: 1.0   memory length: 34465   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 191   score: 3.0   memory length: 34692   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 192   score: 4.0   memory length: 34972   epsilon: 1.0    steps: 280    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 193   score: 1.0   memory length: 35143   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 194   score: 0.0   memory length: 35265   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 195   score: 2.0   memory length: 35445   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 196   score: 0.0   memory length: 35568   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 197   score: 2.0   memory length: 35789   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 198   score: 2.0   memory length: 35991   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 199   score: 0.0   memory length: 36113   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 200   score: 2.0   memory length: 36331   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 201   score: 1.0   memory length: 36483   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 202   score: 1.0   memory length: 36655   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 203   score: 2.0   memory length: 36853   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 204   score: 0.0   memory length: 36976   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 205   score: 2.0   memory length: 37173   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 206   score: 2.0   memory length: 37370   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 207   score: 1.0   memory length: 37539   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 208   score: 0.0   memory length: 37662   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 209   score: 0.0   memory length: 37785   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 210   score: 0.0   memory length: 37907   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 211   score: 0.0   memory length: 38030   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 212   score: 2.0   memory length: 38228   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 213   score: 2.0   memory length: 38446   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 214   score: 0.0   memory length: 38569   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 215   score: 3.0   memory length: 38798   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 216   score: 1.0   memory length: 38969   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 217   score: 4.0   memory length: 39248   epsilon: 1.0    steps: 279    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 218   score: 0.0   memory length: 39371   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 219   score: 3.0   memory length: 39600   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 220   score: 0.0   memory length: 39723   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 221   score: 2.0   memory length: 39923   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 222   score: 0.0   memory length: 40045   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 223   score: 3.0   memory length: 40270   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 224   score: 0.0   memory length: 40392   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 225   score: 0.0   memory length: 40514   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 226   score: 1.0   memory length: 40685   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 227   score: 0.0   memory length: 40808   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 228   score: 3.0   memory length: 41076   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 229   score: 1.0   memory length: 41247   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 230   score: 1.0   memory length: 41398   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 231   score: 0.0   memory length: 41521   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 232   score: 3.0   memory length: 41747   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 233   score: 2.0   memory length: 41965   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 234   score: 0.0   memory length: 42087   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 235   score: 1.0   memory length: 42256   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 236   score: 0.0   memory length: 42379   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 237   score: 1.0   memory length: 42529   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 238   score: 1.0   memory length: 42698   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 239   score: 2.0   memory length: 42914   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 240   score: 2.0   memory length: 43112   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 241   score: 0.0   memory length: 43235   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 242   score: 3.0   memory length: 43463   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 243   score: 1.0   memory length: 43632   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 244   score: 3.0   memory length: 43900   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 245   score: 0.0   memory length: 44022   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 246   score: 1.0   memory length: 44190   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 247   score: 5.0   memory length: 44535   epsilon: 1.0    steps: 345    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 248   score: 2.0   memory length: 44734   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 249   score: 4.0   memory length: 44993   epsilon: 1.0    steps: 259    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 250   score: 3.0   memory length: 45223   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 251   score: 1.0   memory length: 45373   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 252   score: 1.0   memory length: 45523   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 253   score: 1.0   memory length: 45674   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 254   score: 0.0   memory length: 45796   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 255   score: 1.0   memory length: 45966   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 256   score: 1.0   memory length: 46135   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 257   score: 1.0   memory length: 46286   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 258   score: 2.0   memory length: 46484   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 259   score: 0.0   memory length: 46607   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 260   score: 0.0   memory length: 46730   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 261   score: 0.0   memory length: 46852   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 262   score: 2.0   memory length: 47050   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 263   score: 4.0   memory length: 47325   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 264   score: 0.0   memory length: 47447   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 265   score: 2.0   memory length: 47627   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 266   score: 0.0   memory length: 47750   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 267   score: 4.0   memory length: 48044   epsilon: 1.0    steps: 294    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 268   score: 1.0   memory length: 48194   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 269   score: 0.0   memory length: 48317   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 270   score: 1.0   memory length: 48468   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 271   score: 3.0   memory length: 48694   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 272   score: 1.0   memory length: 48845   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 273   score: 2.0   memory length: 49044   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 274   score: 2.0   memory length: 49244   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 275   score: 2.0   memory length: 49461   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 276   score: 1.0   memory length: 49631   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 277   score: 0.0   memory length: 49754   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 278   score: 2.0   memory length: 49975   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 279   score: 3.0   memory length: 50244   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 280   score: 1.0   memory length: 50395   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 281   score: 1.0   memory length: 50563   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 282   score: 2.0   memory length: 50781   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 283   score: 2.0   memory length: 50999   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 284   score: 4.0   memory length: 51278   epsilon: 1.0    steps: 279    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 285   score: 0.0   memory length: 51401   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 286   score: 0.0   memory length: 51524   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 287   score: 0.0   memory length: 51646   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 288   score: 4.0   memory length: 51960   epsilon: 1.0    steps: 314    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 289   score: 2.0   memory length: 52158   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 290   score: 0.0   memory length: 52281   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 291   score: 9.0   memory length: 52664   epsilon: 1.0    steps: 383    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 292   score: 4.0   memory length: 52918   epsilon: 1.0    steps: 254    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 293   score: 2.0   memory length: 53116   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 294   score: 0.0   memory length: 53238   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 295   score: 2.0   memory length: 53458   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 296   score: 0.0   memory length: 53581   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 297   score: 1.0   memory length: 53750   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 298   score: 1.0   memory length: 53900   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 299   score: 2.0   memory length: 54117   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 300   score: 0.0   memory length: 54239   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 301   score: 2.0   memory length: 54437   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 302   score: 0.0   memory length: 54560   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 303   score: 1.0   memory length: 54729   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 304   score: 3.0   memory length: 54978   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 305   score: 0.0   memory length: 55101   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 306   score: 3.0   memory length: 55327   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 307   score: 0.0   memory length: 55449   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 308   score: 1.0   memory length: 55600   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 309   score: 2.0   memory length: 55802   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 310   score: 2.0   memory length: 56017   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 311   score: 0.0   memory length: 56140   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 312   score: 0.0   memory length: 56263   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 313   score: 1.0   memory length: 56434   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 314   score: 0.0   memory length: 56556   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 315   score: 1.0   memory length: 56725   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 316   score: 2.0   memory length: 56909   epsilon: 1.0    steps: 184    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 317   score: 2.0   memory length: 57107   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 318   score: 0.0   memory length: 57229   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 319   score: 0.0   memory length: 57352   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 320   score: 0.0   memory length: 57474   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 321   score: 0.0   memory length: 57596   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 322   score: 3.0   memory length: 57844   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 323   score: 0.0   memory length: 57967   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 324   score: 1.0   memory length: 58135   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 325   score: 1.0   memory length: 58286   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 326   score: 2.0   memory length: 58504   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 327   score: 4.0   memory length: 58759   epsilon: 1.0    steps: 255    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 328   score: 2.0   memory length: 58979   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 329   score: 4.0   memory length: 59296   epsilon: 1.0    steps: 317    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 330   score: 4.0   memory length: 59591   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 331   score: 0.0   memory length: 59714   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 332   score: 0.0   memory length: 59836   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 333   score: 0.0   memory length: 59959   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 334   score: 1.0   memory length: 60110   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 335   score: 2.0   memory length: 60291   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 336   score: 4.0   memory length: 60563   epsilon: 1.0    steps: 272    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 337   score: 0.0   memory length: 60686   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 338   score: 4.0   memory length: 60927   epsilon: 1.0    steps: 241    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 339   score: 3.0   memory length: 61175   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 340   score: 1.0   memory length: 61344   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 341   score: 0.0   memory length: 61466   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 342   score: 2.0   memory length: 61683   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 343   score: 3.0   memory length: 61909   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 344   score: 1.0   memory length: 62081   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 345   score: 0.0   memory length: 62203   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 346   score: 1.0   memory length: 62354   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 347   score: 0.0   memory length: 62477   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 348   score: 1.0   memory length: 62628   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 349   score: 1.0   memory length: 62797   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 350   score: 1.0   memory length: 62965   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 351   score: 1.0   memory length: 63137   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 352   score: 0.0   memory length: 63259   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 353   score: 0.0   memory length: 63381   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 354   score: 1.0   memory length: 63552   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 355   score: 0.0   memory length: 63675   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 356   score: 0.0   memory length: 63797   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 357   score: 2.0   memory length: 64020   epsilon: 1.0    steps: 223    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 358   score: 1.0   memory length: 64189   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 359   score: 2.0   memory length: 64405   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 360   score: 0.0   memory length: 64527   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 361   score: 1.0   memory length: 64696   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 362   score: 1.0   memory length: 64864   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 363   score: 0.0   memory length: 64987   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 364   score: 0.0   memory length: 65110   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 365   score: 2.0   memory length: 65292   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 366   score: 0.0   memory length: 65415   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 367   score: 1.0   memory length: 65585   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 368   score: 2.0   memory length: 65803   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 369   score: 1.0   memory length: 65973   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 370   score: 2.0   memory length: 66194   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 371   score: 0.0   memory length: 66316   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 372   score: 2.0   memory length: 66514   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 373   score: 0.0   memory length: 66637   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 374   score: 3.0   memory length: 66906   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 375   score: 0.0   memory length: 67028   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 376   score: 2.0   memory length: 67244   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 377   score: 0.0   memory length: 67367   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 378   score: 0.0   memory length: 67490   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 379   score: 2.0   memory length: 67708   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 380   score: 1.0   memory length: 67876   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 381   score: 0.0   memory length: 67998   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 382   score: 1.0   memory length: 68166   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 383   score: 2.0   memory length: 68364   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 384   score: 0.0   memory length: 68487   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 385   score: 2.0   memory length: 68685   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 386   score: 0.0   memory length: 68808   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 387   score: 1.0   memory length: 68960   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 388   score: 1.0   memory length: 69128   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 389   score: 2.0   memory length: 69348   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 390   score: 1.0   memory length: 69517   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 391   score: 2.0   memory length: 69715   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 392   score: 1.0   memory length: 69866   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.14\n",
      "episode: 393   score: 2.0   memory length: 70063   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.14\n",
      "episode: 394   score: 3.0   memory length: 70316   epsilon: 1.0    steps: 253    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 395   score: 4.0   memory length: 70596   epsilon: 1.0    steps: 280    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 396   score: 4.0   memory length: 70875   epsilon: 1.0    steps: 279    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 397   score: 0.0   memory length: 70998   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 398   score: 7.0   memory length: 71278   epsilon: 1.0    steps: 280    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 399   score: 7.0   memory length: 71724   epsilon: 1.0    steps: 446    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 400   score: 2.0   memory length: 71922   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 401   score: 5.0   memory length: 72261   epsilon: 1.0    steps: 339    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 402   score: 7.0   memory length: 72563   epsilon: 1.0    steps: 302    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 403   score: 2.0   memory length: 72779   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 404   score: 4.0   memory length: 73057   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 405   score: 2.0   memory length: 73255   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 406   score: 2.0   memory length: 73474   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 407   score: 2.0   memory length: 73673   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 408   score: 2.0   memory length: 73871   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 409   score: 2.0   memory length: 74068   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 410   score: 0.0   memory length: 74191   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 411   score: 2.0   memory length: 74388   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 412   score: 2.0   memory length: 74568   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 413   score: 0.0   memory length: 74691   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 414   score: 0.0   memory length: 74814   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 415   score: 3.0   memory length: 75080   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 416   score: 4.0   memory length: 75373   epsilon: 1.0    steps: 293    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 417   score: 2.0   memory length: 75571   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 418   score: 2.0   memory length: 75769   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 419   score: 1.0   memory length: 75938   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 420   score: 3.0   memory length: 76184   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 421   score: 2.0   memory length: 76381   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 422   score: 1.0   memory length: 76550   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 423   score: 2.0   memory length: 76748   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 424   score: 0.0   memory length: 76870   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 425   score: 3.0   memory length: 77096   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 426   score: 0.0   memory length: 77218   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 427   score: 0.0   memory length: 77341   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 428   score: 0.0   memory length: 77463   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 429   score: 0.0   memory length: 77585   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 430   score: 3.0   memory length: 77811   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 431   score: 1.0   memory length: 77962   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 432   score: 3.0   memory length: 78188   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 433   score: 1.0   memory length: 78357   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 434   score: 0.0   memory length: 78479   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 435   score: 3.0   memory length: 78708   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 436   score: 1.0   memory length: 78861   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 437   score: 0.0   memory length: 78983   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 438   score: 1.0   memory length: 79152   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 439   score: 0.0   memory length: 79275   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 440   score: 1.0   memory length: 79444   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 441   score: 1.0   memory length: 79595   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 442   score: 0.0   memory length: 79718   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 443   score: 1.0   memory length: 79887   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 444   score: 4.0   memory length: 80201   epsilon: 1.0    steps: 314    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 445   score: 1.0   memory length: 80371   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 446   score: 4.0   memory length: 80625   epsilon: 1.0    steps: 254    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 447   score: 1.0   memory length: 80794   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 448   score: 0.0   memory length: 80917   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 449   score: 1.0   memory length: 81086   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 450   score: 0.0   memory length: 81209   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 451   score: 1.0   memory length: 81377   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 452   score: 1.0   memory length: 81528   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 453   score: 1.0   memory length: 81696   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 454   score: 0.0   memory length: 81819   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 455   score: 1.0   memory length: 81989   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 456   score: 3.0   memory length: 82236   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 457   score: 1.0   memory length: 82405   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 458   score: 3.0   memory length: 82631   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 459   score: 0.0   memory length: 82754   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 460   score: 1.0   memory length: 82923   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 461   score: 2.0   memory length: 83102   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 462   score: 0.0   memory length: 83225   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 463   score: 0.0   memory length: 83347   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 464   score: 3.0   memory length: 83595   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 465   score: 3.0   memory length: 83859   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 466   score: 0.0   memory length: 83982   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 467   score: 7.0   memory length: 84380   epsilon: 1.0    steps: 398    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 468   score: 2.0   memory length: 84597   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 469   score: 1.0   memory length: 84748   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 470   score: 0.0   memory length: 84871   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 471   score: 4.0   memory length: 85166   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 472   score: 1.0   memory length: 85334   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 473   score: 0.0   memory length: 85457   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 474   score: 2.0   memory length: 85656   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 475   score: 0.0   memory length: 85779   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 476   score: 0.0   memory length: 85901   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 477   score: 0.0   memory length: 86023   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 478   score: 0.0   memory length: 86146   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 479   score: 2.0   memory length: 86346   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 480   score: 2.0   memory length: 86563   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 481   score: 0.0   memory length: 86686   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 482   score: 0.0   memory length: 86808   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 483   score: 1.0   memory length: 86977   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 484   score: 3.0   memory length: 87223   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 485   score: 2.0   memory length: 87420   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 486   score: 1.0   memory length: 87570   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 487   score: 4.0   memory length: 87888   epsilon: 1.0    steps: 318    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 488   score: 2.0   memory length: 88106   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 489   score: 1.0   memory length: 88274   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 490   score: 0.0   memory length: 88397   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 491   score: 0.0   memory length: 88520   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 492   score: 6.0   memory length: 88894   epsilon: 1.0    steps: 374    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 493   score: 1.0   memory length: 89062   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 494   score: 0.0   memory length: 89185   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 495   score: 2.0   memory length: 89383   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 496   score: 2.0   memory length: 89581   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 497   score: 1.0   memory length: 89731   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 498   score: 2.0   memory length: 89929   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 499   score: 2.0   memory length: 90129   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 500   score: 2.0   memory length: 90347   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 501   score: 1.0   memory length: 90498   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 502   score: 2.0   memory length: 90718   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 503   score: 1.0   memory length: 90887   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 504   score: 2.0   memory length: 91085   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 505   score: 0.0   memory length: 91208   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 506   score: 0.0   memory length: 91331   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 507   score: 2.0   memory length: 91530   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 508   score: 2.0   memory length: 91752   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 509   score: 2.0   memory length: 91968   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 510   score: 1.0   memory length: 92136   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 511   score: 2.0   memory length: 92335   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 512   score: 2.0   memory length: 92515   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 513   score: 2.0   memory length: 92717   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 514   score: 0.0   memory length: 92840   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 515   score: 0.0   memory length: 92962   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 516   score: 3.0   memory length: 93206   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 517   score: 0.0   memory length: 93328   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 518   score: 3.0   memory length: 93577   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 519   score: 2.0   memory length: 93775   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 520   score: 1.0   memory length: 93925   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 521   score: 1.0   memory length: 94095   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 522   score: 0.0   memory length: 94217   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 523   score: 2.0   memory length: 94417   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 524   score: 0.0   memory length: 94540   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 525   score: 1.0   memory length: 94710   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 526   score: 3.0   memory length: 94956   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 527   score: 4.0   memory length: 95231   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 528   score: 2.0   memory length: 95429   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 529   score: 2.0   memory length: 95647   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 530   score: 1.0   memory length: 95798   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 531   score: 2.0   memory length: 96016   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 532   score: 0.0   memory length: 96139   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 533   score: 2.0   memory length: 96340   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 534   score: 3.0   memory length: 96604   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 535   score: 0.0   memory length: 96727   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 536   score: 2.0   memory length: 96946   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 537   score: 3.0   memory length: 97176   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 538   score: 0.0   memory length: 97299   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 539   score: 0.0   memory length: 97421   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 540   score: 0.0   memory length: 97544   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 541   score: 4.0   memory length: 97857   epsilon: 1.0    steps: 313    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 542   score: 2.0   memory length: 98055   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 543   score: 1.0   memory length: 98224   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 544   score: 0.0   memory length: 98347   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 545   score: 0.0   memory length: 98470   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 546   score: 3.0   memory length: 98713   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 547   score: 2.0   memory length: 98892   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 548   score: 0.0   memory length: 99015   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 549   score: 0.0   memory length: 99137   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 550   score: 1.0   memory length: 99305   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 551   score: 2.0   memory length: 99522   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 552   score: 5.0   memory length: 99884   epsilon: 1.0    steps: 362    lr: 0.0001     evaluation reward: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanshporwal/memory.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sample = np.array(sample)\n",
      "/home/vanshporwal/agent_double.py:74: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mini_batch = np.array(mini_batch).transpose()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 553   score: 1.0   memory length: 100056   epsilon: 0.9998871400000025    steps: 172    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 554   score: 0.0   memory length: 100178   epsilon: 0.9996455800000077    steps: 122    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 555   score: 3.0   memory length: 100407   epsilon: 0.9991921600000175    steps: 229    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 556   score: 2.0   memory length: 100605   epsilon: 0.998800120000026    steps: 198    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 557   score: 0.0   memory length: 100728   epsilon: 0.9985565800000313    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 558   score: 2.0   memory length: 100945   epsilon: 0.9981269200000407    steps: 217    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 559   score: 0.0   memory length: 101067   epsilon: 0.9978853600000459    steps: 122    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 560   score: 0.0   memory length: 101189   epsilon: 0.9976438000000512    steps: 122    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 561   score: 2.0   memory length: 101405   epsilon: 0.9972161200000604    steps: 216    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 562   score: 4.0   memory length: 101681   epsilon: 0.9966696400000723    steps: 276    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 563   score: 4.0   memory length: 101977   epsilon: 0.996083560000085    steps: 296    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 564   score: 2.0   memory length: 102175   epsilon: 0.9956915200000935    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 565   score: 1.0   memory length: 102344   epsilon: 0.9953569000001008    steps: 169    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 566   score: 6.0   memory length: 102699   epsilon: 0.9946540000001161    steps: 355    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 567   score: 1.0   memory length: 102850   epsilon: 0.9943550200001225    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 568   score: 2.0   memory length: 103048   epsilon: 0.9939629800001311    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 569   score: 2.0   memory length: 103266   epsilon: 0.9935313400001404    steps: 218    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 570   score: 0.0   memory length: 103389   epsilon: 0.9932878000001457    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 571   score: 2.0   memory length: 103586   epsilon: 0.9928977400001542    steps: 197    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 572   score: 1.0   memory length: 103737   epsilon: 0.9925987600001607    steps: 151    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 573   score: 1.0   memory length: 103888   epsilon: 0.9922997800001672    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 574   score: 1.0   memory length: 104038   epsilon: 0.9920027800001736    steps: 150    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 575   score: 2.0   memory length: 104235   epsilon: 0.9916127200001821    steps: 197    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 576   score: 1.0   memory length: 104406   epsilon: 0.9912741400001894    steps: 171    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 577   score: 1.0   memory length: 104577   epsilon: 0.9909355600001968    steps: 171    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 578   score: 1.0   memory length: 104746   epsilon: 0.990600940000204    steps: 169    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 579   score: 1.0   memory length: 104914   epsilon: 0.9902683000002113    steps: 168    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 580   score: 1.0   memory length: 105083   epsilon: 0.9899336800002185    steps: 169    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 581   score: 1.0   memory length: 105234   epsilon: 0.989634700000225    steps: 151    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 582   score: 1.0   memory length: 105402   epsilon: 0.9893020600002322    steps: 168    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 583   score: 5.0   memory length: 105762   epsilon: 0.9885892600002477    steps: 360    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 584   score: 1.0   memory length: 105914   epsilon: 0.9882883000002542    steps: 152    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 585   score: 0.0   memory length: 106037   epsilon: 0.9880447600002595    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 586   score: 0.0   memory length: 106160   epsilon: 0.9878012200002648    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 587   score: 0.0   memory length: 106283   epsilon: 0.9875576800002701    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 588   score: 0.0   memory length: 106406   epsilon: 0.9873141400002754    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 589   score: 2.0   memory length: 106606   epsilon: 0.986918140000284    steps: 200    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 590   score: 5.0   memory length: 106927   epsilon: 0.9862825600002978    steps: 321    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 591   score: 0.0   memory length: 107049   epsilon: 0.986041000000303    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 592   score: 4.0   memory length: 107341   epsilon: 0.9854628400003156    steps: 292    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 593   score: 3.0   memory length: 107589   epsilon: 0.9849718000003262    steps: 248    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 594   score: 2.0   memory length: 107770   epsilon: 0.984613420000334    steps: 181    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 595   score: 0.0   memory length: 107892   epsilon: 0.9843718600003393    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 596   score: 1.0   memory length: 108062   epsilon: 0.9840352600003466    steps: 170    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 597   score: 3.0   memory length: 108291   epsilon: 0.9835818400003564    steps: 229    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 598   score: 3.0   memory length: 108536   epsilon: 0.983096740000367    steps: 245    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 599   score: 2.0   memory length: 108754   epsilon: 0.9826651000003763    steps: 218    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 600   score: 2.0   memory length: 108951   epsilon: 0.9822750400003848    steps: 197    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 601   score: 4.0   memory length: 109217   epsilon: 0.9817483600003962    steps: 266    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 602   score: 4.0   memory length: 109511   epsilon: 0.9811662400004089    steps: 294    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 603   score: 1.0   memory length: 109661   epsilon: 0.9808692400004153    steps: 150    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 604   score: 3.0   memory length: 109907   epsilon: 0.9803821600004259    steps: 246    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 605   score: 2.0   memory length: 110105   epsilon: 0.9799901200004344    steps: 198    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 606   score: 3.0   memory length: 110334   epsilon: 0.9795367000004442    steps: 229    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 607   score: 0.0   memory length: 110457   epsilon: 0.9792931600004495    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 608   score: 2.0   memory length: 110656   epsilon: 0.9788991400004581    steps: 199    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 609   score: 5.0   memory length: 110952   epsilon: 0.9783130600004708    steps: 296    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 610   score: 1.0   memory length: 111102   epsilon: 0.9780160600004772    steps: 150    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 611   score: 1.0   memory length: 111271   epsilon: 0.9776814400004845    steps: 169    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 612   score: 2.0   memory length: 111489   epsilon: 0.9772498000004939    steps: 218    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 613   score: 0.0   memory length: 111612   epsilon: 0.9770062600004992    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 614   score: 0.0   memory length: 111735   epsilon: 0.9767627200005045    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 615   score: 0.0   memory length: 111858   epsilon: 0.9765191800005097    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 616   score: 2.0   memory length: 112056   epsilon: 0.9761271400005183    steps: 198    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 617   score: 1.0   memory length: 112224   epsilon: 0.9757945000005255    steps: 168    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 618   score: 2.0   memory length: 112423   epsilon: 0.975400480000534    steps: 199    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 619   score: 2.0   memory length: 112621   epsilon: 0.9750084400005425    steps: 198    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 620   score: 0.0   memory length: 112743   epsilon: 0.9747668800005478    steps: 122    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 621   score: 1.0   memory length: 112893   epsilon: 0.9744698800005542    steps: 150    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 622   score: 4.0   memory length: 113210   epsilon: 0.9738422200005679    steps: 317    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 623   score: 1.0   memory length: 113360   epsilon: 0.9735452200005743    steps: 150    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 624   score: 2.0   memory length: 113580   epsilon: 0.9731096200005838    steps: 220    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 625   score: 2.0   memory length: 113777   epsilon: 0.9727195600005922    steps: 197    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 626   score: 0.0   memory length: 113900   epsilon: 0.9724760200005975    steps: 123    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 627   score: 0.0   memory length: 114023   epsilon: 0.9722324800006028    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 628   score: 0.0   memory length: 114145   epsilon: 0.971990920000608    steps: 122    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 629   score: 2.0   memory length: 114363   epsilon: 0.9715592800006174    steps: 218    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 630   score: 0.0   memory length: 114485   epsilon: 0.9713177200006227    steps: 122    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 631   score: 0.0   memory length: 114608   epsilon: 0.971074180000628    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 632   score: 0.0   memory length: 114730   epsilon: 0.9708326200006332    steps: 122    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 633   score: 0.0   memory length: 114853   epsilon: 0.9705890800006385    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 634   score: 3.0   memory length: 115101   epsilon: 0.9700980400006491    steps: 248    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 635   score: 2.0   memory length: 115281   epsilon: 0.9697416400006569    steps: 180    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 636   score: 1.0   memory length: 115449   epsilon: 0.9694090000006641    steps: 168    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 637   score: 2.0   memory length: 115629   epsilon: 0.9690526000006718    steps: 180    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 638   score: 0.0   memory length: 115752   epsilon: 0.9688090600006771    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 639   score: 0.0   memory length: 115875   epsilon: 0.9685655200006824    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 640   score: 2.0   memory length: 116073   epsilon: 0.9681734800006909    steps: 198    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 641   score: 0.0   memory length: 116196   epsilon: 0.9679299400006962    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 642   score: 0.0   memory length: 116318   epsilon: 0.9676883800007015    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 643   score: 1.0   memory length: 116469   epsilon: 0.9673894000007079    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 644   score: 1.0   memory length: 116641   epsilon: 0.9670488400007153    steps: 172    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 645   score: 1.0   memory length: 116809   epsilon: 0.9667162000007226    steps: 168    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 646   score: 0.0   memory length: 116931   epsilon: 0.9664746400007278    steps: 122    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 647   score: 4.0   memory length: 117206   epsilon: 0.9659301400007396    steps: 275    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 648   score: 3.0   memory length: 117454   epsilon: 0.9654391000007503    steps: 248    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 649   score: 3.0   memory length: 117680   epsilon: 0.96499162000076    steps: 226    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 650   score: 0.0   memory length: 117803   epsilon: 0.9647480800007653    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 651   score: 0.0   memory length: 117926   epsilon: 0.9645045400007706    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 652   score: 3.0   memory length: 118176   epsilon: 0.9640095400007813    steps: 250    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 653   score: 2.0   memory length: 118394   epsilon: 0.9635779000007907    steps: 218    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 654   score: 3.0   memory length: 118638   epsilon: 0.9630947800008012    steps: 244    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 655   score: 0.0   memory length: 118761   epsilon: 0.9628512400008065    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 656   score: 0.0   memory length: 118884   epsilon: 0.9626077000008118    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 657   score: 5.0   memory length: 119247   epsilon: 0.9618889600008274    steps: 363    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 658   score: 0.0   memory length: 119370   epsilon: 0.9616454200008326    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 659   score: 0.0   memory length: 119493   epsilon: 0.9614018800008379    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 660   score: 1.0   memory length: 119645   epsilon: 0.9611009200008445    steps: 152    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 661   score: 1.0   memory length: 119795   epsilon: 0.9608039200008509    steps: 150    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 662   score: 1.0   memory length: 119967   epsilon: 0.9604633600008583    steps: 172    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 663   score: 0.0   memory length: 120089   epsilon: 0.9602218000008635    steps: 122    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 664   score: 2.0   memory length: 120286   epsilon: 0.959831740000872    steps: 197    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 665   score: 0.0   memory length: 120409   epsilon: 0.9595882000008773    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 666   score: 4.0   memory length: 120705   epsilon: 0.95900212000089    steps: 296    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 667   score: 2.0   memory length: 120925   epsilon: 0.9585665200008995    steps: 220    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 668   score: 0.0   memory length: 121047   epsilon: 0.9583249600009047    steps: 122    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 669   score: 1.0   memory length: 121216   epsilon: 0.957990340000912    steps: 169    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 670   score: 0.0   memory length: 121339   epsilon: 0.9577468000009173    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 671   score: 3.0   memory length: 121552   epsilon: 0.9573250600009264    steps: 213    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 672   score: 3.0   memory length: 121800   epsilon: 0.9568340200009371    steps: 248    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 673   score: 0.0   memory length: 121922   epsilon: 0.9565924600009423    steps: 122    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 674   score: 0.0   memory length: 122045   epsilon: 0.9563489200009476    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 675   score: 1.0   memory length: 122195   epsilon: 0.9560519200009541    steps: 150    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 676   score: 1.0   memory length: 122347   epsilon: 0.9557509600009606    steps: 152    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 677   score: 1.0   memory length: 122516   epsilon: 0.9554163400009679    steps: 169    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 678   score: 2.0   memory length: 122735   epsilon: 0.9549827200009773    steps: 219    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 679   score: 3.0   memory length: 122982   epsilon: 0.9544936600009879    steps: 247    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 680   score: 3.0   memory length: 123210   epsilon: 0.9540422200009977    steps: 228    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 681   score: 3.0   memory length: 123458   epsilon: 0.9535511800010084    steps: 248    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 682   score: 0.0   memory length: 123581   epsilon: 0.9533076400010136    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 683   score: 1.0   memory length: 123751   epsilon: 0.952971040001021    steps: 170    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 684   score: 3.0   memory length: 123981   epsilon: 0.9525156400010308    steps: 230    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 685   score: 3.0   memory length: 124209   epsilon: 0.9520642000010406    steps: 228    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 686   score: 1.0   memory length: 124362   epsilon: 0.9517612600010472    steps: 153    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 687   score: 1.0   memory length: 124532   epsilon: 0.9514246600010545    steps: 170    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 688   score: 2.0   memory length: 124729   epsilon: 0.951034600001063    steps: 197    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 689   score: 2.0   memory length: 124946   epsilon: 0.9506049400010723    steps: 217    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 690   score: 1.0   memory length: 125115   epsilon: 0.9502703200010796    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 691   score: 1.0   memory length: 125266   epsilon: 0.9499713400010861    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 692   score: 2.0   memory length: 125464   epsilon: 0.9495793000010946    steps: 198    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 693   score: 3.0   memory length: 125709   epsilon: 0.9490942000011051    steps: 245    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 694   score: 5.0   memory length: 126051   epsilon: 0.9484170400011198    steps: 342    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 695   score: 0.0   memory length: 126174   epsilon: 0.9481735000011251    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 696   score: 0.0   memory length: 126297   epsilon: 0.9479299600011304    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 697   score: 2.0   memory length: 126515   epsilon: 0.9474983200011398    steps: 218    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 698   score: 0.0   memory length: 126638   epsilon: 0.947254780001145    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 699   score: 1.0   memory length: 126807   epsilon: 0.9469201600011523    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 700   score: 1.0   memory length: 126975   epsilon: 0.9465875200011595    steps: 168    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 701   score: 3.0   memory length: 127242   epsilon: 0.946058860001171    steps: 267    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 702   score: 3.0   memory length: 127468   epsilon: 0.9456113800011807    steps: 226    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 703   score: 1.0   memory length: 127619   epsilon: 0.9453124000011872    steps: 151    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 704   score: 1.0   memory length: 127791   epsilon: 0.9449718400011946    steps: 172    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 705   score: 0.0   memory length: 127914   epsilon: 0.9447283000011999    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 706   score: 1.0   memory length: 128065   epsilon: 0.9444293200012064    steps: 151    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 707   score: 1.0   memory length: 128234   epsilon: 0.9440947000012136    steps: 169    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 708   score: 2.0   memory length: 128452   epsilon: 0.943663060001223    steps: 218    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 709   score: 0.0   memory length: 128575   epsilon: 0.9434195200012283    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 710   score: 1.0   memory length: 128744   epsilon: 0.9430849000012356    steps: 169    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 711   score: 1.0   memory length: 128914   epsilon: 0.9427483000012429    steps: 170    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 712   score: 2.0   memory length: 129114   epsilon: 0.9423523000012515    steps: 200    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 713   score: 4.0   memory length: 129389   epsilon: 0.9418078000012633    steps: 275    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 714   score: 3.0   memory length: 129656   epsilon: 0.9412791400012748    steps: 267    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 715   score: 1.0   memory length: 129825   epsilon: 0.940944520001282    steps: 169    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 716   score: 0.0   memory length: 129947   epsilon: 0.9407029600012873    steps: 122    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 717   score: 2.0   memory length: 130145   epsilon: 0.9403109200012958    steps: 198    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 718   score: 1.0   memory length: 130296   epsilon: 0.9400119400013023    steps: 151    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 719   score: 0.0   memory length: 130419   epsilon: 0.9397684000013076    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 720   score: 0.0   memory length: 130542   epsilon: 0.9395248600013129    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 721   score: 2.0   memory length: 130757   epsilon: 0.9390991600013221    steps: 215    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 722   score: 7.0   memory length: 131168   epsilon: 0.9382853800013398    steps: 411    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 723   score: 1.0   memory length: 131340   epsilon: 0.9379448200013472    steps: 172    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 724   score: 0.0   memory length: 131462   epsilon: 0.9377032600013524    steps: 122    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 725   score: 1.0   memory length: 131612   epsilon: 0.9374062600013588    steps: 150    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 726   score: 2.0   memory length: 131809   epsilon: 0.9370162000013673    steps: 197    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 727   score: 0.0   memory length: 131931   epsilon: 0.9367746400013726    steps: 122    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 728   score: 0.0   memory length: 132054   epsilon: 0.9365311000013778    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 729   score: 0.0   memory length: 132177   epsilon: 0.9362875600013831    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 730   score: 1.0   memory length: 132328   epsilon: 0.9359885800013896    steps: 151    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 731   score: 5.0   memory length: 132649   epsilon: 0.9353530000014034    steps: 321    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 732   score: 3.0   memory length: 132898   epsilon: 0.9348599800014141    steps: 249    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 733   score: 3.0   memory length: 133127   epsilon: 0.934406560001424    steps: 229    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 734   score: 3.0   memory length: 133373   epsilon: 0.9339194800014345    steps: 246    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 735   score: 3.0   memory length: 133601   epsilon: 0.9334680400014443    steps: 228    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 736   score: 2.0   memory length: 133799   epsilon: 0.9330760000014529    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 737   score: 3.0   memory length: 134027   epsilon: 0.9326245600014627    steps: 228    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 738   score: 2.0   memory length: 134207   epsilon: 0.9322681600014704    steps: 180    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 739   score: 1.0   memory length: 134377   epsilon: 0.9319315600014777    steps: 170    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 740   score: 2.0   memory length: 134577   epsilon: 0.9315355600014863    steps: 200    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 741   score: 2.0   memory length: 134775   epsilon: 0.9311435200014948    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 742   score: 2.0   memory length: 134973   epsilon: 0.9307514800015033    steps: 198    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 743   score: 3.0   memory length: 135241   epsilon: 0.9302208400015148    steps: 268    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 744   score: 2.0   memory length: 135457   epsilon: 0.9297931600015241    steps: 216    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 745   score: 2.0   memory length: 135639   epsilon: 0.929432800001532    steps: 182    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 746   score: 2.0   memory length: 135856   epsilon: 0.9290031400015413    steps: 217    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 747   score: 0.0   memory length: 135979   epsilon: 0.9287596000015466    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 748   score: 0.0   memory length: 136102   epsilon: 0.9285160600015518    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 749   score: 3.0   memory length: 136348   epsilon: 0.9280289800015624    steps: 246    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 750   score: 3.0   memory length: 136591   epsilon: 0.9275478400015729    steps: 243    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 751   score: 0.0   memory length: 136713   epsilon: 0.9273062800015781    steps: 122    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 752   score: 0.0   memory length: 136836   epsilon: 0.9270627400015834    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 753   score: 3.0   memory length: 137064   epsilon: 0.9266113000015932    steps: 228    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 754   score: 1.0   memory length: 137232   epsilon: 0.9262786600016004    steps: 168    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 755   score: 1.0   memory length: 137404   epsilon: 0.9259381000016078    steps: 172    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 756   score: 1.0   memory length: 137573   epsilon: 0.9256034800016151    steps: 169    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 757   score: 1.0   memory length: 137745   epsilon: 0.9252629200016225    steps: 172    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 758   score: 2.0   memory length: 137943   epsilon: 0.924870880001631    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 759   score: 0.0   memory length: 138066   epsilon: 0.9246273400016363    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 760   score: 1.0   memory length: 138217   epsilon: 0.9243283600016428    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 761   score: 1.0   memory length: 138386   epsilon: 0.92399374000165    steps: 169    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 762   score: 2.0   memory length: 138606   epsilon: 0.9235581400016595    steps: 220    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 763   score: 1.0   memory length: 138777   epsilon: 0.9232195600016668    steps: 171    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 764   score: 4.0   memory length: 139072   epsilon: 0.9226354600016795    steps: 295    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 765   score: 0.0   memory length: 139195   epsilon: 0.9223919200016848    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 766   score: 1.0   memory length: 139346   epsilon: 0.9220929400016913    steps: 151    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 767   score: 2.0   memory length: 139543   epsilon: 0.9217028800016998    steps: 197    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 768   score: 2.0   memory length: 139741   epsilon: 0.9213108400017083    steps: 198    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 769   score: 2.0   memory length: 139960   epsilon: 0.9208772200017177    steps: 219    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 770   score: 3.0   memory length: 140205   epsilon: 0.9203921200017282    steps: 245    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 771   score: 0.0   memory length: 140327   epsilon: 0.9201505600017335    steps: 122    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 772   score: 2.0   memory length: 140525   epsilon: 0.919758520001742    steps: 198    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 773   score: 2.0   memory length: 140723   epsilon: 0.9193664800017505    steps: 198    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 774   score: 2.0   memory length: 140921   epsilon: 0.918974440001759    steps: 198    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 775   score: 1.0   memory length: 141090   epsilon: 0.9186398200017662    steps: 169    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 776   score: 6.0   memory length: 141431   epsilon: 0.9179646400017809    steps: 341    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 777   score: 0.0   memory length: 141553   epsilon: 0.9177230800017862    steps: 122    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 778   score: 1.0   memory length: 141722   epsilon: 0.9173884600017934    steps: 169    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 779   score: 2.0   memory length: 141920   epsilon: 0.9169964200018019    steps: 198    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 780   score: 1.0   memory length: 142088   epsilon: 0.9166637800018091    steps: 168    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 781   score: 3.0   memory length: 142300   epsilon: 0.9162440200018183    steps: 212    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 782   score: 0.0   memory length: 142423   epsilon: 0.9160004800018235    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 783   score: 0.0   memory length: 142545   epsilon: 0.9157589200018288    steps: 122    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 784   score: 2.0   memory length: 142743   epsilon: 0.9153668800018373    steps: 198    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 785   score: 2.0   memory length: 142961   epsilon: 0.9149352400018467    steps: 218    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 786   score: 3.0   memory length: 143190   epsilon: 0.9144818200018565    steps: 229    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 787   score: 3.0   memory length: 143403   epsilon: 0.9140600800018657    steps: 213    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 788   score: 0.0   memory length: 143526   epsilon: 0.913816540001871    steps: 123    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 789   score: 0.0   memory length: 143649   epsilon: 0.9135730000018762    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 790   score: 1.0   memory length: 143800   epsilon: 0.9132740200018827    steps: 151    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 791   score: 3.0   memory length: 144047   epsilon: 0.9127849600018934    steps: 247    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 792   score: 2.0   memory length: 144245   epsilon: 0.9123929200019019    steps: 198    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 793   score: 2.0   memory length: 144462   epsilon: 0.9119632600019112    steps: 217    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 794   score: 0.0   memory length: 144585   epsilon: 0.9117197200019165    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 795   score: 4.0   memory length: 144879   epsilon: 0.9111376000019291    steps: 294    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 796   score: 1.0   memory length: 145030   epsilon: 0.9108386200019356    steps: 151    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 797   score: 2.0   memory length: 145227   epsilon: 0.9104485600019441    steps: 197    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 798   score: 9.0   memory length: 145718   epsilon: 0.9094763800019652    steps: 491    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 799   score: 1.0   memory length: 145889   epsilon: 0.9091378000019725    steps: 171    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 800   score: 1.0   memory length: 146060   epsilon: 0.9087992200019799    steps: 171    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 801   score: 4.0   memory length: 146335   epsilon: 0.9082547200019917    steps: 275    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 802   score: 2.0   memory length: 146532   epsilon: 0.9078646600020002    steps: 197    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 803   score: 3.0   memory length: 146779   epsilon: 0.9073756000020108    steps: 247    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 804   score: 0.0   memory length: 146902   epsilon: 0.9071320600020161    steps: 123    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 805   score: 2.0   memory length: 147117   epsilon: 0.9067063600020253    steps: 215    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 806   score: 3.0   memory length: 147382   epsilon: 0.9061816600020367    steps: 265    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 807   score: 1.0   memory length: 147551   epsilon: 0.905847040002044    steps: 169    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 808   score: 3.0   memory length: 147780   epsilon: 0.9053936200020538    steps: 229    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 809   score: 1.0   memory length: 147930   epsilon: 0.9050966200020603    steps: 150    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 810   score: 2.0   memory length: 148127   epsilon: 0.9047065600020687    steps: 197    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 811   score: 4.0   memory length: 148441   epsilon: 0.9040848400020822    steps: 314    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 812   score: 5.0   memory length: 148804   epsilon: 0.9033661000020978    steps: 363    lr: 0.0001     evaluation reward: 1.85\n",
      "episode: 813   score: 0.0   memory length: 148926   epsilon: 0.9031245400021031    steps: 122    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 814   score: 2.0   memory length: 149143   epsilon: 0.9026948800021124    steps: 217    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 815   score: 1.0   memory length: 149294   epsilon: 0.9023959000021189    steps: 151    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 816   score: 3.0   memory length: 149520   epsilon: 0.9019484200021286    steps: 226    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 817   score: 1.0   memory length: 149691   epsilon: 0.901609840002136    steps: 171    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 818   score: 2.0   memory length: 149908   epsilon: 0.9011801800021453    steps: 217    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 819   score: 2.0   memory length: 150106   epsilon: 0.9007881400021538    steps: 198    lr: 0.0001     evaluation reward: 1.85\n",
      "episode: 820   score: 2.0   memory length: 150304   epsilon: 0.9003961000021623    steps: 198    lr: 0.0001     evaluation reward: 1.87\n",
      "episode: 821   score: 2.0   memory length: 150524   epsilon: 0.8999605000021718    steps: 220    lr: 0.0001     evaluation reward: 1.87\n",
      "episode: 822   score: 5.0   memory length: 150872   epsilon: 0.8992714600021867    steps: 348    lr: 0.0001     evaluation reward: 1.85\n",
      "episode: 823   score: 0.0   memory length: 150994   epsilon: 0.899029900002192    steps: 122    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 824   score: 0.0   memory length: 151116   epsilon: 0.8987883400021972    steps: 122    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 825   score: 0.0   memory length: 151239   epsilon: 0.8985448000022025    steps: 123    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 826   score: 0.0   memory length: 151362   epsilon: 0.8983012600022078    steps: 123    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 827   score: 2.0   memory length: 151559   epsilon: 0.8979112000022162    steps: 197    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 828   score: 1.0   memory length: 151729   epsilon: 0.8975746000022236    steps: 170    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 829   score: 5.0   memory length: 152079   epsilon: 0.8968816000022386    steps: 350    lr: 0.0001     evaluation reward: 1.89\n",
      "episode: 830   score: 1.0   memory length: 152250   epsilon: 0.896543020002246    steps: 171    lr: 0.0001     evaluation reward: 1.89\n",
      "episode: 831   score: 1.0   memory length: 152401   epsilon: 0.8962440400022524    steps: 151    lr: 0.0001     evaluation reward: 1.85\n",
      "episode: 832   score: 1.0   memory length: 152570   epsilon: 0.8959094200022597    steps: 169    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 833   score: 0.0   memory length: 152693   epsilon: 0.895665880002265    steps: 123    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 834   score: 2.0   memory length: 152894   epsilon: 0.8952679000022736    steps: 201    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 835   score: 3.0   memory length: 153158   epsilon: 0.894745180002285    steps: 264    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 836   score: 5.0   memory length: 153482   epsilon: 0.8941036600022989    steps: 324    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 837   score: 1.0   memory length: 153632   epsilon: 0.8938066600023054    steps: 150    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 838   score: 0.0   memory length: 153755   epsilon: 0.8935631200023106    steps: 123    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 839   score: 2.0   memory length: 153976   epsilon: 0.8931255400023201    steps: 221    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 840   score: 2.0   memory length: 154199   epsilon: 0.8926840000023297    steps: 223    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 841   score: 3.0   memory length: 154424   epsilon: 0.8922385000023394    steps: 225    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 842   score: 1.0   memory length: 154593   epsilon: 0.8919038800023467    steps: 169    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 843   score: 2.0   memory length: 154790   epsilon: 0.8915138200023551    steps: 197    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 844   score: 2.0   memory length: 154987   epsilon: 0.8911237600023636    steps: 197    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 845   score: 5.0   memory length: 155350   epsilon: 0.8904050200023792    steps: 363    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 846   score: 1.0   memory length: 155520   epsilon: 0.8900684200023865    steps: 170    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 847   score: 1.0   memory length: 155670   epsilon: 0.889771420002393    steps: 150    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 848   score: 3.0   memory length: 155898   epsilon: 0.8893199800024028    steps: 228    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 849   score: 1.0   memory length: 156066   epsilon: 0.88898734000241    steps: 168    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 850   score: 4.0   memory length: 156340   epsilon: 0.8884448200024218    steps: 274    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 851   score: 3.0   memory length: 156566   epsilon: 0.8879973400024315    steps: 226    lr: 0.0001     evaluation reward: 1.86\n",
      "episode: 852   score: 2.0   memory length: 156786   epsilon: 0.8875617400024409    steps: 220    lr: 0.0001     evaluation reward: 1.88\n",
      "episode: 853   score: 1.0   memory length: 156956   epsilon: 0.8872251400024482    steps: 170    lr: 0.0001     evaluation reward: 1.86\n",
      "episode: 854   score: 1.0   memory length: 157127   epsilon: 0.8868865600024556    steps: 171    lr: 0.0001     evaluation reward: 1.86\n",
      "episode: 855   score: 2.0   memory length: 157345   epsilon: 0.886454920002465    steps: 218    lr: 0.0001     evaluation reward: 1.87\n",
      "episode: 856   score: 4.0   memory length: 157602   epsilon: 0.885946060002476    steps: 257    lr: 0.0001     evaluation reward: 1.9\n",
      "episode: 857   score: 3.0   memory length: 157845   epsilon: 0.8854649200024864    steps: 243    lr: 0.0001     evaluation reward: 1.92\n",
      "episode: 858   score: 3.0   memory length: 158071   epsilon: 0.8850174400024962    steps: 226    lr: 0.0001     evaluation reward: 1.93\n",
      "episode: 859   score: 5.0   memory length: 158376   epsilon: 0.8844135400025093    steps: 305    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 860   score: 1.0   memory length: 158527   epsilon: 0.8841145600025158    steps: 151    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 861   score: 5.0   memory length: 158814   epsilon: 0.8835463000025281    steps: 287    lr: 0.0001     evaluation reward: 2.02\n",
      "episode: 862   score: 0.0   memory length: 158937   epsilon: 0.8833027600025334    steps: 123    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 863   score: 3.0   memory length: 159163   epsilon: 0.8828552800025431    steps: 226    lr: 0.0001     evaluation reward: 2.02\n",
      "episode: 864   score: 1.0   memory length: 159332   epsilon: 0.8825206600025504    steps: 169    lr: 0.0001     evaluation reward: 1.99\n",
      "episode: 865   score: 3.0   memory length: 159561   epsilon: 0.8820672400025602    steps: 229    lr: 0.0001     evaluation reward: 2.02\n",
      "episode: 866   score: 1.0   memory length: 159712   epsilon: 0.8817682600025667    steps: 151    lr: 0.0001     evaluation reward: 2.02\n",
      "episode: 867   score: 0.0   memory length: 159835   epsilon: 0.881524720002572    steps: 123    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 868   score: 0.0   memory length: 159957   epsilon: 0.8812831600025772    steps: 122    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 869   score: 2.0   memory length: 160155   epsilon: 0.8808911200025857    steps: 198    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 870   score: 1.0   memory length: 160306   epsilon: 0.8805921400025922    steps: 151    lr: 0.0001     evaluation reward: 1.96\n",
      "episode: 871   score: 2.0   memory length: 160504   epsilon: 0.8802001000026007    steps: 198    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 872   score: 3.0   memory length: 160769   epsilon: 0.8796754000026121    steps: 265    lr: 0.0001     evaluation reward: 1.99\n",
      "episode: 873   score: 3.0   memory length: 160999   epsilon: 0.879220000002622    steps: 230    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 874   score: 0.0   memory length: 161122   epsilon: 0.8789764600026273    steps: 123    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 875   score: 1.0   memory length: 161293   epsilon: 0.8786378800026347    steps: 171    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 876   score: 2.0   memory length: 161491   epsilon: 0.8782458400026432    steps: 198    lr: 0.0001     evaluation reward: 1.94\n",
      "episode: 877   score: 1.0   memory length: 161642   epsilon: 0.8779468600026497    steps: 151    lr: 0.0001     evaluation reward: 1.95\n",
      "episode: 878   score: 2.0   memory length: 161860   epsilon: 0.877515220002659    steps: 218    lr: 0.0001     evaluation reward: 1.96\n",
      "episode: 879   score: 2.0   memory length: 162058   epsilon: 0.8771231800026675    steps: 198    lr: 0.0001     evaluation reward: 1.96\n",
      "episode: 880   score: 1.0   memory length: 162209   epsilon: 0.876824200002674    steps: 151    lr: 0.0001     evaluation reward: 1.96\n",
      "episode: 881   score: 3.0   memory length: 162456   epsilon: 0.8763351400026846    steps: 247    lr: 0.0001     evaluation reward: 1.96\n",
      "episode: 882   score: 3.0   memory length: 162704   epsilon: 0.8758441000026953    steps: 248    lr: 0.0001     evaluation reward: 1.99\n",
      "episode: 883   score: 1.0   memory length: 162876   epsilon: 0.8755035400027027    steps: 172    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 884   score: 1.0   memory length: 163026   epsilon: 0.8752065400027091    steps: 150    lr: 0.0001     evaluation reward: 1.99\n",
      "episode: 885   score: 3.0   memory length: 163276   epsilon: 0.8747115400027199    steps: 250    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 886   score: 1.0   memory length: 163445   epsilon: 0.8743769200027272    steps: 169    lr: 0.0001     evaluation reward: 1.98\n",
      "episode: 887   score: 4.0   memory length: 163720   epsilon: 0.873832420002739    steps: 275    lr: 0.0001     evaluation reward: 1.99\n",
      "episode: 888   score: 2.0   memory length: 163942   epsilon: 0.8733928600027485    steps: 222    lr: 0.0001     evaluation reward: 2.01\n",
      "episode: 889   score: 4.0   memory length: 164236   epsilon: 0.8728107400027612    steps: 294    lr: 0.0001     evaluation reward: 2.05\n",
      "episode: 890   score: 1.0   memory length: 164387   epsilon: 0.8725117600027676    steps: 151    lr: 0.0001     evaluation reward: 2.05\n",
      "episode: 891   score: 2.0   memory length: 164587   epsilon: 0.8721157600027762    steps: 200    lr: 0.0001     evaluation reward: 2.04\n",
      "episode: 892   score: 2.0   memory length: 164805   epsilon: 0.8716841200027856    steps: 218    lr: 0.0001     evaluation reward: 2.04\n",
      "episode: 893   score: 1.0   memory length: 164957   epsilon: 0.8713831600027921    steps: 152    lr: 0.0001     evaluation reward: 2.03\n",
      "episode: 894   score: 2.0   memory length: 165174   epsilon: 0.8709535000028015    steps: 217    lr: 0.0001     evaluation reward: 2.05\n",
      "episode: 895   score: 4.0   memory length: 165469   epsilon: 0.8703694000028142    steps: 295    lr: 0.0001     evaluation reward: 2.05\n",
      "episode: 896   score: 1.0   memory length: 165640   epsilon: 0.8700308200028215    steps: 171    lr: 0.0001     evaluation reward: 2.05\n",
      "episode: 897   score: 4.0   memory length: 165934   epsilon: 0.8694487000028341    steps: 294    lr: 0.0001     evaluation reward: 2.07\n",
      "episode: 898   score: 3.0   memory length: 166164   epsilon: 0.868993300002844    steps: 230    lr: 0.0001     evaluation reward: 2.01\n",
      "episode: 899   score: 1.0   memory length: 166333   epsilon: 0.8686586800028513    steps: 169    lr: 0.0001     evaluation reward: 2.01\n",
      "episode: 900   score: 7.0   memory length: 166741   epsilon: 0.8678508400028688    steps: 408    lr: 0.0001     evaluation reward: 2.07\n",
      "episode: 901   score: 4.0   memory length: 167017   epsilon: 0.8673043600028807    steps: 276    lr: 0.0001     evaluation reward: 2.07\n",
      "episode: 902   score: 2.0   memory length: 167196   epsilon: 0.8669499400028884    steps: 179    lr: 0.0001     evaluation reward: 2.07\n",
      "episode: 903   score: 3.0   memory length: 167421   epsilon: 0.8665044400028981    steps: 225    lr: 0.0001     evaluation reward: 2.07\n",
      "episode: 904   score: 1.0   memory length: 167591   epsilon: 0.8661678400029054    steps: 170    lr: 0.0001     evaluation reward: 2.08\n",
      "episode: 905   score: 3.0   memory length: 167860   epsilon: 0.8656352200029169    steps: 269    lr: 0.0001     evaluation reward: 2.09\n",
      "episode: 906   score: 3.0   memory length: 168087   epsilon: 0.8651857600029267    steps: 227    lr: 0.0001     evaluation reward: 2.09\n",
      "episode: 907   score: 1.0   memory length: 168239   epsilon: 0.8648848000029332    steps: 152    lr: 0.0001     evaluation reward: 2.09\n",
      "episode: 908   score: 4.0   memory length: 168538   epsilon: 0.8642927800029461    steps: 299    lr: 0.0001     evaluation reward: 2.1\n",
      "episode: 909   score: 1.0   memory length: 168689   epsilon: 0.8639938000029526    steps: 151    lr: 0.0001     evaluation reward: 2.1\n",
      "episode: 910   score: 3.0   memory length: 168916   epsilon: 0.8635443400029623    steps: 227    lr: 0.0001     evaluation reward: 2.11\n",
      "episode: 911   score: 2.0   memory length: 169113   epsilon: 0.8631542800029708    steps: 197    lr: 0.0001     evaluation reward: 2.09\n",
      "episode: 912   score: 2.0   memory length: 169295   epsilon: 0.8627939200029786    steps: 182    lr: 0.0001     evaluation reward: 2.06\n",
      "episode: 913   score: 2.0   memory length: 169476   epsilon: 0.8624355400029864    steps: 181    lr: 0.0001     evaluation reward: 2.08\n",
      "episode: 914   score: 6.0   memory length: 169859   epsilon: 0.8616772000030029    steps: 383    lr: 0.0001     evaluation reward: 2.12\n",
      "episode: 915   score: 1.0   memory length: 170010   epsilon: 0.8613782200030093    steps: 151    lr: 0.0001     evaluation reward: 2.12\n",
      "episode: 916   score: 2.0   memory length: 170227   epsilon: 0.8609485600030187    steps: 217    lr: 0.0001     evaluation reward: 2.11\n",
      "episode: 917   score: 3.0   memory length: 170438   epsilon: 0.8605307800030277    steps: 211    lr: 0.0001     evaluation reward: 2.13\n",
      "episode: 918   score: 3.0   memory length: 170665   epsilon: 0.8600813200030375    steps: 227    lr: 0.0001     evaluation reward: 2.14\n",
      "episode: 919   score: 0.0   memory length: 170788   epsilon: 0.8598377800030428    steps: 123    lr: 0.0001     evaluation reward: 2.12\n",
      "episode: 920   score: 7.0   memory length: 171229   epsilon: 0.8589646000030617    steps: 441    lr: 0.0001     evaluation reward: 2.17\n",
      "episode: 921   score: 1.0   memory length: 171398   epsilon: 0.858629980003069    steps: 169    lr: 0.0001     evaluation reward: 2.16\n",
      "episode: 922   score: 0.0   memory length: 171521   epsilon: 0.8583864400030743    steps: 123    lr: 0.0001     evaluation reward: 2.11\n",
      "episode: 923   score: 1.0   memory length: 171672   epsilon: 0.8580874600030808    steps: 151    lr: 0.0001     evaluation reward: 2.12\n",
      "episode: 924   score: 4.0   memory length: 171965   epsilon: 0.8575073200030934    steps: 293    lr: 0.0001     evaluation reward: 2.16\n",
      "episode: 925   score: 5.0   memory length: 172294   epsilon: 0.8568559000031075    steps: 329    lr: 0.0001     evaluation reward: 2.21\n",
      "episode: 926   score: 6.0   memory length: 172690   epsilon: 0.8560718200031245    steps: 396    lr: 0.0001     evaluation reward: 2.27\n",
      "episode: 927   score: 3.0   memory length: 172916   epsilon: 0.8556243400031343    steps: 226    lr: 0.0001     evaluation reward: 2.28\n",
      "episode: 928   score: 0.0   memory length: 173039   epsilon: 0.8553808000031395    steps: 123    lr: 0.0001     evaluation reward: 2.27\n",
      "episode: 929   score: 2.0   memory length: 173255   epsilon: 0.8549531200031488    steps: 216    lr: 0.0001     evaluation reward: 2.24\n",
      "episode: 930   score: 2.0   memory length: 173453   epsilon: 0.8545610800031573    steps: 198    lr: 0.0001     evaluation reward: 2.25\n",
      "episode: 931   score: 3.0   memory length: 173699   epsilon: 0.8540740000031679    steps: 246    lr: 0.0001     evaluation reward: 2.27\n",
      "episode: 932   score: 3.0   memory length: 173928   epsilon: 0.8536205800031778    steps: 229    lr: 0.0001     evaluation reward: 2.29\n",
      "episode: 933   score: 2.0   memory length: 174126   epsilon: 0.8532285400031863    steps: 198    lr: 0.0001     evaluation reward: 2.31\n",
      "episode: 934   score: 4.0   memory length: 174401   epsilon: 0.8526840400031981    steps: 275    lr: 0.0001     evaluation reward: 2.33\n",
      "episode: 935   score: 3.0   memory length: 174652   epsilon: 0.8521870600032089    steps: 251    lr: 0.0001     evaluation reward: 2.33\n",
      "episode: 936   score: 3.0   memory length: 174918   epsilon: 0.8516603800032203    steps: 266    lr: 0.0001     evaluation reward: 2.31\n",
      "episode: 937   score: 1.0   memory length: 175087   epsilon: 0.8513257600032276    steps: 169    lr: 0.0001     evaluation reward: 2.31\n",
      "episode: 938   score: 3.0   memory length: 175314   epsilon: 0.8508763000032373    steps: 227    lr: 0.0001     evaluation reward: 2.34\n",
      "episode: 939   score: 5.0   memory length: 175679   epsilon: 0.850153600003253    steps: 365    lr: 0.0001     evaluation reward: 2.37\n",
      "episode: 940   score: 2.0   memory length: 175860   epsilon: 0.8497952200032608    steps: 181    lr: 0.0001     evaluation reward: 2.37\n",
      "episode: 941   score: 3.0   memory length: 176088   epsilon: 0.8493437800032706    steps: 228    lr: 0.0001     evaluation reward: 2.37\n",
      "episode: 942   score: 1.0   memory length: 176239   epsilon: 0.8490448000032771    steps: 151    lr: 0.0001     evaluation reward: 2.37\n",
      "episode: 943   score: 3.0   memory length: 176503   epsilon: 0.8485220800032884    steps: 264    lr: 0.0001     evaluation reward: 2.38\n",
      "episode: 944   score: 4.0   memory length: 176803   epsilon: 0.8479280800033013    steps: 300    lr: 0.0001     evaluation reward: 2.4\n",
      "episode: 945   score: 3.0   memory length: 177051   epsilon: 0.847437040003312    steps: 248    lr: 0.0001     evaluation reward: 2.38\n",
      "episode: 946   score: 10.0   memory length: 177529   epsilon: 0.8464906000033325    steps: 478    lr: 0.0001     evaluation reward: 2.47\n",
      "episode: 947   score: 0.0   memory length: 177652   epsilon: 0.8462470600033378    steps: 123    lr: 0.0001     evaluation reward: 2.46\n",
      "episode: 948   score: 3.0   memory length: 177899   epsilon: 0.8457580000033484    steps: 247    lr: 0.0001     evaluation reward: 2.46\n",
      "episode: 949   score: 0.0   memory length: 178022   epsilon: 0.8455144600033537    steps: 123    lr: 0.0001     evaluation reward: 2.45\n",
      "episode: 950   score: 1.0   memory length: 178173   epsilon: 0.8452154800033602    steps: 151    lr: 0.0001     evaluation reward: 2.42\n",
      "episode: 951   score: 3.0   memory length: 178399   epsilon: 0.8447680000033699    steps: 226    lr: 0.0001     evaluation reward: 2.42\n",
      "episode: 952   score: 2.0   memory length: 178616   epsilon: 0.8443383400033793    steps: 217    lr: 0.0001     evaluation reward: 2.42\n",
      "episode: 953   score: 0.0   memory length: 178739   epsilon: 0.8440948000033845    steps: 123    lr: 0.0001     evaluation reward: 2.41\n",
      "episode: 954   score: 2.0   memory length: 178940   epsilon: 0.8436968200033932    steps: 201    lr: 0.0001     evaluation reward: 2.42\n",
      "episode: 955   score: 3.0   memory length: 179184   epsilon: 0.8432137000034037    steps: 244    lr: 0.0001     evaluation reward: 2.43\n",
      "episode: 956   score: 0.0   memory length: 179307   epsilon: 0.842970160003409    steps: 123    lr: 0.0001     evaluation reward: 2.39\n",
      "episode: 957   score: 2.0   memory length: 179527   epsilon: 0.8425345600034184    steps: 220    lr: 0.0001     evaluation reward: 2.38\n",
      "episode: 958   score: 4.0   memory length: 179824   epsilon: 0.8419465000034312    steps: 297    lr: 0.0001     evaluation reward: 2.39\n",
      "episode: 959   score: 3.0   memory length: 180072   epsilon: 0.8414554600034418    steps: 248    lr: 0.0001     evaluation reward: 2.37\n",
      "episode: 960   score: 1.0   memory length: 180243   epsilon: 0.8411168800034492    steps: 171    lr: 0.0001     evaluation reward: 2.37\n",
      "episode: 961   score: 1.0   memory length: 180395   epsilon: 0.8408159200034557    steps: 152    lr: 0.0001     evaluation reward: 2.33\n",
      "episode: 962   score: 2.0   memory length: 180612   epsilon: 0.8403862600034651    steps: 217    lr: 0.0001     evaluation reward: 2.35\n",
      "episode: 963   score: 5.0   memory length: 180934   epsilon: 0.8397487000034789    steps: 322    lr: 0.0001     evaluation reward: 2.37\n",
      "episode: 964   score: 1.0   memory length: 181085   epsilon: 0.8394497200034854    steps: 151    lr: 0.0001     evaluation reward: 2.37\n",
      "episode: 965   score: 3.0   memory length: 181311   epsilon: 0.8390022400034951    steps: 226    lr: 0.0001     evaluation reward: 2.37\n",
      "episode: 966   score: 1.0   memory length: 181480   epsilon: 0.8386676200035024    steps: 169    lr: 0.0001     evaluation reward: 2.37\n",
      "episode: 967   score: 0.0   memory length: 181603   epsilon: 0.8384240800035077    steps: 123    lr: 0.0001     evaluation reward: 2.37\n",
      "episode: 968   score: 2.0   memory length: 181800   epsilon: 0.8380340200035161    steps: 197    lr: 0.0001     evaluation reward: 2.39\n",
      "episode: 969   score: 0.0   memory length: 181922   epsilon: 0.8377924600035214    steps: 122    lr: 0.0001     evaluation reward: 2.37\n",
      "episode: 970   score: 0.0   memory length: 182045   epsilon: 0.8375489200035267    steps: 123    lr: 0.0001     evaluation reward: 2.36\n",
      "episode: 971   score: 1.0   memory length: 182217   epsilon: 0.837208360003534    steps: 172    lr: 0.0001     evaluation reward: 2.35\n",
      "episode: 972   score: 2.0   memory length: 182435   epsilon: 0.8367767200035434    steps: 218    lr: 0.0001     evaluation reward: 2.34\n",
      "episode: 973   score: 3.0   memory length: 182649   epsilon: 0.8363530000035526    steps: 214    lr: 0.0001     evaluation reward: 2.34\n",
      "episode: 974   score: 1.0   memory length: 182819   epsilon: 0.8360164000035599    steps: 170    lr: 0.0001     evaluation reward: 2.35\n",
      "episode: 975   score: 4.0   memory length: 183094   epsilon: 0.8354719000035717    steps: 275    lr: 0.0001     evaluation reward: 2.38\n",
      "episode: 976   score: 3.0   memory length: 183342   epsilon: 0.8349808600035824    steps: 248    lr: 0.0001     evaluation reward: 2.39\n",
      "episode: 977   score: 6.0   memory length: 183698   epsilon: 0.8342759800035977    steps: 356    lr: 0.0001     evaluation reward: 2.44\n",
      "episode: 978   score: 3.0   memory length: 183964   epsilon: 0.8337493000036091    steps: 266    lr: 0.0001     evaluation reward: 2.45\n",
      "episode: 979   score: 10.0   memory length: 184373   epsilon: 0.8329394800036267    steps: 409    lr: 0.0001     evaluation reward: 2.53\n",
      "episode: 980   score: 0.0   memory length: 184496   epsilon: 0.832695940003632    steps: 123    lr: 0.0001     evaluation reward: 2.52\n",
      "episode: 981   score: 2.0   memory length: 184693   epsilon: 0.8323058800036405    steps: 197    lr: 0.0001     evaluation reward: 2.51\n",
      "episode: 982   score: 4.0   memory length: 184988   epsilon: 0.8317217800036532    steps: 295    lr: 0.0001     evaluation reward: 2.52\n",
      "episode: 983   score: 2.0   memory length: 185186   epsilon: 0.8313297400036617    steps: 198    lr: 0.0001     evaluation reward: 2.53\n",
      "episode: 984   score: 4.0   memory length: 185462   epsilon: 0.8307832600036735    steps: 276    lr: 0.0001     evaluation reward: 2.56\n",
      "episode: 985   score: 2.0   memory length: 185680   epsilon: 0.8303516200036829    steps: 218    lr: 0.0001     evaluation reward: 2.55\n",
      "episode: 986   score: 2.0   memory length: 185878   epsilon: 0.8299595800036914    steps: 198    lr: 0.0001     evaluation reward: 2.56\n",
      "episode: 987   score: 2.0   memory length: 186057   epsilon: 0.8296051600036991    steps: 179    lr: 0.0001     evaluation reward: 2.54\n",
      "episode: 988   score: 0.0   memory length: 186180   epsilon: 0.8293616200037044    steps: 123    lr: 0.0001     evaluation reward: 2.52\n",
      "episode: 989   score: 0.0   memory length: 186303   epsilon: 0.8291180800037097    steps: 123    lr: 0.0001     evaluation reward: 2.48\n",
      "episode: 990   score: 2.0   memory length: 186503   epsilon: 0.8287220800037183    steps: 200    lr: 0.0001     evaluation reward: 2.49\n",
      "episode: 991   score: 3.0   memory length: 186771   epsilon: 0.8281914400037298    steps: 268    lr: 0.0001     evaluation reward: 2.5\n",
      "episode: 992   score: 1.0   memory length: 186940   epsilon: 0.8278568200037371    steps: 169    lr: 0.0001     evaluation reward: 2.49\n",
      "episode: 993   score: 3.0   memory length: 187187   epsilon: 0.8273677600037477    steps: 247    lr: 0.0001     evaluation reward: 2.51\n",
      "episode: 994   score: 6.0   memory length: 187576   epsilon: 0.8265975400037644    steps: 389    lr: 0.0001     evaluation reward: 2.55\n",
      "episode: 995   score: 1.0   memory length: 187727   epsilon: 0.8262985600037709    steps: 151    lr: 0.0001     evaluation reward: 2.52\n",
      "episode: 996   score: 0.0   memory length: 187850   epsilon: 0.8260550200037762    steps: 123    lr: 0.0001     evaluation reward: 2.51\n",
      "episode: 997   score: 3.0   memory length: 188077   epsilon: 0.8256055600037859    steps: 227    lr: 0.0001     evaluation reward: 2.5\n",
      "episode: 998   score: 2.0   memory length: 188274   epsilon: 0.8252155000037944    steps: 197    lr: 0.0001     evaluation reward: 2.49\n",
      "episode: 999   score: 3.0   memory length: 188524   epsilon: 0.8247205000038051    steps: 250    lr: 0.0001     evaluation reward: 2.51\n",
      "episode: 1000   score: 2.0   memory length: 188741   epsilon: 0.8242908400038145    steps: 217    lr: 0.0001     evaluation reward: 2.46\n",
      "episode: 1001   score: 3.0   memory length: 188988   epsilon: 0.8238017800038251    steps: 247    lr: 0.0001     evaluation reward: 2.45\n",
      "episode: 1002   score: 4.0   memory length: 189265   epsilon: 0.823253320003837    steps: 277    lr: 0.0001     evaluation reward: 2.47\n",
      "episode: 1003   score: 0.0   memory length: 189388   epsilon: 0.8230097800038423    steps: 123    lr: 0.0001     evaluation reward: 2.44\n",
      "episode: 1004   score: 2.0   memory length: 189586   epsilon: 0.8226177400038508    steps: 198    lr: 0.0001     evaluation reward: 2.45\n",
      "episode: 1005   score: 2.0   memory length: 189784   epsilon: 0.8222257000038593    steps: 198    lr: 0.0001     evaluation reward: 2.44\n",
      "episode: 1006   score: 1.0   memory length: 189956   epsilon: 0.8218851400038667    steps: 172    lr: 0.0001     evaluation reward: 2.42\n",
      "episode: 1007   score: 4.0   memory length: 190230   epsilon: 0.8213426200038785    steps: 274    lr: 0.0001     evaluation reward: 2.45\n",
      "episode: 1008   score: 2.0   memory length: 190428   epsilon: 0.820950580003887    steps: 198    lr: 0.0001     evaluation reward: 2.43\n",
      "episode: 1009   score: 4.0   memory length: 190721   epsilon: 0.8203704400038996    steps: 293    lr: 0.0001     evaluation reward: 2.46\n",
      "episode: 1010   score: 2.0   memory length: 190919   epsilon: 0.8199784000039081    steps: 198    lr: 0.0001     evaluation reward: 2.45\n",
      "episode: 1011   score: 1.0   memory length: 191090   epsilon: 0.8196398200039154    steps: 171    lr: 0.0001     evaluation reward: 2.44\n",
      "episode: 1012   score: 2.0   memory length: 191290   epsilon: 0.819243820003924    steps: 200    lr: 0.0001     evaluation reward: 2.44\n",
      "episode: 1013   score: 6.0   memory length: 191657   epsilon: 0.8185171600039398    steps: 367    lr: 0.0001     evaluation reward: 2.48\n",
      "episode: 1014   score: 4.0   memory length: 191974   epsilon: 0.8178895000039534    steps: 317    lr: 0.0001     evaluation reward: 2.46\n",
      "episode: 1015   score: 2.0   memory length: 192192   epsilon: 0.8174578600039628    steps: 218    lr: 0.0001     evaluation reward: 2.47\n",
      "episode: 1016   score: 2.0   memory length: 192390   epsilon: 0.8170658200039713    steps: 198    lr: 0.0001     evaluation reward: 2.47\n",
      "episode: 1017   score: 3.0   memory length: 192636   epsilon: 0.8165787400039819    steps: 246    lr: 0.0001     evaluation reward: 2.47\n",
      "episode: 1018   score: 0.0   memory length: 192758   epsilon: 0.8163371800039871    steps: 122    lr: 0.0001     evaluation reward: 2.44\n",
      "episode: 1019   score: 2.0   memory length: 192955   epsilon: 0.8159471200039956    steps: 197    lr: 0.0001     evaluation reward: 2.46\n",
      "episode: 1020   score: 2.0   memory length: 193154   epsilon: 0.8155531000040042    steps: 199    lr: 0.0001     evaluation reward: 2.41\n",
      "episode: 1021   score: 6.0   memory length: 193490   epsilon: 0.8148878200040186    steps: 336    lr: 0.0001     evaluation reward: 2.46\n",
      "episode: 1022   score: 2.0   memory length: 193691   epsilon: 0.8144898400040272    steps: 201    lr: 0.0001     evaluation reward: 2.48\n",
      "episode: 1023   score: 1.0   memory length: 193842   epsilon: 0.8141908600040337    steps: 151    lr: 0.0001     evaluation reward: 2.48\n",
      "episode: 1024   score: 2.0   memory length: 194040   epsilon: 0.8137988200040422    steps: 198    lr: 0.0001     evaluation reward: 2.46\n",
      "episode: 1025   score: 2.0   memory length: 194258   epsilon: 0.8133671800040516    steps: 218    lr: 0.0001     evaluation reward: 2.43\n",
      "episode: 1026   score: 1.0   memory length: 194409   epsilon: 0.8130682000040581    steps: 151    lr: 0.0001     evaluation reward: 2.38\n",
      "episode: 1027   score: 8.0   memory length: 194877   epsilon: 0.8121415600040782    steps: 468    lr: 0.0001     evaluation reward: 2.43\n",
      "episode: 1028   score: 1.0   memory length: 195028   epsilon: 0.8118425800040847    steps: 151    lr: 0.0001     evaluation reward: 2.44\n",
      "episode: 1029   score: 3.0   memory length: 195241   epsilon: 0.8114208400040939    steps: 213    lr: 0.0001     evaluation reward: 2.45\n",
      "episode: 1030   score: 3.0   memory length: 195470   epsilon: 0.8109674200041037    steps: 229    lr: 0.0001     evaluation reward: 2.46\n",
      "episode: 1031   score: 4.0   memory length: 195737   epsilon: 0.8104387600041152    steps: 267    lr: 0.0001     evaluation reward: 2.47\n",
      "episode: 1032   score: 3.0   memory length: 195963   epsilon: 0.8099912800041249    steps: 226    lr: 0.0001     evaluation reward: 2.47\n",
      "episode: 1033   score: 3.0   memory length: 196190   epsilon: 0.8095418200041347    steps: 227    lr: 0.0001     evaluation reward: 2.48\n",
      "episode: 1034   score: 2.0   memory length: 196388   epsilon: 0.8091497800041432    steps: 198    lr: 0.0001     evaluation reward: 2.46\n",
      "episode: 1035   score: 4.0   memory length: 196681   epsilon: 0.8085696400041558    steps: 293    lr: 0.0001     evaluation reward: 2.47\n",
      "episode: 1036   score: 6.0   memory length: 197055   epsilon: 0.8078291200041718    steps: 374    lr: 0.0001     evaluation reward: 2.5\n",
      "episode: 1037   score: 1.0   memory length: 197224   epsilon: 0.8074945000041791    steps: 169    lr: 0.0001     evaluation reward: 2.5\n",
      "episode: 1038   score: 3.0   memory length: 197487   epsilon: 0.8069737600041904    steps: 263    lr: 0.0001     evaluation reward: 2.5\n",
      "episode: 1039   score: 7.0   memory length: 197849   epsilon: 0.806257000004206    steps: 362    lr: 0.0001     evaluation reward: 2.52\n",
      "episode: 1040   score: 2.0   memory length: 198067   epsilon: 0.8058253600042153    steps: 218    lr: 0.0001     evaluation reward: 2.52\n",
      "episode: 1041   score: 3.0   memory length: 198317   epsilon: 0.8053303600042261    steps: 250    lr: 0.0001     evaluation reward: 2.52\n",
      "episode: 1042   score: 4.0   memory length: 198614   epsilon: 0.8047423000042389    steps: 297    lr: 0.0001     evaluation reward: 2.55\n",
      "episode: 1043   score: 2.0   memory length: 198812   epsilon: 0.8043502600042474    steps: 198    lr: 0.0001     evaluation reward: 2.54\n",
      "episode: 1044   score: 3.0   memory length: 199056   epsilon: 0.8038671400042579    steps: 244    lr: 0.0001     evaluation reward: 2.53\n",
      "episode: 1045   score: 2.0   memory length: 199254   epsilon: 0.8034751000042664    steps: 198    lr: 0.0001     evaluation reward: 2.52\n",
      "episode: 1046   score: 2.0   memory length: 199452   epsilon: 0.8030830600042749    steps: 198    lr: 0.0001     evaluation reward: 2.44\n",
      "episode: 1047   score: 0.0   memory length: 199575   epsilon: 0.8028395200042802    steps: 123    lr: 0.0001     evaluation reward: 2.44\n",
      "episode: 1048   score: 2.0   memory length: 199773   epsilon: 0.8024474800042887    steps: 198    lr: 0.0001     evaluation reward: 2.43\n",
      "episode: 1049   score: 3.0   memory length: 200001   epsilon: 0.8019960400042985    steps: 228    lr: 4e-05     evaluation reward: 2.46\n",
      "episode: 1050   score: 7.0   memory length: 200389   epsilon: 0.8012278000043151    steps: 388    lr: 4e-05     evaluation reward: 2.52\n",
      "episode: 1051   score: 2.0   memory length: 200586   epsilon: 0.8008377400043236    steps: 197    lr: 4e-05     evaluation reward: 2.51\n",
      "episode: 1052   score: 5.0   memory length: 200893   epsilon: 0.8002298800043368    steps: 307    lr: 4e-05     evaluation reward: 2.54\n",
      "episode: 1053   score: 4.0   memory length: 201191   epsilon: 0.7996398400043496    steps: 298    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1054   score: 1.0   memory length: 201361   epsilon: 0.7993032400043569    steps: 170    lr: 4e-05     evaluation reward: 2.57\n",
      "episode: 1055   score: 2.0   memory length: 201580   epsilon: 0.7988696200043663    steps: 219    lr: 4e-05     evaluation reward: 2.56\n",
      "episode: 1056   score: 4.0   memory length: 201823   epsilon: 0.7983884800043768    steps: 243    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1057   score: 8.0   memory length: 202242   epsilon: 0.7975588600043948    steps: 419    lr: 4e-05     evaluation reward: 2.66\n",
      "episode: 1058   score: 7.0   memory length: 202648   epsilon: 0.7967549800044122    steps: 406    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1059   score: 2.0   memory length: 202846   epsilon: 0.7963629400044208    steps: 198    lr: 4e-05     evaluation reward: 2.68\n",
      "episode: 1060   score: 5.0   memory length: 203151   epsilon: 0.7957590400044339    steps: 305    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1061   score: 4.0   memory length: 203429   epsilon: 0.7952086000044458    steps: 278    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1062   score: 2.0   memory length: 203630   epsilon: 0.7948106200044545    steps: 201    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1063   score: 0.0   memory length: 203752   epsilon: 0.7945690600044597    steps: 122    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1064   score: 4.0   memory length: 204046   epsilon: 0.7939869400044723    steps: 294    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1065   score: 6.0   memory length: 204425   epsilon: 0.7932365200044886    steps: 379    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1066   score: 1.0   memory length: 204575   epsilon: 0.7929395200044951    steps: 150    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1067   score: 5.0   memory length: 204885   epsilon: 0.7923257200045084    steps: 310    lr: 4e-05     evaluation reward: 2.81\n",
      "episode: 1068   score: 3.0   memory length: 205098   epsilon: 0.7919039800045176    steps: 213    lr: 4e-05     evaluation reward: 2.82\n",
      "episode: 1069   score: 6.0   memory length: 205451   epsilon: 0.7912050400045327    steps: 353    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1070   score: 2.0   memory length: 205667   epsilon: 0.790777360004542    steps: 216    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1071   score: 4.0   memory length: 205946   epsilon: 0.790224940004554    steps: 279    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1072   score: 4.0   memory length: 206224   epsilon: 0.789674500004566    steps: 278    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1073   score: 4.0   memory length: 206503   epsilon: 0.789122080004578    steps: 279    lr: 4e-05     evaluation reward: 2.96\n",
      "episode: 1074   score: 4.0   memory length: 206781   epsilon: 0.7885716400045899    steps: 278    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1075   score: 3.0   memory length: 207007   epsilon: 0.7881241600045996    steps: 226    lr: 4e-05     evaluation reward: 2.98\n",
      "episode: 1076   score: 0.0   memory length: 207130   epsilon: 0.7878806200046049    steps: 123    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1077   score: 7.0   memory length: 207493   epsilon: 0.7871618800046205    steps: 363    lr: 4e-05     evaluation reward: 2.96\n",
      "episode: 1078   score: 1.0   memory length: 207664   epsilon: 0.7868233000046279    steps: 171    lr: 4e-05     evaluation reward: 2.94\n",
      "episode: 1079   score: 2.0   memory length: 207844   epsilon: 0.7864669000046356    steps: 180    lr: 4e-05     evaluation reward: 2.86\n",
      "episode: 1080   score: 6.0   memory length: 208188   epsilon: 0.7857857800046504    steps: 344    lr: 4e-05     evaluation reward: 2.92\n",
      "episode: 1081   score: 3.0   memory length: 208414   epsilon: 0.7853383000046601    steps: 226    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1082   score: 5.0   memory length: 208756   epsilon: 0.7846611400046748    steps: 342    lr: 4e-05     evaluation reward: 2.94\n",
      "episode: 1083   score: 5.0   memory length: 209046   epsilon: 0.7840869400046873    steps: 290    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1084   score: 6.0   memory length: 209421   epsilon: 0.7833444400047034    steps: 375    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1085   score: 0.0   memory length: 209544   epsilon: 0.7831009000047087    steps: 123    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1086   score: 4.0   memory length: 209819   epsilon: 0.7825564000047205    steps: 275    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1087   score: 4.0   memory length: 210120   epsilon: 0.7819604200047334    steps: 301    lr: 4e-05     evaluation reward: 3.01\n",
      "episode: 1088   score: 5.0   memory length: 210447   epsilon: 0.7813129600047475    steps: 327    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1089   score: 2.0   memory length: 210645   epsilon: 0.780920920004756    steps: 198    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1090   score: 3.0   memory length: 210912   epsilon: 0.7803922600047675    steps: 267    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1091   score: 2.0   memory length: 211110   epsilon: 0.780000220004776    steps: 198    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1092   score: 3.0   memory length: 211378   epsilon: 0.7794695800047875    steps: 268    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1093   score: 7.0   memory length: 211780   epsilon: 0.7786736200048048    steps: 402    lr: 4e-05     evaluation reward: 3.14\n",
      "episode: 1094   score: 2.0   memory length: 211980   epsilon: 0.7782776200048134    steps: 200    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1095   score: 3.0   memory length: 212191   epsilon: 0.7778598400048224    steps: 211    lr: 4e-05     evaluation reward: 3.12\n",
      "episode: 1096   score: 7.0   memory length: 212476   epsilon: 0.7772955400048347    steps: 285    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1097   score: 3.0   memory length: 212701   epsilon: 0.7768500400048444    steps: 225    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1098   score: 7.0   memory length: 213052   epsilon: 0.7761550600048595    steps: 351    lr: 4e-05     evaluation reward: 3.24\n",
      "episode: 1099   score: 9.0   memory length: 213571   epsilon: 0.7751274400048818    steps: 519    lr: 4e-05     evaluation reward: 3.3\n",
      "episode: 1100   score: 4.0   memory length: 213871   epsilon: 0.7745334400048947    steps: 300    lr: 4e-05     evaluation reward: 3.32\n",
      "episode: 1101   score: 3.0   memory length: 214084   epsilon: 0.7741117000049038    steps: 213    lr: 4e-05     evaluation reward: 3.32\n",
      "episode: 1102   score: 2.0   memory length: 214283   epsilon: 0.7737176800049124    steps: 199    lr: 4e-05     evaluation reward: 3.3\n",
      "episode: 1103   score: 3.0   memory length: 214509   epsilon: 0.7732702000049221    steps: 226    lr: 4e-05     evaluation reward: 3.33\n",
      "episode: 1104   score: 3.0   memory length: 214758   epsilon: 0.7727771800049328    steps: 249    lr: 4e-05     evaluation reward: 3.34\n",
      "episode: 1105   score: 3.0   memory length: 214986   epsilon: 0.7723257400049426    steps: 228    lr: 4e-05     evaluation reward: 3.35\n",
      "episode: 1106   score: 4.0   memory length: 215260   epsilon: 0.7717832200049544    steps: 274    lr: 4e-05     evaluation reward: 3.38\n",
      "episode: 1107   score: 3.0   memory length: 215488   epsilon: 0.7713317800049642    steps: 228    lr: 4e-05     evaluation reward: 3.37\n",
      "episode: 1108   score: 4.0   memory length: 215766   epsilon: 0.7707813400049761    steps: 278    lr: 4e-05     evaluation reward: 3.39\n",
      "episode: 1109   score: 9.0   memory length: 216247   epsilon: 0.7698289600049968    steps: 481    lr: 4e-05     evaluation reward: 3.44\n",
      "episode: 1110   score: 6.0   memory length: 216612   epsilon: 0.7691062600050125    steps: 365    lr: 4e-05     evaluation reward: 3.48\n",
      "episode: 1111   score: 2.0   memory length: 216811   epsilon: 0.768712240005021    steps: 199    lr: 4e-05     evaluation reward: 3.49\n",
      "episode: 1112   score: 5.0   memory length: 217135   epsilon: 0.768070720005035    steps: 324    lr: 4e-05     evaluation reward: 3.52\n",
      "episode: 1113   score: 3.0   memory length: 217379   epsilon: 0.7675876000050454    steps: 244    lr: 4e-05     evaluation reward: 3.49\n",
      "episode: 1114   score: 5.0   memory length: 217687   epsilon: 0.7669777600050587    steps: 308    lr: 4e-05     evaluation reward: 3.5\n",
      "episode: 1115   score: 7.0   memory length: 218122   epsilon: 0.7661164600050774    steps: 435    lr: 4e-05     evaluation reward: 3.55\n",
      "episode: 1116   score: 5.0   memory length: 218464   epsilon: 0.7654393000050921    steps: 342    lr: 4e-05     evaluation reward: 3.58\n",
      "episode: 1117   score: 3.0   memory length: 218677   epsilon: 0.7650175600051012    steps: 213    lr: 4e-05     evaluation reward: 3.58\n",
      "episode: 1118   score: 3.0   memory length: 218905   epsilon: 0.764566120005111    steps: 228    lr: 4e-05     evaluation reward: 3.61\n",
      "episode: 1119   score: 4.0   memory length: 219200   epsilon: 0.7639820200051237    steps: 295    lr: 4e-05     evaluation reward: 3.63\n",
      "episode: 1120   score: 1.0   memory length: 219369   epsilon: 0.763647400005131    steps: 169    lr: 4e-05     evaluation reward: 3.62\n",
      "episode: 1121   score: 0.0   memory length: 219492   epsilon: 0.7634038600051363    steps: 123    lr: 4e-05     evaluation reward: 3.56\n",
      "episode: 1122   score: 2.0   memory length: 219690   epsilon: 0.7630118200051448    steps: 198    lr: 4e-05     evaluation reward: 3.56\n",
      "episode: 1123   score: 5.0   memory length: 220014   epsilon: 0.7623703000051587    steps: 324    lr: 4e-05     evaluation reward: 3.6\n",
      "episode: 1124   score: 6.0   memory length: 220395   epsilon: 0.7616159200051751    steps: 381    lr: 4e-05     evaluation reward: 3.64\n",
      "episode: 1125   score: 6.0   memory length: 220771   epsilon: 0.7608714400051912    steps: 376    lr: 4e-05     evaluation reward: 3.68\n",
      "episode: 1126   score: 4.0   memory length: 221031   epsilon: 0.7603566400052024    steps: 260    lr: 4e-05     evaluation reward: 3.71\n",
      "episode: 1127   score: 4.0   memory length: 221273   epsilon: 0.7598774800052128    steps: 242    lr: 4e-05     evaluation reward: 3.67\n",
      "episode: 1128   score: 1.0   memory length: 221424   epsilon: 0.7595785000052193    steps: 151    lr: 4e-05     evaluation reward: 3.67\n",
      "episode: 1129   score: 2.0   memory length: 221645   epsilon: 0.7591409200052288    steps: 221    lr: 4e-05     evaluation reward: 3.66\n",
      "episode: 1130   score: 3.0   memory length: 221892   epsilon: 0.7586518600052394    steps: 247    lr: 4e-05     evaluation reward: 3.66\n",
      "episode: 1131   score: 1.0   memory length: 222043   epsilon: 0.7583528800052459    steps: 151    lr: 4e-05     evaluation reward: 3.63\n",
      "episode: 1132   score: 2.0   memory length: 222243   epsilon: 0.7579568800052545    steps: 200    lr: 4e-05     evaluation reward: 3.62\n",
      "episode: 1133   score: 3.0   memory length: 222472   epsilon: 0.7575034600052644    steps: 229    lr: 4e-05     evaluation reward: 3.62\n",
      "episode: 1134   score: 4.0   memory length: 222731   epsilon: 0.7569906400052755    steps: 259    lr: 4e-05     evaluation reward: 3.64\n",
      "episode: 1135   score: 4.0   memory length: 223008   epsilon: 0.7564421800052874    steps: 277    lr: 4e-05     evaluation reward: 3.64\n",
      "episode: 1136   score: 1.0   memory length: 223177   epsilon: 0.7561075600052947    steps: 169    lr: 4e-05     evaluation reward: 3.59\n",
      "episode: 1137   score: 3.0   memory length: 223421   epsilon: 0.7556244400053052    steps: 244    lr: 4e-05     evaluation reward: 3.61\n",
      "episode: 1138   score: 4.0   memory length: 223683   epsilon: 0.7551056800053164    steps: 262    lr: 4e-05     evaluation reward: 3.62\n",
      "episode: 1139   score: 3.0   memory length: 223911   epsilon: 0.7546542400053262    steps: 228    lr: 4e-05     evaluation reward: 3.58\n",
      "episode: 1140   score: 3.0   memory length: 224176   epsilon: 0.7541295400053376    steps: 265    lr: 4e-05     evaluation reward: 3.59\n",
      "episode: 1141   score: 5.0   memory length: 224520   epsilon: 0.7534484200053524    steps: 344    lr: 4e-05     evaluation reward: 3.61\n",
      "episode: 1142   score: 3.0   memory length: 224729   epsilon: 0.7530346000053614    steps: 209    lr: 4e-05     evaluation reward: 3.6\n",
      "episode: 1143   score: 1.0   memory length: 224900   epsilon: 0.7526960200053687    steps: 171    lr: 4e-05     evaluation reward: 3.59\n",
      "episode: 1144   score: 4.0   memory length: 225142   epsilon: 0.7522168600053791    steps: 242    lr: 4e-05     evaluation reward: 3.6\n",
      "episode: 1145   score: 2.0   memory length: 225339   epsilon: 0.7518268000053876    steps: 197    lr: 4e-05     evaluation reward: 3.6\n",
      "episode: 1146   score: 2.0   memory length: 225539   epsilon: 0.7514308000053962    steps: 200    lr: 4e-05     evaluation reward: 3.6\n",
      "episode: 1147   score: 2.0   memory length: 225736   epsilon: 0.7510407400054047    steps: 197    lr: 4e-05     evaluation reward: 3.62\n",
      "episode: 1148   score: 2.0   memory length: 225953   epsilon: 0.750611080005414    steps: 217    lr: 4e-05     evaluation reward: 3.62\n",
      "episode: 1149   score: 5.0   memory length: 226278   epsilon: 0.749967580005428    steps: 325    lr: 4e-05     evaluation reward: 3.64\n",
      "episode: 1150   score: 4.0   memory length: 226552   epsilon: 0.7494250600054397    steps: 274    lr: 4e-05     evaluation reward: 3.61\n",
      "episode: 1151   score: 3.0   memory length: 226799   epsilon: 0.7489360000054504    steps: 247    lr: 4e-05     evaluation reward: 3.62\n",
      "episode: 1152   score: 5.0   memory length: 227121   epsilon: 0.7482984400054642    steps: 322    lr: 4e-05     evaluation reward: 3.62\n",
      "episode: 1153   score: 1.0   memory length: 227291   epsilon: 0.7479618400054715    steps: 170    lr: 4e-05     evaluation reward: 3.59\n",
      "episode: 1154   score: 3.0   memory length: 227517   epsilon: 0.7475143600054812    steps: 226    lr: 4e-05     evaluation reward: 3.61\n",
      "episode: 1155   score: 4.0   memory length: 227813   epsilon: 0.7469282800054939    steps: 296    lr: 4e-05     evaluation reward: 3.63\n",
      "episode: 1156   score: 6.0   memory length: 228187   epsilon: 0.74618776000551    steps: 374    lr: 4e-05     evaluation reward: 3.65\n",
      "episode: 1157   score: 10.0   memory length: 228586   epsilon: 0.7453977400055272    steps: 399    lr: 4e-05     evaluation reward: 3.67\n",
      "episode: 1158   score: 7.0   memory length: 228972   epsilon: 0.7446334600055438    steps: 386    lr: 4e-05     evaluation reward: 3.67\n",
      "episode: 1159   score: 5.0   memory length: 229251   epsilon: 0.7440810400055557    steps: 279    lr: 4e-05     evaluation reward: 3.7\n",
      "episode: 1160   score: 1.0   memory length: 229402   epsilon: 0.7437820600055622    steps: 151    lr: 4e-05     evaluation reward: 3.66\n",
      "episode: 1161   score: 5.0   memory length: 229726   epsilon: 0.7431405400055762    steps: 324    lr: 4e-05     evaluation reward: 3.67\n",
      "episode: 1162   score: 6.0   memory length: 230078   epsilon: 0.7424435800055913    steps: 352    lr: 4e-05     evaluation reward: 3.71\n",
      "episode: 1163   score: 7.0   memory length: 230479   epsilon: 0.7416496000056085    steps: 401    lr: 4e-05     evaluation reward: 3.78\n",
      "episode: 1164   score: 1.0   memory length: 230648   epsilon: 0.7413149800056158    steps: 169    lr: 4e-05     evaluation reward: 3.75\n",
      "episode: 1165   score: 6.0   memory length: 231023   epsilon: 0.7405724800056319    steps: 375    lr: 4e-05     evaluation reward: 3.75\n",
      "episode: 1166   score: 4.0   memory length: 231298   epsilon: 0.7400279800056437    steps: 275    lr: 4e-05     evaluation reward: 3.78\n",
      "episode: 1167   score: 6.0   memory length: 231630   epsilon: 0.739370620005658    steps: 332    lr: 4e-05     evaluation reward: 3.79\n",
      "episode: 1168   score: 3.0   memory length: 231857   epsilon: 0.7389211600056678    steps: 227    lr: 4e-05     evaluation reward: 3.79\n",
      "episode: 1169   score: 1.0   memory length: 232008   epsilon: 0.7386221800056743    steps: 151    lr: 4e-05     evaluation reward: 3.74\n",
      "episode: 1170   score: 3.0   memory length: 232237   epsilon: 0.7381687600056841    steps: 229    lr: 4e-05     evaluation reward: 3.75\n",
      "episode: 1171   score: 4.0   memory length: 232555   epsilon: 0.7375391200056978    steps: 318    lr: 4e-05     evaluation reward: 3.75\n",
      "episode: 1172   score: 3.0   memory length: 232781   epsilon: 0.7370916400057075    steps: 226    lr: 4e-05     evaluation reward: 3.74\n",
      "episode: 1173   score: 7.0   memory length: 233192   epsilon: 0.7362778600057251    steps: 411    lr: 4e-05     evaluation reward: 3.77\n",
      "episode: 1174   score: 4.0   memory length: 233451   epsilon: 0.7357650400057363    steps: 259    lr: 4e-05     evaluation reward: 3.77\n",
      "episode: 1175   score: 3.0   memory length: 233718   epsilon: 0.7352363800057478    steps: 267    lr: 4e-05     evaluation reward: 3.77\n",
      "episode: 1176   score: 5.0   memory length: 234042   epsilon: 0.7345948600057617    steps: 324    lr: 4e-05     evaluation reward: 3.82\n",
      "episode: 1177   score: 3.0   memory length: 234310   epsilon: 0.7340642200057732    steps: 268    lr: 4e-05     evaluation reward: 3.78\n",
      "episode: 1178   score: 3.0   memory length: 234577   epsilon: 0.7335355600057847    steps: 267    lr: 4e-05     evaluation reward: 3.8\n",
      "episode: 1179   score: 3.0   memory length: 234842   epsilon: 0.7330108600057961    steps: 265    lr: 4e-05     evaluation reward: 3.81\n",
      "episode: 1180   score: 2.0   memory length: 235042   epsilon: 0.7326148600058047    steps: 200    lr: 4e-05     evaluation reward: 3.77\n",
      "episode: 1181   score: 3.0   memory length: 235306   epsilon: 0.732092140005816    steps: 264    lr: 4e-05     evaluation reward: 3.77\n",
      "episode: 1182   score: 5.0   memory length: 235595   epsilon: 0.7315199200058284    steps: 289    lr: 4e-05     evaluation reward: 3.77\n",
      "episode: 1183   score: 3.0   memory length: 235840   epsilon: 0.731034820005839    steps: 245    lr: 4e-05     evaluation reward: 3.75\n",
      "episode: 1184   score: 6.0   memory length: 236232   epsilon: 0.7302586600058558    steps: 392    lr: 4e-05     evaluation reward: 3.75\n",
      "episode: 1185   score: 2.0   memory length: 236432   epsilon: 0.7298626600058644    steps: 200    lr: 4e-05     evaluation reward: 3.77\n",
      "episode: 1186   score: 3.0   memory length: 236700   epsilon: 0.7293320200058759    steps: 268    lr: 4e-05     evaluation reward: 3.76\n",
      "episode: 1187   score: 4.0   memory length: 236973   epsilon: 0.7287914800058877    steps: 273    lr: 4e-05     evaluation reward: 3.76\n",
      "episode: 1188   score: 2.0   memory length: 237153   epsilon: 0.7284350800058954    steps: 180    lr: 4e-05     evaluation reward: 3.73\n",
      "episode: 1189   score: 5.0   memory length: 237468   epsilon: 0.727811380005909    steps: 315    lr: 4e-05     evaluation reward: 3.76\n",
      "episode: 1190   score: 1.0   memory length: 237637   epsilon: 0.7274767600059162    steps: 169    lr: 4e-05     evaluation reward: 3.74\n",
      "episode: 1191   score: 3.0   memory length: 237864   epsilon: 0.727027300005926    steps: 227    lr: 4e-05     evaluation reward: 3.75\n",
      "episode: 1192   score: 1.0   memory length: 238014   epsilon: 0.7267303000059324    steps: 150    lr: 4e-05     evaluation reward: 3.73\n",
      "episode: 1193   score: 4.0   memory length: 238291   epsilon: 0.7261818400059443    steps: 277    lr: 4e-05     evaluation reward: 3.7\n",
      "episode: 1194   score: 2.0   memory length: 238489   epsilon: 0.7257898000059528    steps: 198    lr: 4e-05     evaluation reward: 3.7\n",
      "episode: 1195   score: 4.0   memory length: 238805   epsilon: 0.7251641200059664    steps: 316    lr: 4e-05     evaluation reward: 3.71\n",
      "episode: 1196   score: 2.0   memory length: 239003   epsilon: 0.7247720800059749    steps: 198    lr: 4e-05     evaluation reward: 3.66\n",
      "episode: 1197   score: 2.0   memory length: 239205   epsilon: 0.7243721200059836    steps: 202    lr: 4e-05     evaluation reward: 3.65\n",
      "episode: 1198   score: 6.0   memory length: 239582   epsilon: 0.7236256600059998    steps: 377    lr: 4e-05     evaluation reward: 3.64\n",
      "episode: 1199   score: 4.0   memory length: 239842   epsilon: 0.723110860006011    steps: 260    lr: 4e-05     evaluation reward: 3.59\n",
      "episode: 1200   score: 5.0   memory length: 240174   epsilon: 0.7224535000060253    steps: 332    lr: 4e-05     evaluation reward: 3.6\n",
      "episode: 1201   score: 7.0   memory length: 240594   epsilon: 0.7216219000060433    steps: 420    lr: 4e-05     evaluation reward: 3.64\n",
      "episode: 1202   score: 3.0   memory length: 240820   epsilon: 0.721174420006053    steps: 226    lr: 4e-05     evaluation reward: 3.65\n",
      "episode: 1203   score: 3.0   memory length: 241048   epsilon: 0.7207229800060628    steps: 228    lr: 4e-05     evaluation reward: 3.65\n",
      "episode: 1204   score: 1.0   memory length: 241199   epsilon: 0.7204240000060693    steps: 151    lr: 4e-05     evaluation reward: 3.63\n",
      "episode: 1205   score: 13.0   memory length: 241718   epsilon: 0.7193963800060916    steps: 519    lr: 4e-05     evaluation reward: 3.73\n",
      "episode: 1206   score: 5.0   memory length: 242025   epsilon: 0.7187885200061048    steps: 307    lr: 4e-05     evaluation reward: 3.74\n",
      "episode: 1207   score: 8.0   memory length: 242446   epsilon: 0.7179549400061229    steps: 421    lr: 4e-05     evaluation reward: 3.79\n",
      "episode: 1208   score: 4.0   memory length: 242739   epsilon: 0.7173748000061355    steps: 293    lr: 4e-05     evaluation reward: 3.79\n",
      "episode: 1209   score: 2.0   memory length: 242939   epsilon: 0.7169788000061441    steps: 200    lr: 4e-05     evaluation reward: 3.72\n",
      "episode: 1210   score: 12.0   memory length: 243506   epsilon: 0.7158561400061685    steps: 567    lr: 4e-05     evaluation reward: 3.78\n",
      "episode: 1211   score: 4.0   memory length: 243779   epsilon: 0.7153156000061802    steps: 273    lr: 4e-05     evaluation reward: 3.8\n",
      "episode: 1212   score: 5.0   memory length: 244069   epsilon: 0.7147414000061927    steps: 290    lr: 4e-05     evaluation reward: 3.8\n",
      "episode: 1213   score: 4.0   memory length: 244365   epsilon: 0.7141553200062054    steps: 296    lr: 4e-05     evaluation reward: 3.81\n",
      "episode: 1214   score: 7.0   memory length: 244770   epsilon: 0.7133534200062228    steps: 405    lr: 4e-05     evaluation reward: 3.83\n",
      "episode: 1215   score: 6.0   memory length: 245132   epsilon: 0.7126366600062384    steps: 362    lr: 4e-05     evaluation reward: 3.82\n",
      "episode: 1216   score: 2.0   memory length: 245332   epsilon: 0.712240660006247    steps: 200    lr: 4e-05     evaluation reward: 3.79\n",
      "episode: 1217   score: 5.0   memory length: 245622   epsilon: 0.7116664600062594    steps: 290    lr: 4e-05     evaluation reward: 3.81\n",
      "episode: 1218   score: 2.0   memory length: 245820   epsilon: 0.711274420006268    steps: 198    lr: 4e-05     evaluation reward: 3.8\n",
      "episode: 1219   score: 6.0   memory length: 246175   epsilon: 0.7105715200062832    steps: 355    lr: 4e-05     evaluation reward: 3.82\n",
      "episode: 1220   score: 2.0   memory length: 246356   epsilon: 0.710213140006291    steps: 181    lr: 4e-05     evaluation reward: 3.83\n",
      "episode: 1221   score: 2.0   memory length: 246538   epsilon: 0.7098527800062988    steps: 182    lr: 4e-05     evaluation reward: 3.85\n",
      "episode: 1222   score: 3.0   memory length: 246789   epsilon: 0.7093558000063096    steps: 251    lr: 4e-05     evaluation reward: 3.86\n",
      "episode: 1223   score: 5.0   memory length: 247097   epsilon: 0.7087459600063228    steps: 308    lr: 4e-05     evaluation reward: 3.86\n",
      "episode: 1224   score: 5.0   memory length: 247411   epsilon: 0.7081242400063363    steps: 314    lr: 4e-05     evaluation reward: 3.85\n",
      "episode: 1225   score: 3.0   memory length: 247637   epsilon: 0.707676760006346    steps: 226    lr: 4e-05     evaluation reward: 3.82\n",
      "episode: 1226   score: 6.0   memory length: 248010   epsilon: 0.7069382200063621    steps: 373    lr: 4e-05     evaluation reward: 3.84\n",
      "episode: 1227   score: 1.0   memory length: 248160   epsilon: 0.7066412200063685    steps: 150    lr: 4e-05     evaluation reward: 3.81\n",
      "episode: 1228   score: 3.0   memory length: 248408   epsilon: 0.7061501800063792    steps: 248    lr: 4e-05     evaluation reward: 3.83\n",
      "episode: 1229   score: 4.0   memory length: 248708   epsilon: 0.7055561800063921    steps: 300    lr: 4e-05     evaluation reward: 3.85\n",
      "episode: 1230   score: 4.0   memory length: 248982   epsilon: 0.7050136600064039    steps: 274    lr: 4e-05     evaluation reward: 3.86\n",
      "episode: 1231   score: 8.0   memory length: 249444   epsilon: 0.7040989000064237    steps: 462    lr: 4e-05     evaluation reward: 3.93\n",
      "episode: 1232   score: 6.0   memory length: 249818   epsilon: 0.7033583800064398    steps: 374    lr: 4e-05     evaluation reward: 3.97\n",
      "episode: 1233   score: 7.0   memory length: 250201   epsilon: 0.7026000400064563    steps: 383    lr: 4e-05     evaluation reward: 4.01\n",
      "episode: 1234   score: 4.0   memory length: 250518   epsilon: 0.7019723800064699    steps: 317    lr: 4e-05     evaluation reward: 4.01\n",
      "episode: 1235   score: 5.0   memory length: 250822   epsilon: 0.701370460006483    steps: 304    lr: 4e-05     evaluation reward: 4.02\n",
      "episode: 1236   score: 4.0   memory length: 251098   epsilon: 0.7008239800064948    steps: 276    lr: 4e-05     evaluation reward: 4.05\n",
      "episode: 1237   score: 6.0   memory length: 251458   epsilon: 0.7001111800065103    steps: 360    lr: 4e-05     evaluation reward: 4.08\n",
      "episode: 1238   score: 9.0   memory length: 251931   epsilon: 0.6991746400065306    steps: 473    lr: 4e-05     evaluation reward: 4.13\n",
      "episode: 1239   score: 4.0   memory length: 252206   epsilon: 0.6986301400065424    steps: 275    lr: 4e-05     evaluation reward: 4.14\n",
      "episode: 1240   score: 6.0   memory length: 252580   epsilon: 0.6978896200065585    steps: 374    lr: 4e-05     evaluation reward: 4.17\n",
      "episode: 1241   score: 3.0   memory length: 252828   epsilon: 0.6973985800065692    steps: 248    lr: 4e-05     evaluation reward: 4.15\n",
      "episode: 1242   score: 3.0   memory length: 253057   epsilon: 0.696945160006579    steps: 229    lr: 4e-05     evaluation reward: 4.15\n",
      "episode: 1243   score: 4.0   memory length: 253315   epsilon: 0.6964343200065901    steps: 258    lr: 4e-05     evaluation reward: 4.18\n",
      "episode: 1244   score: 7.0   memory length: 253736   epsilon: 0.6956007400066082    steps: 421    lr: 4e-05     evaluation reward: 4.21\n",
      "episode: 1245   score: 0.0   memory length: 253859   epsilon: 0.6953572000066135    steps: 123    lr: 4e-05     evaluation reward: 4.19\n",
      "episode: 1246   score: 5.0   memory length: 254152   epsilon: 0.6947770600066261    steps: 293    lr: 4e-05     evaluation reward: 4.22\n",
      "episode: 1247   score: 3.0   memory length: 254381   epsilon: 0.6943236400066359    steps: 229    lr: 4e-05     evaluation reward: 4.23\n",
      "episode: 1248   score: 4.0   memory length: 254638   epsilon: 0.693814780006647    steps: 257    lr: 4e-05     evaluation reward: 4.25\n",
      "episode: 1249   score: 9.0   memory length: 255115   epsilon: 0.6928703200066675    steps: 477    lr: 4e-05     evaluation reward: 4.29\n",
      "episode: 1250   score: 3.0   memory length: 255363   epsilon: 0.6923792800066781    steps: 248    lr: 4e-05     evaluation reward: 4.28\n",
      "episode: 1251   score: 6.0   memory length: 255738   epsilon: 0.6916367800066943    steps: 375    lr: 4e-05     evaluation reward: 4.31\n",
      "episode: 1252   score: 2.0   memory length: 255937   epsilon: 0.6912427600067028    steps: 199    lr: 4e-05     evaluation reward: 4.28\n",
      "episode: 1253   score: 4.0   memory length: 256215   epsilon: 0.6906923200067148    steps: 278    lr: 4e-05     evaluation reward: 4.31\n",
      "episode: 1254   score: 5.0   memory length: 256521   epsilon: 0.6900864400067279    steps: 306    lr: 4e-05     evaluation reward: 4.33\n",
      "episode: 1255   score: 5.0   memory length: 256827   epsilon: 0.6894805600067411    steps: 306    lr: 4e-05     evaluation reward: 4.34\n",
      "episode: 1256   score: 2.0   memory length: 257027   epsilon: 0.6890845600067497    steps: 200    lr: 4e-05     evaluation reward: 4.3\n",
      "episode: 1257   score: 0.0   memory length: 257150   epsilon: 0.688841020006755    steps: 123    lr: 4e-05     evaluation reward: 4.2\n",
      "episode: 1258   score: 1.0   memory length: 257300   epsilon: 0.6885440200067614    steps: 150    lr: 4e-05     evaluation reward: 4.14\n",
      "episode: 1259   score: 4.0   memory length: 257541   epsilon: 0.6880668400067718    steps: 241    lr: 4e-05     evaluation reward: 4.13\n",
      "episode: 1260   score: 4.0   memory length: 257819   epsilon: 0.6875164000067837    steps: 278    lr: 4e-05     evaluation reward: 4.16\n",
      "episode: 1261   score: 6.0   memory length: 258194   epsilon: 0.6867739000067998    steps: 375    lr: 4e-05     evaluation reward: 4.17\n",
      "episode: 1262   score: 6.0   memory length: 258549   epsilon: 0.6860710000068151    steps: 355    lr: 4e-05     evaluation reward: 4.17\n",
      "episode: 1263   score: 3.0   memory length: 258775   epsilon: 0.6856235200068248    steps: 226    lr: 4e-05     evaluation reward: 4.13\n",
      "episode: 1264   score: 5.0   memory length: 259082   epsilon: 0.685015660006838    steps: 307    lr: 4e-05     evaluation reward: 4.17\n",
      "episode: 1265   score: 8.0   memory length: 259519   epsilon: 0.6841504000068568    steps: 437    lr: 4e-05     evaluation reward: 4.19\n",
      "episode: 1266   score: 1.0   memory length: 259671   epsilon: 0.6838494400068633    steps: 152    lr: 4e-05     evaluation reward: 4.16\n",
      "episode: 1267   score: 4.0   memory length: 259946   epsilon: 0.6833049400068751    steps: 275    lr: 4e-05     evaluation reward: 4.14\n",
      "episode: 1268   score: 4.0   memory length: 260205   epsilon: 0.6827921200068863    steps: 259    lr: 4e-05     evaluation reward: 4.15\n",
      "episode: 1269   score: 2.0   memory length: 260403   epsilon: 0.6824000800068948    steps: 198    lr: 4e-05     evaluation reward: 4.16\n",
      "episode: 1270   score: 8.0   memory length: 260834   epsilon: 0.6815467000069133    steps: 431    lr: 4e-05     evaluation reward: 4.21\n",
      "episode: 1271   score: 8.0   memory length: 261257   epsilon: 0.6807091600069315    steps: 423    lr: 4e-05     evaluation reward: 4.25\n",
      "episode: 1272   score: 5.0   memory length: 261562   epsilon: 0.6801052600069446    steps: 305    lr: 4e-05     evaluation reward: 4.27\n",
      "episode: 1273   score: 3.0   memory length: 261787   epsilon: 0.6796597600069543    steps: 225    lr: 4e-05     evaluation reward: 4.23\n",
      "episode: 1274   score: 4.0   memory length: 262045   epsilon: 0.6791489200069654    steps: 258    lr: 4e-05     evaluation reward: 4.23\n",
      "episode: 1275   score: 4.0   memory length: 262303   epsilon: 0.6786380800069765    steps: 258    lr: 4e-05     evaluation reward: 4.24\n",
      "episode: 1276   score: 3.0   memory length: 262530   epsilon: 0.6781886200069862    steps: 227    lr: 4e-05     evaluation reward: 4.22\n",
      "episode: 1277   score: 7.0   memory length: 262932   epsilon: 0.6773926600070035    steps: 402    lr: 4e-05     evaluation reward: 4.26\n",
      "episode: 1278   score: 6.0   memory length: 263309   epsilon: 0.6766462000070197    steps: 377    lr: 4e-05     evaluation reward: 4.29\n",
      "episode: 1279   score: 4.0   memory length: 263607   epsilon: 0.6760561600070325    steps: 298    lr: 4e-05     evaluation reward: 4.3\n",
      "episode: 1280   score: 2.0   memory length: 263808   epsilon: 0.6756581800070411    steps: 201    lr: 4e-05     evaluation reward: 4.3\n",
      "episode: 1281   score: 2.0   memory length: 264006   epsilon: 0.6752661400070497    steps: 198    lr: 4e-05     evaluation reward: 4.29\n",
      "episode: 1282   score: 3.0   memory length: 264233   epsilon: 0.6748166800070594    steps: 227    lr: 4e-05     evaluation reward: 4.27\n",
      "episode: 1283   score: 6.0   memory length: 264606   epsilon: 0.6740781400070754    steps: 373    lr: 4e-05     evaluation reward: 4.3\n",
      "episode: 1284   score: 1.0   memory length: 264775   epsilon: 0.6737435200070827    steps: 169    lr: 4e-05     evaluation reward: 4.25\n",
      "episode: 1285   score: 7.0   memory length: 265158   epsilon: 0.6729851800070992    steps: 383    lr: 4e-05     evaluation reward: 4.3\n",
      "episode: 1286   score: 5.0   memory length: 265463   epsilon: 0.6723812800071123    steps: 305    lr: 4e-05     evaluation reward: 4.32\n",
      "episode: 1287   score: 5.0   memory length: 265779   epsilon: 0.6717556000071259    steps: 316    lr: 4e-05     evaluation reward: 4.33\n",
      "episode: 1288   score: 5.0   memory length: 266054   epsilon: 0.6712111000071377    steps: 275    lr: 4e-05     evaluation reward: 4.36\n",
      "episode: 1289   score: 6.0   memory length: 266381   epsilon: 0.6705636400071517    steps: 327    lr: 4e-05     evaluation reward: 4.37\n",
      "episode: 1290   score: 6.0   memory length: 266719   epsilon: 0.6698944000071663    steps: 338    lr: 4e-05     evaluation reward: 4.42\n",
      "episode: 1291   score: 5.0   memory length: 267033   epsilon: 0.6692726800071798    steps: 314    lr: 4e-05     evaluation reward: 4.44\n",
      "episode: 1292   score: 2.0   memory length: 267231   epsilon: 0.6688806400071883    steps: 198    lr: 4e-05     evaluation reward: 4.45\n",
      "episode: 1293   score: 3.0   memory length: 267459   epsilon: 0.6684292000071981    steps: 228    lr: 4e-05     evaluation reward: 4.44\n",
      "episode: 1294   score: 5.0   memory length: 267765   epsilon: 0.6678233200072112    steps: 306    lr: 4e-05     evaluation reward: 4.47\n",
      "episode: 1295   score: 7.0   memory length: 268159   epsilon: 0.6670432000072282    steps: 394    lr: 4e-05     evaluation reward: 4.5\n",
      "episode: 1296   score: 6.0   memory length: 268480   epsilon: 0.666407620007242    steps: 321    lr: 4e-05     evaluation reward: 4.54\n",
      "episode: 1297   score: 3.0   memory length: 268710   epsilon: 0.6659522200072518    steps: 230    lr: 4e-05     evaluation reward: 4.55\n",
      "episode: 1298   score: 4.0   memory length: 268950   epsilon: 0.6654770200072622    steps: 240    lr: 4e-05     evaluation reward: 4.53\n",
      "episode: 1299   score: 8.0   memory length: 269457   epsilon: 0.664473160007284    steps: 507    lr: 4e-05     evaluation reward: 4.57\n",
      "episode: 1300   score: 4.0   memory length: 269752   epsilon: 0.6638890600072966    steps: 295    lr: 4e-05     evaluation reward: 4.56\n",
      "episode: 1301   score: 5.0   memory length: 270097   epsilon: 0.6632059600073115    steps: 345    lr: 4e-05     evaluation reward: 4.54\n",
      "episode: 1302   score: 10.0   memory length: 270508   epsilon: 0.6623921800073291    steps: 411    lr: 4e-05     evaluation reward: 4.61\n",
      "episode: 1303   score: 4.0   memory length: 270783   epsilon: 0.661847680007341    steps: 275    lr: 4e-05     evaluation reward: 4.62\n",
      "episode: 1304   score: 4.0   memory length: 271078   epsilon: 0.6612635800073536    steps: 295    lr: 4e-05     evaluation reward: 4.65\n",
      "episode: 1305   score: 3.0   memory length: 271323   epsilon: 0.6607784800073642    steps: 245    lr: 4e-05     evaluation reward: 4.55\n",
      "episode: 1306   score: 6.0   memory length: 271661   epsilon: 0.6601092400073787    steps: 338    lr: 4e-05     evaluation reward: 4.56\n",
      "episode: 1307   score: 4.0   memory length: 271936   epsilon: 0.6595647400073905    steps: 275    lr: 4e-05     evaluation reward: 4.52\n",
      "episode: 1308   score: 7.0   memory length: 272316   epsilon: 0.6588123400074068    steps: 380    lr: 4e-05     evaluation reward: 4.55\n",
      "episode: 1309   score: 5.0   memory length: 272661   epsilon: 0.6581292400074217    steps: 345    lr: 4e-05     evaluation reward: 4.58\n",
      "episode: 1310   score: 4.0   memory length: 272955   epsilon: 0.6575471200074343    steps: 294    lr: 4e-05     evaluation reward: 4.5\n",
      "episode: 1311   score: 2.0   memory length: 273154   epsilon: 0.6571531000074429    steps: 199    lr: 4e-05     evaluation reward: 4.48\n",
      "episode: 1312   score: 5.0   memory length: 273457   epsilon: 0.6565531600074559    steps: 303    lr: 4e-05     evaluation reward: 4.48\n",
      "episode: 1313   score: 4.0   memory length: 273713   epsilon: 0.6560462800074669    steps: 256    lr: 4e-05     evaluation reward: 4.48\n",
      "episode: 1314   score: 6.0   memory length: 274076   epsilon: 0.6553275400074825    steps: 363    lr: 4e-05     evaluation reward: 4.47\n",
      "episode: 1315   score: 4.0   memory length: 274369   epsilon: 0.6547474000074951    steps: 293    lr: 4e-05     evaluation reward: 4.45\n",
      "episode: 1316   score: 8.0   memory length: 274769   epsilon: 0.6539554000075123    steps: 400    lr: 4e-05     evaluation reward: 4.51\n",
      "episode: 1317   score: 9.0   memory length: 275280   epsilon: 0.6529436200075343    steps: 511    lr: 4e-05     evaluation reward: 4.55\n",
      "episode: 1318   score: 3.0   memory length: 275490   epsilon: 0.6525278200075433    steps: 210    lr: 4e-05     evaluation reward: 4.56\n",
      "episode: 1319   score: 3.0   memory length: 275716   epsilon: 0.652080340007553    steps: 226    lr: 4e-05     evaluation reward: 4.53\n",
      "episode: 1320   score: 2.0   memory length: 275916   epsilon: 0.6516843400075616    steps: 200    lr: 4e-05     evaluation reward: 4.53\n",
      "episode: 1321   score: 4.0   memory length: 276171   epsilon: 0.6511794400075726    steps: 255    lr: 4e-05     evaluation reward: 4.55\n",
      "episode: 1322   score: 2.0   memory length: 276369   epsilon: 0.6507874000075811    steps: 198    lr: 4e-05     evaluation reward: 4.54\n",
      "episode: 1323   score: 5.0   memory length: 276713   epsilon: 0.6501062800075958    steps: 344    lr: 4e-05     evaluation reward: 4.54\n",
      "episode: 1324   score: 8.0   memory length: 277169   epsilon: 0.6492034000076154    steps: 456    lr: 4e-05     evaluation reward: 4.57\n",
      "episode: 1325   score: 6.0   memory length: 277543   epsilon: 0.6484628800076315    steps: 374    lr: 4e-05     evaluation reward: 4.6\n",
      "episode: 1326   score: 4.0   memory length: 277812   epsilon: 0.6479302600076431    steps: 269    lr: 4e-05     evaluation reward: 4.58\n",
      "episode: 1327   score: 3.0   memory length: 278041   epsilon: 0.6474768400076529    steps: 229    lr: 4e-05     evaluation reward: 4.6\n",
      "episode: 1328   score: 6.0   memory length: 278382   epsilon: 0.6468016600076676    steps: 341    lr: 4e-05     evaluation reward: 4.63\n",
      "episode: 1329   score: 2.0   memory length: 278581   epsilon: 0.6464076400076761    steps: 199    lr: 4e-05     evaluation reward: 4.61\n",
      "episode: 1330   score: 5.0   memory length: 278891   epsilon: 0.6457938400076895    steps: 310    lr: 4e-05     evaluation reward: 4.62\n",
      "episode: 1331   score: 2.0   memory length: 279088   epsilon: 0.6454037800076979    steps: 197    lr: 4e-05     evaluation reward: 4.56\n",
      "episode: 1332   score: 3.0   memory length: 279336   epsilon: 0.6449127400077086    steps: 248    lr: 4e-05     evaluation reward: 4.53\n",
      "episode: 1333   score: 4.0   memory length: 279596   epsilon: 0.6443979400077198    steps: 260    lr: 4e-05     evaluation reward: 4.5\n",
      "episode: 1334   score: 4.0   memory length: 279894   epsilon: 0.6438079000077326    steps: 298    lr: 4e-05     evaluation reward: 4.5\n",
      "episode: 1335   score: 10.0   memory length: 280430   epsilon: 0.6427466200077556    steps: 536    lr: 4e-05     evaluation reward: 4.55\n",
      "episode: 1336   score: 7.0   memory length: 280837   epsilon: 0.6419407600077731    steps: 407    lr: 4e-05     evaluation reward: 4.58\n",
      "episode: 1337   score: 6.0   memory length: 281163   epsilon: 0.6412952800077871    steps: 326    lr: 4e-05     evaluation reward: 4.58\n",
      "episode: 1338   score: 3.0   memory length: 281375   epsilon: 0.6408755200077962    steps: 212    lr: 4e-05     evaluation reward: 4.52\n",
      "episode: 1339   score: 2.0   memory length: 281575   epsilon: 0.6404795200078048    steps: 200    lr: 4e-05     evaluation reward: 4.5\n",
      "episode: 1340   score: 10.0   memory length: 282084   epsilon: 0.6394717000078267    steps: 509    lr: 4e-05     evaluation reward: 4.54\n",
      "episode: 1341   score: 3.0   memory length: 282309   epsilon: 0.6390262000078364    steps: 225    lr: 4e-05     evaluation reward: 4.54\n",
      "episode: 1342   score: 6.0   memory length: 282653   epsilon: 0.6383450800078512    steps: 344    lr: 4e-05     evaluation reward: 4.57\n",
      "episode: 1343   score: 5.0   memory length: 282967   epsilon: 0.6377233600078647    steps: 314    lr: 4e-05     evaluation reward: 4.58\n",
      "episode: 1344   score: 5.0   memory length: 283255   epsilon: 0.637153120007877    steps: 288    lr: 4e-05     evaluation reward: 4.56\n",
      "episode: 1345   score: 6.0   memory length: 283627   epsilon: 0.636416560007893    steps: 372    lr: 4e-05     evaluation reward: 4.62\n",
      "episode: 1346   score: 7.0   memory length: 284033   epsilon: 0.6356126800079105    steps: 406    lr: 4e-05     evaluation reward: 4.64\n",
      "episode: 1347   score: 4.0   memory length: 284312   epsilon: 0.6350602600079225    steps: 279    lr: 4e-05     evaluation reward: 4.65\n",
      "episode: 1348   score: 9.0   memory length: 284813   epsilon: 0.634068280007944    steps: 501    lr: 4e-05     evaluation reward: 4.7\n",
      "episode: 1349   score: 5.0   memory length: 285137   epsilon: 0.633426760007958    steps: 324    lr: 4e-05     evaluation reward: 4.66\n",
      "episode: 1350   score: 5.0   memory length: 285432   epsilon: 0.6328426600079706    steps: 295    lr: 4e-05     evaluation reward: 4.68\n",
      "episode: 1351   score: 5.0   memory length: 285755   epsilon: 0.6322031200079845    steps: 323    lr: 4e-05     evaluation reward: 4.67\n",
      "episode: 1352   score: 8.0   memory length: 286198   epsilon: 0.6313259800080036    steps: 443    lr: 4e-05     evaluation reward: 4.73\n",
      "episode: 1353   score: 5.0   memory length: 286519   epsilon: 0.6306904000080173    steps: 321    lr: 4e-05     evaluation reward: 4.74\n",
      "episode: 1354   score: 11.0   memory length: 287102   epsilon: 0.6295360600080424    steps: 583    lr: 4e-05     evaluation reward: 4.8\n",
      "episode: 1355   score: 2.0   memory length: 287320   epsilon: 0.6291044200080518    steps: 218    lr: 4e-05     evaluation reward: 4.77\n",
      "episode: 1356   score: 7.0   memory length: 287745   epsilon: 0.62826292000807    steps: 425    lr: 4e-05     evaluation reward: 4.82\n",
      "episode: 1357   score: 5.0   memory length: 288072   epsilon: 0.6276154600080841    steps: 327    lr: 4e-05     evaluation reward: 4.87\n",
      "episode: 1358   score: 5.0   memory length: 288363   epsilon: 0.6270392800080966    steps: 291    lr: 4e-05     evaluation reward: 4.91\n",
      "episode: 1359   score: 7.0   memory length: 288808   epsilon: 0.6261581800081157    steps: 445    lr: 4e-05     evaluation reward: 4.94\n",
      "episode: 1360   score: 5.0   memory length: 289115   epsilon: 0.6255503200081289    steps: 307    lr: 4e-05     evaluation reward: 4.95\n",
      "episode: 1361   score: 5.0   memory length: 289458   epsilon: 0.6248711800081437    steps: 343    lr: 4e-05     evaluation reward: 4.94\n",
      "episode: 1362   score: 7.0   memory length: 289846   epsilon: 0.6241029400081604    steps: 388    lr: 4e-05     evaluation reward: 4.95\n",
      "episode: 1363   score: 5.0   memory length: 290171   epsilon: 0.6234594400081743    steps: 325    lr: 4e-05     evaluation reward: 4.97\n",
      "episode: 1364   score: 2.0   memory length: 290373   epsilon: 0.623059480008183    steps: 202    lr: 4e-05     evaluation reward: 4.94\n",
      "episode: 1365   score: 6.0   memory length: 290747   epsilon: 0.6223189600081991    steps: 374    lr: 4e-05     evaluation reward: 4.92\n",
      "episode: 1366   score: 5.0   memory length: 291050   epsilon: 0.6217190200082121    steps: 303    lr: 4e-05     evaluation reward: 4.96\n",
      "episode: 1367   score: 5.0   memory length: 291359   epsilon: 0.6211072000082254    steps: 309    lr: 4e-05     evaluation reward: 4.97\n",
      "episode: 1368   score: 2.0   memory length: 291541   epsilon: 0.6207468400082332    steps: 182    lr: 4e-05     evaluation reward: 4.95\n",
      "episode: 1369   score: 5.0   memory length: 291905   epsilon: 0.6200261200082489    steps: 364    lr: 4e-05     evaluation reward: 4.98\n",
      "episode: 1370   score: 3.0   memory length: 292150   epsilon: 0.6195410200082594    steps: 245    lr: 4e-05     evaluation reward: 4.93\n",
      "episode: 1371   score: 5.0   memory length: 292453   epsilon: 0.6189410800082724    steps: 303    lr: 4e-05     evaluation reward: 4.9\n",
      "episode: 1372   score: 3.0   memory length: 292699   epsilon: 0.618454000008283    steps: 246    lr: 4e-05     evaluation reward: 4.88\n",
      "episode: 1373   score: 3.0   memory length: 292929   epsilon: 0.6179986000082929    steps: 230    lr: 4e-05     evaluation reward: 4.88\n",
      "episode: 1374   score: 6.0   memory length: 293271   epsilon: 0.6173214400083076    steps: 342    lr: 4e-05     evaluation reward: 4.9\n",
      "episode: 1375   score: 3.0   memory length: 293497   epsilon: 0.6168739600083173    steps: 226    lr: 4e-05     evaluation reward: 4.89\n",
      "episode: 1376   score: 4.0   memory length: 293794   epsilon: 0.6162859000083301    steps: 297    lr: 4e-05     evaluation reward: 4.9\n",
      "episode: 1377   score: 3.0   memory length: 294040   epsilon: 0.6157988200083406    steps: 246    lr: 4e-05     evaluation reward: 4.86\n",
      "episode: 1378   score: 4.0   memory length: 294336   epsilon: 0.6152127400083534    steps: 296    lr: 4e-05     evaluation reward: 4.84\n",
      "episode: 1379   score: 7.0   memory length: 294704   epsilon: 0.6144841000083692    steps: 368    lr: 4e-05     evaluation reward: 4.87\n",
      "episode: 1380   score: 4.0   memory length: 294961   epsilon: 0.6139752400083802    steps: 257    lr: 4e-05     evaluation reward: 4.89\n",
      "episode: 1381   score: 7.0   memory length: 295365   epsilon: 0.6131753200083976    steps: 404    lr: 4e-05     evaluation reward: 4.94\n",
      "episode: 1382   score: 3.0   memory length: 295593   epsilon: 0.6127238800084074    steps: 228    lr: 4e-05     evaluation reward: 4.94\n",
      "episode: 1383   score: 7.0   memory length: 295938   epsilon: 0.6120407800084222    steps: 345    lr: 4e-05     evaluation reward: 4.95\n",
      "episode: 1384   score: 5.0   memory length: 296217   epsilon: 0.6114883600084342    steps: 279    lr: 4e-05     evaluation reward: 4.99\n",
      "episode: 1385   score: 2.0   memory length: 296396   epsilon: 0.6111339400084419    steps: 179    lr: 4e-05     evaluation reward: 4.94\n",
      "episode: 1386   score: 3.0   memory length: 296625   epsilon: 0.6106805200084517    steps: 229    lr: 4e-05     evaluation reward: 4.92\n",
      "episode: 1387   score: 2.0   memory length: 296823   epsilon: 0.6102884800084603    steps: 198    lr: 4e-05     evaluation reward: 4.89\n",
      "episode: 1388   score: 3.0   memory length: 297048   epsilon: 0.6098429800084699    steps: 225    lr: 4e-05     evaluation reward: 4.87\n",
      "episode: 1389   score: 4.0   memory length: 297306   epsilon: 0.609332140008481    steps: 258    lr: 4e-05     evaluation reward: 4.85\n",
      "episode: 1390   score: 3.0   memory length: 297556   epsilon: 0.6088371400084918    steps: 250    lr: 4e-05     evaluation reward: 4.82\n",
      "episode: 1391   score: 8.0   memory length: 297971   epsilon: 0.6080154400085096    steps: 415    lr: 4e-05     evaluation reward: 4.85\n",
      "episode: 1392   score: 8.0   memory length: 298414   epsilon: 0.6071383000085286    steps: 443    lr: 4e-05     evaluation reward: 4.91\n",
      "episode: 1393   score: 3.0   memory length: 298627   epsilon: 0.6067165600085378    steps: 213    lr: 4e-05     evaluation reward: 4.91\n",
      "episode: 1394   score: 4.0   memory length: 298923   epsilon: 0.6061304800085505    steps: 296    lr: 4e-05     evaluation reward: 4.9\n",
      "episode: 1395   score: 8.0   memory length: 299417   epsilon: 0.6051523600085718    steps: 494    lr: 4e-05     evaluation reward: 4.91\n",
      "episode: 1396   score: 1.0   memory length: 299568   epsilon: 0.6048533800085782    steps: 151    lr: 4e-05     evaluation reward: 4.86\n",
      "episode: 1397   score: 3.0   memory length: 299798   epsilon: 0.6043979800085881    steps: 230    lr: 4e-05     evaluation reward: 4.86\n",
      "episode: 1398   score: 7.0   memory length: 300184   epsilon: 0.6036337000086047    steps: 386    lr: 1.6000000000000003e-05     evaluation reward: 4.89\n",
      "episode: 1399   score: 6.0   memory length: 300518   epsilon: 0.6029723800086191    steps: 334    lr: 1.6000000000000003e-05     evaluation reward: 4.87\n",
      "episode: 1400   score: 4.0   memory length: 300780   epsilon: 0.6024536200086303    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 4.87\n",
      "episode: 1401   score: 11.0   memory length: 301184   epsilon: 0.6016537000086477    steps: 404    lr: 1.6000000000000003e-05     evaluation reward: 4.93\n",
      "episode: 1402   score: 4.0   memory length: 301477   epsilon: 0.6010735600086603    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 4.87\n",
      "episode: 1403   score: 3.0   memory length: 301726   epsilon: 0.600580540008671    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 4.86\n",
      "episode: 1404   score: 5.0   memory length: 302033   epsilon: 0.5999726800086842    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.87\n",
      "episode: 1405   score: 9.0   memory length: 302490   epsilon: 0.5990678200087038    steps: 457    lr: 1.6000000000000003e-05     evaluation reward: 4.93\n",
      "episode: 1406   score: 5.0   memory length: 302799   epsilon: 0.5984560000087171    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 4.92\n",
      "episode: 1407   score: 4.0   memory length: 303038   epsilon: 0.5979827800087274    steps: 239    lr: 1.6000000000000003e-05     evaluation reward: 4.92\n",
      "episode: 1408   score: 5.0   memory length: 303364   epsilon: 0.5973373000087414    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 4.9\n",
      "episode: 1409   score: 4.0   memory length: 303658   epsilon: 0.596755180008754    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 4.89\n",
      "episode: 1410   score: 7.0   memory length: 304052   epsilon: 0.595975060008771    steps: 394    lr: 1.6000000000000003e-05     evaluation reward: 4.92\n",
      "episode: 1411   score: 5.0   memory length: 304357   epsilon: 0.5953711600087841    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 4.95\n",
      "episode: 1412   score: 10.0   memory length: 304870   epsilon: 0.5943554200088061    steps: 513    lr: 1.6000000000000003e-05     evaluation reward: 5.0\n",
      "episode: 1413   score: 6.0   memory length: 305206   epsilon: 0.5936901400088206    steps: 336    lr: 1.6000000000000003e-05     evaluation reward: 5.02\n",
      "episode: 1414   score: 7.0   memory length: 305629   epsilon: 0.5928526000088388    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 5.03\n",
      "episode: 1415   score: 3.0   memory length: 305841   epsilon: 0.5924328400088479    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 5.02\n",
      "episode: 1416   score: 7.0   memory length: 306245   epsilon: 0.5916329200088652    steps: 404    lr: 1.6000000000000003e-05     evaluation reward: 5.01\n",
      "episode: 1417   score: 4.0   memory length: 306524   epsilon: 0.5910805000088772    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.96\n",
      "episode: 1418   score: 5.0   memory length: 306834   epsilon: 0.5904667000088906    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 4.98\n",
      "episode: 1419   score: 6.0   memory length: 307211   epsilon: 0.5897202400089068    steps: 377    lr: 1.6000000000000003e-05     evaluation reward: 5.01\n",
      "episode: 1420   score: 4.0   memory length: 307477   epsilon: 0.5891935600089182    steps: 266    lr: 1.6000000000000003e-05     evaluation reward: 5.03\n",
      "episode: 1421   score: 8.0   memory length: 307923   epsilon: 0.5883104800089374    steps: 446    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n",
      "episode: 1422   score: 5.0   memory length: 308267   epsilon: 0.5876293600089522    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 5.1\n",
      "episode: 1423   score: 4.0   memory length: 308559   epsilon: 0.5870512000089647    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 5.09\n",
      "episode: 1424   score: 7.0   memory length: 308983   epsilon: 0.5862116800089829    steps: 424    lr: 1.6000000000000003e-05     evaluation reward: 5.08\n",
      "episode: 1425   score: 3.0   memory length: 309212   epsilon: 0.5857582600089928    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n",
      "episode: 1426   score: 4.0   memory length: 309468   epsilon: 0.5852513800090038    steps: 256    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n",
      "episode: 1427   score: 7.0   memory length: 309873   epsilon: 0.5844494800090212    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 5.09\n",
      "episode: 1428   score: 6.0   memory length: 310208   epsilon: 0.5837861800090356    steps: 335    lr: 1.6000000000000003e-05     evaluation reward: 5.09\n",
      "episode: 1429   score: 6.0   memory length: 310552   epsilon: 0.5831050600090504    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 5.13\n",
      "episode: 1430   score: 6.0   memory length: 310894   epsilon: 0.5824279000090651    steps: 342    lr: 1.6000000000000003e-05     evaluation reward: 5.14\n",
      "episode: 1431   score: 6.0   memory length: 311259   epsilon: 0.5817052000090808    steps: 365    lr: 1.6000000000000003e-05     evaluation reward: 5.18\n",
      "episode: 1432   score: 10.0   memory length: 311742   epsilon: 0.5807488600091015    steps: 483    lr: 1.6000000000000003e-05     evaluation reward: 5.25\n",
      "episode: 1433   score: 6.0   memory length: 312067   epsilon: 0.5801053600091155    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 5.27\n",
      "episode: 1434   score: 4.0   memory length: 312311   epsilon: 0.579622240009126    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 5.27\n",
      "episode: 1435   score: 10.0   memory length: 312824   epsilon: 0.578606500009148    steps: 513    lr: 1.6000000000000003e-05     evaluation reward: 5.27\n",
      "episode: 1436   score: 2.0   memory length: 313021   epsilon: 0.5782164400091565    steps: 197    lr: 1.6000000000000003e-05     evaluation reward: 5.22\n",
      "episode: 1437   score: 5.0   memory length: 313329   epsilon: 0.5776066000091697    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 5.21\n",
      "episode: 1438   score: 1.0   memory length: 313480   epsilon: 0.5773076200091762    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 5.19\n",
      "episode: 1439   score: 6.0   memory length: 313834   epsilon: 0.5766067000091915    steps: 354    lr: 1.6000000000000003e-05     evaluation reward: 5.23\n",
      "episode: 1440   score: 7.0   memory length: 314280   epsilon: 0.5757236200092106    steps: 446    lr: 1.6000000000000003e-05     evaluation reward: 5.2\n",
      "episode: 1441   score: 8.0   memory length: 314706   epsilon: 0.5748801400092289    steps: 426    lr: 1.6000000000000003e-05     evaluation reward: 5.25\n",
      "episode: 1442   score: 7.0   memory length: 315132   epsilon: 0.5740366600092472    steps: 426    lr: 1.6000000000000003e-05     evaluation reward: 5.26\n",
      "episode: 1443   score: 10.0   memory length: 315523   epsilon: 0.573262480009264    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 5.31\n",
      "episode: 1444   score: 13.0   memory length: 316122   epsilon: 0.5720764600092898    steps: 599    lr: 1.6000000000000003e-05     evaluation reward: 5.39\n",
      "episode: 1445   score: 3.0   memory length: 316333   epsilon: 0.5716586800092989    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 5.36\n",
      "episode: 1446   score: 12.0   memory length: 316834   epsilon: 0.5706667000093204    steps: 501    lr: 1.6000000000000003e-05     evaluation reward: 5.41\n",
      "episode: 1447   score: 7.0   memory length: 317254   epsilon: 0.5698351000093385    steps: 420    lr: 1.6000000000000003e-05     evaluation reward: 5.44\n",
      "episode: 1448   score: 9.0   memory length: 317695   epsilon: 0.5689619200093574    steps: 441    lr: 1.6000000000000003e-05     evaluation reward: 5.44\n",
      "episode: 1449   score: 3.0   memory length: 317943   epsilon: 0.5684708800093681    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 5.42\n",
      "episode: 1450   score: 6.0   memory length: 318297   epsilon: 0.5677699600093833    steps: 354    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n",
      "episode: 1451   score: 5.0   memory length: 318626   epsilon: 0.5671185400093974    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n",
      "episode: 1452   score: 5.0   memory length: 318936   epsilon: 0.5665047400094108    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 5.4\n",
      "episode: 1453   score: 6.0   memory length: 319274   epsilon: 0.5658355000094253    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 5.41\n",
      "episode: 1454   score: 3.0   memory length: 319519   epsilon: 0.5653504000094358    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 5.33\n",
      "episode: 1455   score: 5.0   memory length: 319867   epsilon: 0.5646613600094508    steps: 348    lr: 1.6000000000000003e-05     evaluation reward: 5.36\n",
      "episode: 1456   score: 5.0   memory length: 320154   epsilon: 0.5640931000094631    steps: 287    lr: 1.6000000000000003e-05     evaluation reward: 5.34\n",
      "episode: 1457   score: 7.0   memory length: 320515   epsilon: 0.5633783200094786    steps: 361    lr: 1.6000000000000003e-05     evaluation reward: 5.36\n",
      "episode: 1458   score: 5.0   memory length: 320837   epsilon: 0.5627407600094925    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 5.36\n",
      "episode: 1459   score: 3.0   memory length: 321067   epsilon: 0.5622853600095024    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 5.32\n",
      "episode: 1460   score: 10.0   memory length: 321596   epsilon: 0.5612379400095251    steps: 529    lr: 1.6000000000000003e-05     evaluation reward: 5.37\n",
      "episode: 1461   score: 9.0   memory length: 322089   epsilon: 0.5602618000095463    steps: 493    lr: 1.6000000000000003e-05     evaluation reward: 5.41\n",
      "episode: 1462   score: 9.0   memory length: 322542   epsilon: 0.5593648600095658    steps: 453    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n",
      "episode: 1463   score: 5.0   memory length: 322837   epsilon: 0.5587807600095784    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n",
      "episode: 1464   score: 7.0   memory length: 323243   epsilon: 0.5579768800095959    steps: 406    lr: 1.6000000000000003e-05     evaluation reward: 5.48\n",
      "episode: 1465   score: 6.0   memory length: 323563   epsilon: 0.5573432800096096    steps: 320    lr: 1.6000000000000003e-05     evaluation reward: 5.48\n",
      "episode: 1466   score: 4.0   memory length: 323807   epsilon: 0.5568601600096201    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 5.47\n",
      "episode: 1467   score: 6.0   memory length: 324143   epsilon: 0.5561948800096346    steps: 336    lr: 1.6000000000000003e-05     evaluation reward: 5.48\n",
      "episode: 1468   score: 3.0   memory length: 324355   epsilon: 0.5557751200096437    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 5.49\n",
      "episode: 1469   score: 6.0   memory length: 324732   epsilon: 0.5550286600096599    steps: 377    lr: 1.6000000000000003e-05     evaluation reward: 5.5\n",
      "episode: 1470   score: 8.0   memory length: 325203   epsilon: 0.5540960800096801    steps: 471    lr: 1.6000000000000003e-05     evaluation reward: 5.55\n",
      "episode: 1471   score: 8.0   memory length: 325640   epsilon: 0.5532308200096989    steps: 437    lr: 1.6000000000000003e-05     evaluation reward: 5.58\n",
      "episode: 1472   score: 6.0   memory length: 325997   epsilon: 0.5525239600097143    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 5.61\n",
      "episode: 1473   score: 3.0   memory length: 326208   epsilon: 0.5521061800097233    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 5.61\n",
      "episode: 1474   score: 5.0   memory length: 326506   epsilon: 0.5515161400097361    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 5.6\n",
      "episode: 1475   score: 9.0   memory length: 326946   epsilon: 0.5506449400097551    steps: 440    lr: 1.6000000000000003e-05     evaluation reward: 5.66\n",
      "episode: 1476   score: 6.0   memory length: 327314   epsilon: 0.5499163000097709    steps: 368    lr: 1.6000000000000003e-05     evaluation reward: 5.68\n",
      "episode: 1477   score: 3.0   memory length: 327526   epsilon: 0.54949654000978    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 5.68\n",
      "episode: 1478   score: 7.0   memory length: 327939   epsilon: 0.5486788000097977    steps: 413    lr: 1.6000000000000003e-05     evaluation reward: 5.71\n",
      "episode: 1479   score: 3.0   memory length: 328185   epsilon: 0.5481917200098083    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 5.67\n",
      "episode: 1480   score: 6.0   memory length: 328541   epsilon: 0.5474868400098236    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 5.69\n",
      "episode: 1481   score: 4.0   memory length: 328836   epsilon: 0.5469027400098363    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 5.66\n",
      "episode: 1482   score: 3.0   memory length: 329103   epsilon: 0.5463740800098478    steps: 267    lr: 1.6000000000000003e-05     evaluation reward: 5.66\n",
      "episode: 1483   score: 5.0   memory length: 329411   epsilon: 0.545764240009861    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 5.64\n",
      "episode: 1484   score: 8.0   memory length: 329831   epsilon: 0.5449326400098791    steps: 420    lr: 1.6000000000000003e-05     evaluation reward: 5.67\n",
      "episode: 1485   score: 5.0   memory length: 330103   epsilon: 0.5443940800098908    steps: 272    lr: 1.6000000000000003e-05     evaluation reward: 5.7\n",
      "episode: 1486   score: 7.0   memory length: 330515   epsilon: 0.5435783200099085    steps: 412    lr: 1.6000000000000003e-05     evaluation reward: 5.74\n",
      "episode: 1487   score: 7.0   memory length: 330916   epsilon: 0.5427843400099257    steps: 401    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n",
      "episode: 1488   score: 3.0   memory length: 331145   epsilon: 0.5423309200099355    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n",
      "episode: 1489   score: 4.0   memory length: 331405   epsilon: 0.5418161200099467    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n",
      "episode: 1490   score: 6.0   memory length: 331744   epsilon: 0.5411449000099613    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 5.82\n",
      "episode: 1491   score: 4.0   memory length: 332018   epsilon: 0.5406023800099731    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 5.78\n",
      "episode: 1492   score: 6.0   memory length: 332394   epsilon: 0.5398579000099892    steps: 376    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n",
      "episode: 1493   score: 4.0   memory length: 332669   epsilon: 0.539313400010001    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 5.77\n",
      "episode: 1494   score: 4.0   memory length: 332928   epsilon: 0.5388005800100122    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 5.77\n",
      "episode: 1495   score: 5.0   memory length: 333236   epsilon: 0.5381907400100254    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 5.74\n",
      "episode: 1496   score: 6.0   memory length: 333557   epsilon: 0.5375551600100392    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n",
      "episode: 1497   score: 6.0   memory length: 333928   epsilon: 0.5368205800100552    steps: 371    lr: 1.6000000000000003e-05     evaluation reward: 5.82\n",
      "episode: 1498   score: 4.0   memory length: 334224   epsilon: 0.5362345000100679    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n",
      "episode: 1499   score: 6.0   memory length: 334587   epsilon: 0.5355157600100835    steps: 363    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n",
      "episode: 1500   score: 4.0   memory length: 334865   epsilon: 0.5349653200100954    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n",
      "episode: 1501   score: 7.0   memory length: 335252   epsilon: 0.5341990600101121    steps: 387    lr: 1.6000000000000003e-05     evaluation reward: 5.75\n",
      "episode: 1502   score: 3.0   memory length: 335477   epsilon: 0.5337535600101218    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 5.74\n",
      "episode: 1503   score: 12.0   memory length: 335972   epsilon: 0.532773460010143    steps: 495    lr: 1.6000000000000003e-05     evaluation reward: 5.83\n",
      "episode: 1504   score: 10.0   memory length: 336311   epsilon: 0.5321022400101576    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 5.88\n",
      "episode: 1505   score: 5.0   memory length: 336639   epsilon: 0.5314528000101717    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 5.84\n",
      "episode: 1506   score: 5.0   memory length: 336926   epsilon: 0.530884540010184    steps: 287    lr: 1.6000000000000003e-05     evaluation reward: 5.84\n",
      "episode: 1507   score: 6.0   memory length: 337319   epsilon: 0.5301064000102009    steps: 393    lr: 1.6000000000000003e-05     evaluation reward: 5.86\n",
      "episode: 1508   score: 2.0   memory length: 337517   epsilon: 0.5297143600102094    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 5.83\n",
      "episode: 1509   score: 7.0   memory length: 337921   epsilon: 0.5289144400102268    steps: 404    lr: 1.6000000000000003e-05     evaluation reward: 5.86\n",
      "episode: 1510   score: 5.0   memory length: 338230   epsilon: 0.5283026200102401    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 5.84\n",
      "episode: 1511   score: 2.0   memory length: 338428   epsilon: 0.5279105800102486    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 5.81\n",
      "episode: 1512   score: 5.0   memory length: 338756   epsilon: 0.5272611400102627    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n",
      "episode: 1513   score: 7.0   memory length: 339138   epsilon: 0.5265047800102791    steps: 382    lr: 1.6000000000000003e-05     evaluation reward: 5.77\n",
      "episode: 1514   score: 7.0   memory length: 339539   epsilon: 0.5257108000102964    steps: 401    lr: 1.6000000000000003e-05     evaluation reward: 5.77\n",
      "episode: 1515   score: 4.0   memory length: 339834   epsilon: 0.525126700010309    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 5.78\n",
      "episode: 1516   score: 3.0   memory length: 340062   epsilon: 0.5246752600103188    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 5.74\n",
      "episode: 1517   score: 7.0   memory length: 340469   epsilon: 0.5238694000103363    steps: 407    lr: 1.6000000000000003e-05     evaluation reward: 5.77\n",
      "episode: 1518   score: 7.0   memory length: 340865   epsilon: 0.5230853200103533    steps: 396    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n",
      "episode: 1519   score: 12.0   memory length: 341514   epsilon: 0.5218003000103812    steps: 649    lr: 1.6000000000000003e-05     evaluation reward: 5.85\n",
      "episode: 1520   score: 3.0   memory length: 341743   epsilon: 0.5213468800103911    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 5.84\n",
      "episode: 1521   score: 4.0   memory length: 341985   epsilon: 0.5208677200104015    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 5.8\n",
      "episode: 1522   score: 5.0   memory length: 342289   epsilon: 0.5202658000104146    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 5.8\n",
      "episode: 1523   score: 4.0   memory length: 342545   epsilon: 0.5197589200104256    steps: 256    lr: 1.6000000000000003e-05     evaluation reward: 5.8\n",
      "episode: 1524   score: 11.0   memory length: 343101   epsilon: 0.5186580400104495    steps: 556    lr: 1.6000000000000003e-05     evaluation reward: 5.84\n",
      "episode: 1525   score: 8.0   memory length: 343542   epsilon: 0.5177848600104684    steps: 441    lr: 1.6000000000000003e-05     evaluation reward: 5.89\n",
      "episode: 1526   score: 5.0   memory length: 343885   epsilon: 0.5171057200104832    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 5.9\n",
      "episode: 1527   score: 8.0   memory length: 344356   epsilon: 0.5161731400105034    steps: 471    lr: 1.6000000000000003e-05     evaluation reward: 5.91\n",
      "episode: 1528   score: 11.0   memory length: 344887   epsilon: 0.5151217600105262    steps: 531    lr: 1.6000000000000003e-05     evaluation reward: 5.96\n",
      "episode: 1529   score: 8.0   memory length: 345312   epsilon: 0.5142802600105445    steps: 425    lr: 1.6000000000000003e-05     evaluation reward: 5.98\n",
      "episode: 1530   score: 5.0   memory length: 345618   epsilon: 0.5136743800105577    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 5.97\n",
      "episode: 1531   score: 9.0   memory length: 346075   epsilon: 0.5127695200105773    steps: 457    lr: 1.6000000000000003e-05     evaluation reward: 6.0\n",
      "episode: 1532   score: 8.0   memory length: 346464   epsilon: 0.511999300010594    steps: 389    lr: 1.6000000000000003e-05     evaluation reward: 5.98\n",
      "episode: 1533   score: 3.0   memory length: 346695   epsilon: 0.511541920010604    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 5.95\n",
      "episode: 1534   score: 3.0   memory length: 346905   epsilon: 0.511126120010613    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 5.94\n",
      "episode: 1535   score: 9.0   memory length: 347388   epsilon: 0.5101697800106337    steps: 483    lr: 1.6000000000000003e-05     evaluation reward: 5.93\n",
      "episode: 1536   score: 8.0   memory length: 347793   epsilon: 0.5093678800106511    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 5.99\n",
      "episode: 1537   score: 16.0   memory length: 348388   epsilon: 0.5081897800106767    steps: 595    lr: 1.6000000000000003e-05     evaluation reward: 6.1\n",
      "episode: 1538   score: 5.0   memory length: 348694   epsilon: 0.5075839000106899    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 6.14\n",
      "episode: 1539   score: 3.0   memory length: 348920   epsilon: 0.5071364200106996    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 6.11\n",
      "episode: 1540   score: 6.0   memory length: 349254   epsilon: 0.5064751000107139    steps: 334    lr: 1.6000000000000003e-05     evaluation reward: 6.1\n",
      "episode: 1541   score: 5.0   memory length: 349574   epsilon: 0.5058415000107277    steps: 320    lr: 1.6000000000000003e-05     evaluation reward: 6.07\n",
      "episode: 1542   score: 5.0   memory length: 349882   epsilon: 0.5052316600107409    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 6.05\n",
      "episode: 1543   score: 6.0   memory length: 350255   epsilon: 0.504493120010757    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 6.01\n",
      "episode: 1544   score: 8.0   memory length: 350711   epsilon: 0.5035902400107766    steps: 456    lr: 1.6000000000000003e-05     evaluation reward: 5.96\n",
      "episode: 1545   score: 6.0   memory length: 351034   epsilon: 0.5029507000107905    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 5.99\n",
      "episode: 1546   score: 8.0   memory length: 351494   epsilon: 0.5020399000108102    steps: 460    lr: 1.6000000000000003e-05     evaluation reward: 5.95\n",
      "episode: 1547   score: 10.0   memory length: 351961   epsilon: 0.5011152400108303    steps: 467    lr: 1.6000000000000003e-05     evaluation reward: 5.98\n",
      "episode: 1548   score: 4.0   memory length: 352239   epsilon: 0.5005648000108422    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 5.93\n",
      "episode: 1549   score: 5.0   memory length: 352554   epsilon: 0.4999411000108541    steps: 315    lr: 1.6000000000000003e-05     evaluation reward: 5.95\n",
      "episode: 1550   score: 13.0   memory length: 353096   epsilon: 0.49886794001084733    steps: 542    lr: 1.6000000000000003e-05     evaluation reward: 6.02\n",
      "episode: 1551   score: 2.0   memory length: 353278   epsilon: 0.49850758001084505    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 5.99\n",
      "episode: 1552   score: 6.0   memory length: 353597   epsilon: 0.49787596001084106    steps: 319    lr: 1.6000000000000003e-05     evaluation reward: 6.0\n",
      "episode: 1553   score: 7.0   memory length: 353845   epsilon: 0.49738492001083795    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 6.01\n",
      "episode: 1554   score: 8.0   memory length: 354266   epsilon: 0.4965513400108327    steps: 421    lr: 1.6000000000000003e-05     evaluation reward: 6.06\n",
      "episode: 1555   score: 11.0   memory length: 354794   epsilon: 0.49550590001082606    steps: 528    lr: 1.6000000000000003e-05     evaluation reward: 6.12\n",
      "episode: 1556   score: 6.0   memory length: 355172   epsilon: 0.4947574600108213    steps: 378    lr: 1.6000000000000003e-05     evaluation reward: 6.13\n",
      "episode: 1557   score: 8.0   memory length: 355617   epsilon: 0.49387636001081575    steps: 445    lr: 1.6000000000000003e-05     evaluation reward: 6.14\n",
      "episode: 1558   score: 4.0   memory length: 355890   epsilon: 0.49333582001081233    steps: 273    lr: 1.6000000000000003e-05     evaluation reward: 6.13\n",
      "episode: 1559   score: 4.0   memory length: 356145   epsilon: 0.49283092001080914    steps: 255    lr: 1.6000000000000003e-05     evaluation reward: 6.14\n",
      "episode: 1560   score: 9.0   memory length: 356632   epsilon: 0.49186666001080304    steps: 487    lr: 1.6000000000000003e-05     evaluation reward: 6.13\n",
      "episode: 1561   score: 7.0   memory length: 357033   epsilon: 0.491072680010798    steps: 401    lr: 1.6000000000000003e-05     evaluation reward: 6.11\n",
      "episode: 1562   score: 7.0   memory length: 357412   epsilon: 0.49032226001079326    steps: 379    lr: 1.6000000000000003e-05     evaluation reward: 6.09\n",
      "episode: 1563   score: 11.0   memory length: 357836   epsilon: 0.48948274001078795    steps: 424    lr: 1.6000000000000003e-05     evaluation reward: 6.15\n",
      "episode: 1564   score: 9.0   memory length: 358279   epsilon: 0.4886056000107824    steps: 443    lr: 1.6000000000000003e-05     evaluation reward: 6.17\n",
      "episode: 1565   score: 2.0   memory length: 358481   epsilon: 0.4882056400107799    steps: 202    lr: 1.6000000000000003e-05     evaluation reward: 6.13\n",
      "episode: 1566   score: 3.0   memory length: 358711   epsilon: 0.487750240010777    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 6.12\n",
      "episode: 1567   score: 3.0   memory length: 358955   epsilon: 0.48726712001077394    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 6.09\n",
      "episode: 1568   score: 6.0   memory length: 359292   epsilon: 0.4865998600107697    steps: 337    lr: 1.6000000000000003e-05     evaluation reward: 6.12\n",
      "episode: 1569   score: 12.0   memory length: 359764   epsilon: 0.4856653000107638    steps: 472    lr: 1.6000000000000003e-05     evaluation reward: 6.18\n",
      "episode: 1570   score: 4.0   memory length: 360023   epsilon: 0.48515248001076056    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 6.14\n",
      "episode: 1571   score: 4.0   memory length: 360303   epsilon: 0.48459808001075705    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 6.1\n",
      "episode: 1572   score: 6.0   memory length: 360665   epsilon: 0.4838813200107525    steps: 362    lr: 1.6000000000000003e-05     evaluation reward: 6.1\n",
      "episode: 1573   score: 9.0   memory length: 361136   epsilon: 0.4829487400107466    steps: 471    lr: 1.6000000000000003e-05     evaluation reward: 6.16\n",
      "episode: 1574   score: 8.0   memory length: 361547   epsilon: 0.48213496001074146    steps: 411    lr: 1.6000000000000003e-05     evaluation reward: 6.19\n",
      "episode: 1575   score: 13.0   memory length: 362113   epsilon: 0.4810142800107344    steps: 566    lr: 1.6000000000000003e-05     evaluation reward: 6.23\n",
      "episode: 1576   score: 7.0   memory length: 362487   epsilon: 0.4802737600107297    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 6.24\n",
      "episode: 1577   score: 4.0   memory length: 362731   epsilon: 0.47979064001072663    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 6.25\n",
      "episode: 1578   score: 1.0   memory length: 362881   epsilon: 0.47949364001072475    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 6.19\n",
      "episode: 1579   score: 8.0   memory length: 363333   epsilon: 0.4785986800107191    steps: 452    lr: 1.6000000000000003e-05     evaluation reward: 6.24\n",
      "episode: 1580   score: 4.0   memory length: 363592   epsilon: 0.47808586001071585    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 6.22\n",
      "episode: 1581   score: 3.0   memory length: 363839   epsilon: 0.47759680001071275    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 6.21\n",
      "episode: 1582   score: 3.0   memory length: 364050   epsilon: 0.4771790200107101    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 6.21\n",
      "episode: 1583   score: 6.0   memory length: 364388   epsilon: 0.4765097800107059    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 6.22\n",
      "episode: 1584   score: 7.0   memory length: 364797   epsilon: 0.47569996001070075    steps: 409    lr: 1.6000000000000003e-05     evaluation reward: 6.21\n",
      "episode: 1585   score: 7.0   memory length: 365227   epsilon: 0.47484856001069536    steps: 430    lr: 1.6000000000000003e-05     evaluation reward: 6.23\n",
      "episode: 1586   score: 6.0   memory length: 365586   epsilon: 0.47413774001069087    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 6.22\n",
      "episode: 1587   score: 12.0   memory length: 366164   epsilon: 0.4729933000106836    steps: 578    lr: 1.6000000000000003e-05     evaluation reward: 6.27\n",
      "episode: 1588   score: 6.0   memory length: 366499   epsilon: 0.47233000001067943    steps: 335    lr: 1.6000000000000003e-05     evaluation reward: 6.3\n",
      "episode: 1589   score: 7.0   memory length: 366842   epsilon: 0.47165086001067513    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 6.33\n",
      "episode: 1590   score: 8.0   memory length: 367274   epsilon: 0.4707955000106697    steps: 432    lr: 1.6000000000000003e-05     evaluation reward: 6.35\n",
      "episode: 1591   score: 3.0   memory length: 367486   epsilon: 0.47037574001066706    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 6.34\n",
      "episode: 1592   score: 9.0   memory length: 367991   epsilon: 0.46937584001066074    steps: 505    lr: 1.6000000000000003e-05     evaluation reward: 6.37\n",
      "episode: 1593   score: 4.0   memory length: 368267   epsilon: 0.4688293600106573    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 6.37\n",
      "episode: 1594   score: 7.0   memory length: 368673   epsilon: 0.4680254800106522    steps: 406    lr: 1.6000000000000003e-05     evaluation reward: 6.4\n",
      "episode: 1595   score: 6.0   memory length: 369029   epsilon: 0.46732060001064774    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 6.41\n",
      "episode: 1596   score: 6.0   memory length: 369365   epsilon: 0.4666553200106435    steps: 336    lr: 1.6000000000000003e-05     evaluation reward: 6.41\n",
      "episode: 1597   score: 5.0   memory length: 369670   epsilon: 0.4660514200106397    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 6.4\n",
      "episode: 1598   score: 6.0   memory length: 370012   epsilon: 0.4653742600106354    steps: 342    lr: 1.6000000000000003e-05     evaluation reward: 6.42\n",
      "episode: 1599   score: 3.0   memory length: 370225   epsilon: 0.46495252001063275    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 6.39\n",
      "episode: 1600   score: 11.0   memory length: 370667   epsilon: 0.4640773600106272    steps: 442    lr: 1.6000000000000003e-05     evaluation reward: 6.46\n",
      "episode: 1601   score: 9.0   memory length: 371150   epsilon: 0.46312102001062116    steps: 483    lr: 1.6000000000000003e-05     evaluation reward: 6.48\n",
      "episode: 1602   score: 6.0   memory length: 371523   epsilon: 0.4623824800106165    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 6.51\n",
      "episode: 1603   score: 6.0   memory length: 371854   epsilon: 0.46172710001061235    steps: 331    lr: 1.6000000000000003e-05     evaluation reward: 6.45\n",
      "episode: 1604   score: 7.0   memory length: 372264   epsilon: 0.4609153000106072    steps: 410    lr: 1.6000000000000003e-05     evaluation reward: 6.42\n",
      "episode: 1605   score: 5.0   memory length: 372554   epsilon: 0.4603411000106036    steps: 290    lr: 1.6000000000000003e-05     evaluation reward: 6.42\n",
      "episode: 1606   score: 9.0   memory length: 372915   epsilon: 0.45962632001059905    steps: 361    lr: 1.6000000000000003e-05     evaluation reward: 6.46\n",
      "episode: 1607   score: 5.0   memory length: 373206   epsilon: 0.4590501400105954    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 6.45\n",
      "episode: 1608   score: 9.0   memory length: 373691   epsilon: 0.45808984001058933    steps: 485    lr: 1.6000000000000003e-05     evaluation reward: 6.52\n",
      "episode: 1609   score: 5.0   memory length: 373995   epsilon: 0.4574879200105855    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 6.5\n",
      "episode: 1610   score: 7.0   memory length: 374379   epsilon: 0.4567276000105807    steps: 384    lr: 1.6000000000000003e-05     evaluation reward: 6.52\n",
      "episode: 1611   score: 5.0   memory length: 374684   epsilon: 0.4561237000105769    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 6.55\n",
      "episode: 1612   score: 7.0   memory length: 375065   epsilon: 0.4553693200105721    steps: 381    lr: 1.6000000000000003e-05     evaluation reward: 6.57\n",
      "episode: 1613   score: 5.0   memory length: 375357   epsilon: 0.45479116001056846    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 6.55\n",
      "episode: 1614   score: 4.0   memory length: 375617   epsilon: 0.4542763600105652    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 6.52\n",
      "episode: 1615   score: 1.0   memory length: 375767   epsilon: 0.4539793600105633    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 6.49\n",
      "episode: 1616   score: 3.0   memory length: 375996   epsilon: 0.45352594001056046    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 6.49\n",
      "episode: 1617   score: 9.0   memory length: 376421   epsilon: 0.45268444001055513    steps: 425    lr: 1.6000000000000003e-05     evaluation reward: 6.51\n",
      "episode: 1618   score: 7.0   memory length: 376792   epsilon: 0.4519498600105505    steps: 371    lr: 1.6000000000000003e-05     evaluation reward: 6.51\n",
      "episode: 1619   score: 4.0   memory length: 377066   epsilon: 0.45140734001054705    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 6.43\n",
      "episode: 1620   score: 10.0   memory length: 377592   epsilon: 0.45036586001054046    steps: 526    lr: 1.6000000000000003e-05     evaluation reward: 6.5\n",
      "episode: 1621   score: 11.0   memory length: 378114   epsilon: 0.4493323000105339    steps: 522    lr: 1.6000000000000003e-05     evaluation reward: 6.57\n",
      "episode: 1622   score: 10.0   memory length: 378619   epsilon: 0.4483324000105276    steps: 505    lr: 1.6000000000000003e-05     evaluation reward: 6.62\n",
      "episode: 1623   score: 7.0   memory length: 378989   epsilon: 0.44759980001052296    steps: 370    lr: 1.6000000000000003e-05     evaluation reward: 6.65\n",
      "episode: 1624   score: 21.0   memory length: 379766   epsilon: 0.44606134001051323    steps: 777    lr: 1.6000000000000003e-05     evaluation reward: 6.75\n",
      "episode: 1625   score: 6.0   memory length: 380123   epsilon: 0.44535448001050876    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 6.73\n",
      "episode: 1626   score: 9.0   memory length: 380599   epsilon: 0.4444120000105028    steps: 476    lr: 1.6000000000000003e-05     evaluation reward: 6.77\n",
      "episode: 1627   score: 9.0   memory length: 381031   epsilon: 0.4435566400104974    steps: 432    lr: 1.6000000000000003e-05     evaluation reward: 6.78\n",
      "episode: 1628   score: 3.0   memory length: 381244   epsilon: 0.4431349000104947    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 6.7\n",
      "episode: 1629   score: 8.0   memory length: 381687   epsilon: 0.44225776001048916    steps: 443    lr: 1.6000000000000003e-05     evaluation reward: 6.7\n",
      "episode: 1630   score: 4.0   memory length: 381927   epsilon: 0.44178256001048616    steps: 240    lr: 1.6000000000000003e-05     evaluation reward: 6.69\n",
      "episode: 1631   score: 12.0   memory length: 382418   epsilon: 0.44081038001048    steps: 491    lr: 1.6000000000000003e-05     evaluation reward: 6.72\n",
      "episode: 1632   score: 5.0   memory length: 382765   epsilon: 0.44012332001047566    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 6.69\n",
      "episode: 1633   score: 4.0   memory length: 383006   epsilon: 0.43964614001047264    steps: 241    lr: 1.6000000000000003e-05     evaluation reward: 6.7\n",
      "episode: 1634   score: 9.0   memory length: 383528   epsilon: 0.4386125800104661    steps: 522    lr: 1.6000000000000003e-05     evaluation reward: 6.76\n",
      "episode: 1635   score: 8.0   memory length: 383906   epsilon: 0.43786414001046137    steps: 378    lr: 1.6000000000000003e-05     evaluation reward: 6.75\n",
      "episode: 1636   score: 12.0   memory length: 384387   epsilon: 0.43691176001045534    steps: 481    lr: 1.6000000000000003e-05     evaluation reward: 6.79\n",
      "episode: 1637   score: 4.0   memory length: 384684   epsilon: 0.4363237000104516    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 6.67\n",
      "episode: 1638   score: 5.0   memory length: 385010   epsilon: 0.43567822001044754    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 6.67\n",
      "episode: 1639   score: 6.0   memory length: 385347   epsilon: 0.4350109600104433    steps: 337    lr: 1.6000000000000003e-05     evaluation reward: 6.7\n",
      "episode: 1640   score: 9.0   memory length: 385821   epsilon: 0.4340724400104374    steps: 474    lr: 1.6000000000000003e-05     evaluation reward: 6.73\n",
      "episode: 1641   score: 7.0   memory length: 386189   epsilon: 0.43334380001043277    steps: 368    lr: 1.6000000000000003e-05     evaluation reward: 6.75\n",
      "episode: 1642   score: 10.0   memory length: 386667   epsilon: 0.4323973600104268    steps: 478    lr: 1.6000000000000003e-05     evaluation reward: 6.8\n",
      "episode: 1643   score: 12.0   memory length: 387310   epsilon: 0.4311242200104187    steps: 643    lr: 1.6000000000000003e-05     evaluation reward: 6.86\n",
      "episode: 1644   score: 6.0   memory length: 387668   epsilon: 0.43041538001041424    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 6.84\n",
      "episode: 1645   score: 5.0   memory length: 387976   epsilon: 0.4298055400104104    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 6.83\n",
      "episode: 1646   score: 4.0   memory length: 388233   epsilon: 0.42929668001040716    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 6.79\n",
      "episode: 1647   score: 17.0   memory length: 388732   epsilon: 0.4283086600104009    steps: 499    lr: 1.6000000000000003e-05     evaluation reward: 6.86\n",
      "episode: 1648   score: 6.0   memory length: 389103   epsilon: 0.42757408001039626    steps: 371    lr: 1.6000000000000003e-05     evaluation reward: 6.88\n",
      "episode: 1649   score: 4.0   memory length: 389381   epsilon: 0.4270236400103928    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 6.87\n",
      "episode: 1650   score: 4.0   memory length: 389638   epsilon: 0.42651478001038956    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 6.78\n",
      "episode: 1651   score: 8.0   memory length: 390057   epsilon: 0.4256851600103843    steps: 419    lr: 1.6000000000000003e-05     evaluation reward: 6.84\n",
      "episode: 1652   score: 5.0   memory length: 390366   epsilon: 0.42507334001038044    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 6.83\n",
      "episode: 1653   score: 5.0   memory length: 390637   epsilon: 0.42453676001037705    steps: 271    lr: 1.6000000000000003e-05     evaluation reward: 6.81\n",
      "episode: 1654   score: 4.0   memory length: 390911   epsilon: 0.4239942400103736    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 6.77\n",
      "episode: 1655   score: 7.0   memory length: 391323   epsilon: 0.42317848001036845    steps: 412    lr: 1.6000000000000003e-05     evaluation reward: 6.73\n",
      "episode: 1656   score: 4.0   memory length: 391599   epsilon: 0.422632000010365    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 6.71\n",
      "episode: 1657   score: 8.0   memory length: 392054   epsilon: 0.4217311000103593    steps: 455    lr: 1.6000000000000003e-05     evaluation reward: 6.71\n",
      "episode: 1658   score: 12.0   memory length: 392566   epsilon: 0.4207173400103529    steps: 512    lr: 1.6000000000000003e-05     evaluation reward: 6.79\n",
      "episode: 1659   score: 13.0   memory length: 393114   epsilon: 0.419632300010346    steps: 548    lr: 1.6000000000000003e-05     evaluation reward: 6.88\n",
      "episode: 1660   score: 6.0   memory length: 393437   epsilon: 0.41899276001034197    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 6.85\n",
      "episode: 1661   score: 7.0   memory length: 393829   epsilon: 0.41821660001033706    steps: 392    lr: 1.6000000000000003e-05     evaluation reward: 6.85\n",
      "episode: 1662   score: 5.0   memory length: 394174   epsilon: 0.41753350001033274    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 6.83\n",
      "episode: 1663   score: 5.0   memory length: 394480   epsilon: 0.4169276200103289    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 6.77\n",
      "episode: 1664   score: 9.0   memory length: 394915   epsilon: 0.41606632001032345    steps: 435    lr: 1.6000000000000003e-05     evaluation reward: 6.77\n",
      "episode: 1665   score: 5.0   memory length: 395262   epsilon: 0.4153792600103191    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 6.8\n",
      "episode: 1666   score: 3.0   memory length: 395471   epsilon: 0.4149654400103165    steps: 209    lr: 1.6000000000000003e-05     evaluation reward: 6.8\n",
      "episode: 1667   score: 6.0   memory length: 395845   epsilon: 0.4142249200103118    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 6.83\n",
      "episode: 1668   score: 7.0   memory length: 396246   epsilon: 0.4134309400103068    steps: 401    lr: 1.6000000000000003e-05     evaluation reward: 6.84\n",
      "episode: 1669   score: 13.0   memory length: 396840   epsilon: 0.41225482001029934    steps: 594    lr: 1.6000000000000003e-05     evaluation reward: 6.85\n",
      "episode: 1670   score: 9.0   memory length: 397344   epsilon: 0.411256900010293    steps: 504    lr: 1.6000000000000003e-05     evaluation reward: 6.9\n",
      "episode: 1671   score: 8.0   memory length: 397751   epsilon: 0.4104510400102879    steps: 407    lr: 1.6000000000000003e-05     evaluation reward: 6.94\n",
      "episode: 1672   score: 9.0   memory length: 398232   epsilon: 0.4094986600102819    steps: 481    lr: 1.6000000000000003e-05     evaluation reward: 6.97\n",
      "episode: 1673   score: 8.0   memory length: 398604   epsilon: 0.40876210001027724    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 6.96\n",
      "episode: 1674   score: 10.0   memory length: 399070   epsilon: 0.4078394200102714    steps: 466    lr: 1.6000000000000003e-05     evaluation reward: 6.98\n",
      "episode: 1675   score: 6.0   memory length: 399410   epsilon: 0.40716622001026714    steps: 340    lr: 1.6000000000000003e-05     evaluation reward: 6.91\n",
      "episode: 1676   score: 5.0   memory length: 399739   epsilon: 0.406514800010263    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 6.89\n",
      "episode: 1677   score: 10.0   memory length: 400211   epsilon: 0.4055802400102571    steps: 472    lr: 6.400000000000001e-06     evaluation reward: 6.95\n",
      "episode: 1678   score: 6.0   memory length: 400548   epsilon: 0.4049129800102529    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 7.0\n",
      "episode: 1679   score: 7.0   memory length: 400930   epsilon: 0.4041566200102481    steps: 382    lr: 6.400000000000001e-06     evaluation reward: 6.99\n",
      "episode: 1680   score: 8.0   memory length: 401335   epsilon: 0.40335472001024303    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 7.03\n",
      "episode: 1681   score: 16.0   memory length: 401966   epsilon: 0.4021053400102351    steps: 631    lr: 6.400000000000001e-06     evaluation reward: 7.16\n",
      "episode: 1682   score: 6.0   memory length: 402326   epsilon: 0.4013925400102306    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 7.19\n",
      "episode: 1683   score: 6.0   memory length: 402702   epsilon: 0.4006480600102259    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 7.19\n",
      "episode: 1684   score: 9.0   memory length: 403046   epsilon: 0.3999669400102216    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 7.21\n",
      "episode: 1685   score: 9.0   memory length: 403503   epsilon: 0.39906208001021587    steps: 457    lr: 6.400000000000001e-06     evaluation reward: 7.23\n",
      "episode: 1686   score: 9.0   memory length: 403976   epsilon: 0.39812554001020994    steps: 473    lr: 6.400000000000001e-06     evaluation reward: 7.26\n",
      "episode: 1687   score: 9.0   memory length: 404457   epsilon: 0.3971731600102039    steps: 481    lr: 6.400000000000001e-06     evaluation reward: 7.23\n",
      "episode: 1688   score: 13.0   memory length: 404954   epsilon: 0.3961891000101977    steps: 497    lr: 6.400000000000001e-06     evaluation reward: 7.3\n",
      "episode: 1689   score: 6.0   memory length: 405288   epsilon: 0.3955277800101935    steps: 334    lr: 6.400000000000001e-06     evaluation reward: 7.29\n",
      "episode: 1690   score: 5.0   memory length: 405576   epsilon: 0.3949575400101899    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 7.26\n",
      "episode: 1691   score: 13.0   memory length: 406082   epsilon: 0.39395566001018356    steps: 506    lr: 6.400000000000001e-06     evaluation reward: 7.36\n",
      "episode: 1692   score: 7.0   memory length: 406447   epsilon: 0.393232960010179    steps: 365    lr: 6.400000000000001e-06     evaluation reward: 7.34\n",
      "episode: 1693   score: 14.0   memory length: 407037   epsilon: 0.3920647600101716    steps: 590    lr: 6.400000000000001e-06     evaluation reward: 7.44\n",
      "episode: 1694   score: 19.0   memory length: 407708   epsilon: 0.3907361800101632    steps: 671    lr: 6.400000000000001e-06     evaluation reward: 7.56\n",
      "episode: 1695   score: 10.0   memory length: 408080   epsilon: 0.38999962001015853    steps: 372    lr: 6.400000000000001e-06     evaluation reward: 7.6\n",
      "episode: 1696   score: 10.0   memory length: 408565   epsilon: 0.38903932001015246    steps: 485    lr: 6.400000000000001e-06     evaluation reward: 7.64\n",
      "episode: 1697   score: 6.0   memory length: 408902   epsilon: 0.38837206001014823    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 7.65\n",
      "episode: 1698   score: 5.0   memory length: 409208   epsilon: 0.3877661800101444    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 7.64\n",
      "episode: 1699   score: 10.0   memory length: 409731   epsilon: 0.38673064001013785    steps: 523    lr: 6.400000000000001e-06     evaluation reward: 7.71\n",
      "episode: 1700   score: 9.0   memory length: 410209   epsilon: 0.38578420001013186    steps: 478    lr: 6.400000000000001e-06     evaluation reward: 7.69\n",
      "episode: 1701   score: 4.0   memory length: 410465   epsilon: 0.38527732001012865    steps: 256    lr: 6.400000000000001e-06     evaluation reward: 7.64\n",
      "episode: 1702   score: 8.0   memory length: 410873   epsilon: 0.38446948001012354    steps: 408    lr: 6.400000000000001e-06     evaluation reward: 7.66\n",
      "episode: 1703   score: 9.0   memory length: 411325   epsilon: 0.3835745200101179    steps: 452    lr: 6.400000000000001e-06     evaluation reward: 7.69\n",
      "episode: 1704   score: 11.0   memory length: 411730   epsilon: 0.3827726200101128    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 7.73\n",
      "episode: 1705   score: 7.0   memory length: 412121   epsilon: 0.3819984400101079    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 7.75\n",
      "episode: 1706   score: 7.0   memory length: 412507   epsilon: 0.3812341600101031    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 7.73\n",
      "episode: 1707   score: 7.0   memory length: 412947   epsilon: 0.38036296001009756    steps: 440    lr: 6.400000000000001e-06     evaluation reward: 7.75\n",
      "episode: 1708   score: 11.0   memory length: 413503   epsilon: 0.3792620800100906    steps: 556    lr: 6.400000000000001e-06     evaluation reward: 7.77\n",
      "episode: 1709   score: 2.0   memory length: 413682   epsilon: 0.37890766001008835    steps: 179    lr: 6.400000000000001e-06     evaluation reward: 7.74\n",
      "episode: 1710   score: 8.0   memory length: 414141   epsilon: 0.3779988400100826    steps: 459    lr: 6.400000000000001e-06     evaluation reward: 7.75\n",
      "episode: 1711   score: 10.0   memory length: 414649   epsilon: 0.37699300001007624    steps: 508    lr: 6.400000000000001e-06     evaluation reward: 7.8\n",
      "episode: 1712   score: 9.0   memory length: 415007   epsilon: 0.37628416001007176    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 7.82\n",
      "episode: 1713   score: 8.0   memory length: 415449   epsilon: 0.3754090000100662    steps: 442    lr: 6.400000000000001e-06     evaluation reward: 7.85\n",
      "episode: 1714   score: 8.0   memory length: 415864   epsilon: 0.374587300010061    steps: 415    lr: 6.400000000000001e-06     evaluation reward: 7.89\n",
      "episode: 1715   score: 7.0   memory length: 416111   epsilon: 0.3740982400100579    steps: 247    lr: 6.400000000000001e-06     evaluation reward: 7.95\n",
      "episode: 1716   score: 9.0   memory length: 416594   epsilon: 0.3731419000100519    steps: 483    lr: 6.400000000000001e-06     evaluation reward: 8.01\n",
      "episode: 1717   score: 4.0   memory length: 416835   epsilon: 0.37266472001004886    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 7.96\n",
      "episode: 1718   score: 10.0   memory length: 417349   epsilon: 0.3716470000100424    steps: 514    lr: 6.400000000000001e-06     evaluation reward: 7.99\n",
      "episode: 1719   score: 11.0   memory length: 417869   epsilon: 0.3706174000100359    steps: 520    lr: 6.400000000000001e-06     evaluation reward: 8.06\n",
      "episode: 1720   score: 9.0   memory length: 418339   epsilon: 0.36968680001003    steps: 470    lr: 6.400000000000001e-06     evaluation reward: 8.05\n",
      "episode: 1721   score: 6.0   memory length: 418694   epsilon: 0.36898390001002557    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 8.0\n",
      "episode: 1722   score: 7.0   memory length: 419077   epsilon: 0.36822556001002077    steps: 383    lr: 6.400000000000001e-06     evaluation reward: 7.97\n",
      "episode: 1723   score: 9.0   memory length: 419566   epsilon: 0.36725734001001464    steps: 489    lr: 6.400000000000001e-06     evaluation reward: 7.99\n",
      "episode: 1724   score: 7.0   memory length: 419936   epsilon: 0.36652474001001    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 7.85\n",
      "episode: 1725   score: 7.0   memory length: 420308   epsilon: 0.36578818001000535    steps: 372    lr: 6.400000000000001e-06     evaluation reward: 7.86\n",
      "episode: 1726   score: 5.0   memory length: 420614   epsilon: 0.3651823000100015    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 7.82\n",
      "episode: 1727   score: 6.0   memory length: 420943   epsilon: 0.3645308800099974    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 7.79\n",
      "episode: 1728   score: 8.0   memory length: 421382   epsilon: 0.3636616600099919    steps: 439    lr: 6.400000000000001e-06     evaluation reward: 7.84\n",
      "episode: 1729   score: 7.0   memory length: 421730   epsilon: 0.36297262000998753    steps: 348    lr: 6.400000000000001e-06     evaluation reward: 7.83\n",
      "episode: 1730   score: 8.0   memory length: 422161   epsilon: 0.36211924000998214    steps: 431    lr: 6.400000000000001e-06     evaluation reward: 7.87\n",
      "episode: 1731   score: 9.0   memory length: 422609   epsilon: 0.3612322000099765    steps: 448    lr: 6.400000000000001e-06     evaluation reward: 7.84\n",
      "episode: 1732   score: 7.0   memory length: 422984   epsilon: 0.3604897000099718    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 7.86\n",
      "episode: 1733   score: 11.0   memory length: 423497   epsilon: 0.3594739600099654    steps: 513    lr: 6.400000000000001e-06     evaluation reward: 7.93\n",
      "episode: 1734   score: 6.0   memory length: 423834   epsilon: 0.3588067000099612    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 7.9\n",
      "episode: 1735   score: 7.0   memory length: 424241   epsilon: 0.3580008400099561    steps: 407    lr: 6.400000000000001e-06     evaluation reward: 7.89\n",
      "episode: 1736   score: 8.0   memory length: 424640   epsilon: 0.3572108200099511    steps: 399    lr: 6.400000000000001e-06     evaluation reward: 7.85\n",
      "episode: 1737   score: 7.0   memory length: 425010   epsilon: 0.35647822000994644    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 7.88\n",
      "episode: 1738   score: 8.0   memory length: 425411   epsilon: 0.3556842400099414    steps: 401    lr: 6.400000000000001e-06     evaluation reward: 7.91\n",
      "episode: 1739   score: 7.0   memory length: 425819   epsilon: 0.3548764000099363    steps: 408    lr: 6.400000000000001e-06     evaluation reward: 7.92\n",
      "episode: 1740   score: 9.0   memory length: 426302   epsilon: 0.35392006000993026    steps: 483    lr: 6.400000000000001e-06     evaluation reward: 7.92\n",
      "episode: 1741   score: 11.0   memory length: 426818   epsilon: 0.3528983800099238    steps: 516    lr: 6.400000000000001e-06     evaluation reward: 7.96\n",
      "episode: 1742   score: 8.0   memory length: 427260   epsilon: 0.35202322000991826    steps: 442    lr: 6.400000000000001e-06     evaluation reward: 7.94\n",
      "episode: 1743   score: 9.0   memory length: 427712   epsilon: 0.3511282600099126    steps: 452    lr: 6.400000000000001e-06     evaluation reward: 7.91\n",
      "episode: 1744   score: 16.0   memory length: 428362   epsilon: 0.34984126000990445    steps: 650    lr: 6.400000000000001e-06     evaluation reward: 8.01\n",
      "episode: 1745   score: 6.0   memory length: 428727   epsilon: 0.3491185600098999    steps: 365    lr: 6.400000000000001e-06     evaluation reward: 8.02\n",
      "episode: 1746   score: 9.0   memory length: 429197   epsilon: 0.348187960009894    steps: 470    lr: 6.400000000000001e-06     evaluation reward: 8.07\n",
      "episode: 1747   score: 6.0   memory length: 429589   epsilon: 0.3474118000098891    steps: 392    lr: 6.400000000000001e-06     evaluation reward: 7.96\n",
      "episode: 1748   score: 6.0   memory length: 429924   epsilon: 0.3467485000098849    steps: 335    lr: 6.400000000000001e-06     evaluation reward: 7.96\n",
      "episode: 1749   score: 9.0   memory length: 430341   epsilon: 0.34592284000987966    steps: 417    lr: 6.400000000000001e-06     evaluation reward: 8.01\n",
      "episode: 1750   score: 7.0   memory length: 430730   epsilon: 0.3451526200098748    steps: 389    lr: 6.400000000000001e-06     evaluation reward: 8.04\n",
      "episode: 1751   score: 9.0   memory length: 431220   epsilon: 0.34418242000986865    steps: 490    lr: 6.400000000000001e-06     evaluation reward: 8.05\n",
      "episode: 1752   score: 7.0   memory length: 431602   epsilon: 0.34342606000986386    steps: 382    lr: 6.400000000000001e-06     evaluation reward: 8.07\n",
      "episode: 1753   score: 4.0   memory length: 431848   epsilon: 0.3429389800098608    steps: 246    lr: 6.400000000000001e-06     evaluation reward: 8.06\n",
      "episode: 1754   score: 9.0   memory length: 432314   epsilon: 0.34201630000985495    steps: 466    lr: 6.400000000000001e-06     evaluation reward: 8.11\n",
      "episode: 1755   score: 3.0   memory length: 432560   epsilon: 0.34152922000985186    steps: 246    lr: 6.400000000000001e-06     evaluation reward: 8.07\n",
      "episode: 1756   score: 13.0   memory length: 433061   epsilon: 0.3405372400098456    steps: 501    lr: 6.400000000000001e-06     evaluation reward: 8.16\n",
      "episode: 1757   score: 8.0   memory length: 433494   epsilon: 0.33967990000984016    steps: 433    lr: 6.400000000000001e-06     evaluation reward: 8.16\n",
      "episode: 1758   score: 11.0   memory length: 434010   epsilon: 0.3386582200098337    steps: 516    lr: 6.400000000000001e-06     evaluation reward: 8.15\n",
      "episode: 1759   score: 4.0   memory length: 434251   epsilon: 0.3381810400098307    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 8.06\n",
      "episode: 1760   score: 7.0   memory length: 434607   epsilon: 0.3374761600098262    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 8.07\n",
      "episode: 1761   score: 6.0   memory length: 434958   epsilon: 0.3367811800098218    steps: 351    lr: 6.400000000000001e-06     evaluation reward: 8.06\n",
      "episode: 1762   score: 9.0   memory length: 435411   epsilon: 0.33588424000981615    steps: 453    lr: 6.400000000000001e-06     evaluation reward: 8.1\n",
      "episode: 1763   score: 6.0   memory length: 435764   epsilon: 0.3351853000098117    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 8.11\n",
      "episode: 1764   score: 9.0   memory length: 436235   epsilon: 0.3342527200098058    steps: 471    lr: 6.400000000000001e-06     evaluation reward: 8.11\n",
      "episode: 1765   score: 11.0   memory length: 436644   epsilon: 0.3334429000098007    steps: 409    lr: 6.400000000000001e-06     evaluation reward: 8.17\n",
      "episode: 1766   score: 13.0   memory length: 437150   epsilon: 0.33244102000979436    steps: 506    lr: 6.400000000000001e-06     evaluation reward: 8.27\n",
      "episode: 1767   score: 5.0   memory length: 437441   epsilon: 0.3318648400097907    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 8.26\n",
      "episode: 1768   score: 9.0   memory length: 437981   epsilon: 0.33079564000978395    steps: 540    lr: 6.400000000000001e-06     evaluation reward: 8.28\n",
      "episode: 1769   score: 8.0   memory length: 438458   epsilon: 0.329851180009778    steps: 477    lr: 6.400000000000001e-06     evaluation reward: 8.23\n",
      "episode: 1770   score: 4.0   memory length: 438737   epsilon: 0.3292987600097745    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 8.18\n",
      "episode: 1771   score: 7.0   memory length: 439108   epsilon: 0.32856418000976984    steps: 371    lr: 6.400000000000001e-06     evaluation reward: 8.17\n",
      "episode: 1772   score: 5.0   memory length: 439451   epsilon: 0.32788504000976554    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 8.13\n",
      "episode: 1773   score: 11.0   memory length: 439992   epsilon: 0.32681386000975876    steps: 541    lr: 6.400000000000001e-06     evaluation reward: 8.16\n",
      "episode: 1774   score: 9.0   memory length: 440427   epsilon: 0.3259525600097533    steps: 435    lr: 6.400000000000001e-06     evaluation reward: 8.15\n",
      "episode: 1775   score: 5.0   memory length: 440736   epsilon: 0.32534074000974944    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 8.14\n",
      "episode: 1776   score: 6.0   memory length: 441068   epsilon: 0.3246833800097453    steps: 332    lr: 6.400000000000001e-06     evaluation reward: 8.15\n",
      "episode: 1777   score: 8.0   memory length: 441489   epsilon: 0.32384980000974    steps: 421    lr: 6.400000000000001e-06     evaluation reward: 8.13\n",
      "episode: 1778   score: 5.0   memory length: 441796   epsilon: 0.32324194000973616    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 8.12\n",
      "episode: 1779   score: 11.0   memory length: 442179   epsilon: 0.32248360000973136    steps: 383    lr: 6.400000000000001e-06     evaluation reward: 8.16\n",
      "episode: 1780   score: 5.0   memory length: 442474   epsilon: 0.32189950000972767    steps: 295    lr: 6.400000000000001e-06     evaluation reward: 8.13\n",
      "episode: 1781   score: 8.0   memory length: 442909   epsilon: 0.3210382000097222    steps: 435    lr: 6.400000000000001e-06     evaluation reward: 8.05\n",
      "episode: 1782   score: 12.0   memory length: 443399   epsilon: 0.3200680000097161    steps: 490    lr: 6.400000000000001e-06     evaluation reward: 8.11\n",
      "episode: 1783   score: 7.0   memory length: 443769   epsilon: 0.31933540000971145    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 8.12\n",
      "episode: 1784   score: 8.0   memory length: 444048   epsilon: 0.31878298000970795    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 8.11\n",
      "episode: 1785   score: 8.0   memory length: 444467   epsilon: 0.3179533600097027    steps: 419    lr: 6.400000000000001e-06     evaluation reward: 8.1\n",
      "episode: 1786   score: 7.0   memory length: 444860   epsilon: 0.3171752200096978    steps: 393    lr: 6.400000000000001e-06     evaluation reward: 8.08\n",
      "episode: 1787   score: 10.0   memory length: 445319   epsilon: 0.31626640000969203    steps: 459    lr: 6.400000000000001e-06     evaluation reward: 8.09\n",
      "episode: 1788   score: 12.0   memory length: 445872   epsilon: 0.3151714600096851    steps: 553    lr: 6.400000000000001e-06     evaluation reward: 8.08\n",
      "episode: 1789   score: 10.0   memory length: 446360   epsilon: 0.314205220009679    steps: 488    lr: 6.400000000000001e-06     evaluation reward: 8.12\n",
      "episode: 1790   score: 4.0   memory length: 446622   epsilon: 0.3136864600096757    steps: 262    lr: 6.400000000000001e-06     evaluation reward: 8.11\n",
      "episode: 1791   score: 6.0   memory length: 446981   epsilon: 0.3129756400096712    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 8.04\n",
      "episode: 1792   score: 9.0   memory length: 447472   epsilon: 0.31200346000966506    steps: 491    lr: 6.400000000000001e-06     evaluation reward: 8.06\n",
      "episode: 1793   score: 8.0   memory length: 447904   epsilon: 0.31114810000965964    steps: 432    lr: 6.400000000000001e-06     evaluation reward: 8.0\n",
      "episode: 1794   score: 4.0   memory length: 448204   epsilon: 0.3105541000096559    steps: 300    lr: 6.400000000000001e-06     evaluation reward: 7.85\n",
      "episode: 1795   score: 14.0   memory length: 448830   epsilon: 0.30931462000964804    steps: 626    lr: 6.400000000000001e-06     evaluation reward: 7.89\n",
      "episode: 1796   score: 4.0   memory length: 449073   epsilon: 0.308833480009645    steps: 243    lr: 6.400000000000001e-06     evaluation reward: 7.83\n",
      "episode: 1797   score: 9.0   memory length: 449511   epsilon: 0.3079662400096395    steps: 438    lr: 6.400000000000001e-06     evaluation reward: 7.86\n",
      "episode: 1798   score: 11.0   memory length: 450065   epsilon: 0.3068693200096326    steps: 554    lr: 6.400000000000001e-06     evaluation reward: 7.92\n",
      "episode: 1799   score: 7.0   memory length: 450463   epsilon: 0.3060812800096276    steps: 398    lr: 6.400000000000001e-06     evaluation reward: 7.89\n",
      "episode: 1800   score: 5.0   memory length: 450755   epsilon: 0.30550312000962393    steps: 292    lr: 6.400000000000001e-06     evaluation reward: 7.85\n",
      "episode: 1801   score: 8.0   memory length: 451226   epsilon: 0.30457054000961803    steps: 471    lr: 6.400000000000001e-06     evaluation reward: 7.89\n",
      "episode: 1802   score: 17.0   memory length: 451714   epsilon: 0.3036043000096119    steps: 488    lr: 6.400000000000001e-06     evaluation reward: 7.98\n",
      "episode: 1803   score: 6.0   memory length: 452034   epsilon: 0.3029707000096079    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 7.95\n",
      "episode: 1804   score: 9.0   memory length: 452487   epsilon: 0.30207376000960223    steps: 453    lr: 6.400000000000001e-06     evaluation reward: 7.93\n",
      "episode: 1805   score: 5.0   memory length: 452800   epsilon: 0.3014540200095983    steps: 313    lr: 6.400000000000001e-06     evaluation reward: 7.91\n",
      "episode: 1806   score: 5.0   memory length: 453125   epsilon: 0.30081052000959424    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 7.89\n",
      "episode: 1807   score: 10.0   memory length: 453569   epsilon: 0.2999314000095887    steps: 444    lr: 6.400000000000001e-06     evaluation reward: 7.92\n",
      "episode: 1808   score: 5.0   memory length: 453873   epsilon: 0.29932948000958487    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 7.86\n",
      "episode: 1809   score: 5.0   memory length: 454198   epsilon: 0.2986859800095808    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 7.89\n",
      "episode: 1810   score: 7.0   memory length: 454620   epsilon: 0.2978504200095755    steps: 422    lr: 6.400000000000001e-06     evaluation reward: 7.88\n",
      "episode: 1811   score: 9.0   memory length: 455107   epsilon: 0.2968861600095694    steps: 487    lr: 6.400000000000001e-06     evaluation reward: 7.87\n",
      "episode: 1812   score: 5.0   memory length: 455414   epsilon: 0.29627830000956556    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 7.83\n",
      "episode: 1813   score: 11.0   memory length: 455842   epsilon: 0.2954308600095602    steps: 428    lr: 6.400000000000001e-06     evaluation reward: 7.86\n",
      "episode: 1814   score: 6.0   memory length: 456214   epsilon: 0.29469430000955554    steps: 372    lr: 6.400000000000001e-06     evaluation reward: 7.84\n",
      "episode: 1815   score: 8.0   memory length: 456647   epsilon: 0.2938369600095501    steps: 433    lr: 6.400000000000001e-06     evaluation reward: 7.85\n",
      "episode: 1816   score: 6.0   memory length: 456970   epsilon: 0.2931974200095461    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 7.82\n",
      "episode: 1817   score: 7.0   memory length: 457390   epsilon: 0.2923658200095408    steps: 420    lr: 6.400000000000001e-06     evaluation reward: 7.85\n",
      "episode: 1818   score: 11.0   memory length: 457919   epsilon: 0.2913184000095342    steps: 529    lr: 6.400000000000001e-06     evaluation reward: 7.86\n",
      "episode: 1819   score: 9.0   memory length: 458373   epsilon: 0.2904194800095285    steps: 454    lr: 6.400000000000001e-06     evaluation reward: 7.84\n",
      "episode: 1820   score: 9.0   memory length: 458843   epsilon: 0.2894888800095226    steps: 470    lr: 6.400000000000001e-06     evaluation reward: 7.84\n",
      "episode: 1821   score: 15.0   memory length: 459438   epsilon: 0.28831078000951516    steps: 595    lr: 6.400000000000001e-06     evaluation reward: 7.93\n",
      "episode: 1822   score: 12.0   memory length: 459997   epsilon: 0.28720396000950815    steps: 559    lr: 6.400000000000001e-06     evaluation reward: 7.98\n",
      "episode: 1823   score: 5.0   memory length: 460302   epsilon: 0.28660006000950433    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 7.94\n",
      "episode: 1824   score: 9.0   memory length: 460734   epsilon: 0.2857447000094989    steps: 432    lr: 6.400000000000001e-06     evaluation reward: 7.96\n",
      "episode: 1825   score: 5.0   memory length: 461007   epsilon: 0.2852041600094955    steps: 273    lr: 6.400000000000001e-06     evaluation reward: 7.94\n",
      "episode: 1826   score: 8.0   memory length: 461442   epsilon: 0.28434286000949005    steps: 435    lr: 6.400000000000001e-06     evaluation reward: 7.97\n",
      "episode: 1827   score: 7.0   memory length: 461826   epsilon: 0.28358254000948524    steps: 384    lr: 6.400000000000001e-06     evaluation reward: 7.98\n",
      "episode: 1828   score: 9.0   memory length: 462295   epsilon: 0.28265392000947936    steps: 469    lr: 6.400000000000001e-06     evaluation reward: 7.99\n",
      "episode: 1829   score: 10.0   memory length: 462808   epsilon: 0.28163818000947294    steps: 513    lr: 6.400000000000001e-06     evaluation reward: 8.02\n",
      "episode: 1830   score: 9.0   memory length: 463223   epsilon: 0.28081648000946774    steps: 415    lr: 6.400000000000001e-06     evaluation reward: 8.03\n",
      "episode: 1831   score: 8.0   memory length: 463677   epsilon: 0.27991756000946205    steps: 454    lr: 6.400000000000001e-06     evaluation reward: 8.02\n",
      "episode: 1832   score: 5.0   memory length: 463986   epsilon: 0.2793057400094582    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 8.0\n",
      "episode: 1833   score: 12.0   memory length: 464537   epsilon: 0.2782147600094513    steps: 551    lr: 6.400000000000001e-06     evaluation reward: 8.01\n",
      "episode: 1834   score: 4.0   memory length: 464839   epsilon: 0.2776168000094475    steps: 302    lr: 6.400000000000001e-06     evaluation reward: 7.99\n",
      "episode: 1835   score: 7.0   memory length: 465222   epsilon: 0.2768584600094427    steps: 383    lr: 6.400000000000001e-06     evaluation reward: 7.99\n",
      "episode: 1836   score: 15.0   memory length: 465762   epsilon: 0.27578926000943593    steps: 540    lr: 6.400000000000001e-06     evaluation reward: 8.06\n",
      "episode: 1837   score: 7.0   memory length: 466144   epsilon: 0.27503290000943115    steps: 382    lr: 6.400000000000001e-06     evaluation reward: 8.06\n",
      "episode: 1838   score: 11.0   memory length: 466635   epsilon: 0.274060720009425    steps: 491    lr: 6.400000000000001e-06     evaluation reward: 8.09\n",
      "episode: 1839   score: 3.0   memory length: 466844   epsilon: 0.2736469000094224    steps: 209    lr: 6.400000000000001e-06     evaluation reward: 8.05\n",
      "episode: 1840   score: 9.0   memory length: 467298   epsilon: 0.2727479800094167    steps: 454    lr: 6.400000000000001e-06     evaluation reward: 8.05\n",
      "episode: 1841   score: 6.0   memory length: 467650   epsilon: 0.2720510200094123    steps: 352    lr: 6.400000000000001e-06     evaluation reward: 8.0\n",
      "episode: 1842   score: 4.0   memory length: 467908   epsilon: 0.27154018000940905    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 7.96\n",
      "episode: 1843   score: 6.0   memory length: 468260   epsilon: 0.27084322000940464    steps: 352    lr: 6.400000000000001e-06     evaluation reward: 7.93\n",
      "episode: 1844   score: 10.0   memory length: 468744   epsilon: 0.2698849000093986    steps: 484    lr: 6.400000000000001e-06     evaluation reward: 7.87\n",
      "episode: 1845   score: 15.0   memory length: 469436   epsilon: 0.2685147400093899    steps: 692    lr: 6.400000000000001e-06     evaluation reward: 7.96\n",
      "episode: 1846   score: 10.0   memory length: 469960   epsilon: 0.26747722000938334    steps: 524    lr: 6.400000000000001e-06     evaluation reward: 7.97\n",
      "episode: 1847   score: 10.0   memory length: 470497   epsilon: 0.2664139600093766    steps: 537    lr: 6.400000000000001e-06     evaluation reward: 8.01\n",
      "episode: 1848   score: 9.0   memory length: 470940   epsilon: 0.26553682000937107    steps: 443    lr: 6.400000000000001e-06     evaluation reward: 8.04\n",
      "episode: 1849   score: 8.0   memory length: 471376   epsilon: 0.2646735400093656    steps: 436    lr: 6.400000000000001e-06     evaluation reward: 8.03\n",
      "episode: 1850   score: 4.0   memory length: 471618   epsilon: 0.2641943800093626    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 8.0\n",
      "episode: 1851   score: 19.0   memory length: 472196   epsilon: 0.26304994000935533    steps: 578    lr: 6.400000000000001e-06     evaluation reward: 8.1\n",
      "episode: 1852   score: 9.0   memory length: 472720   epsilon: 0.26201242000934877    steps: 524    lr: 6.400000000000001e-06     evaluation reward: 8.12\n",
      "episode: 1853   score: 11.0   memory length: 473237   epsilon: 0.2609887600093423    steps: 517    lr: 6.400000000000001e-06     evaluation reward: 8.19\n",
      "episode: 1854   score: 6.0   memory length: 473614   epsilon: 0.26024230000933757    steps: 377    lr: 6.400000000000001e-06     evaluation reward: 8.16\n",
      "episode: 1855   score: 8.0   memory length: 474038   epsilon: 0.25940278000933226    steps: 424    lr: 6.400000000000001e-06     evaluation reward: 8.21\n",
      "episode: 1856   score: 7.0   memory length: 474388   epsilon: 0.25870978000932787    steps: 350    lr: 6.400000000000001e-06     evaluation reward: 8.15\n",
      "episode: 1857   score: 6.0   memory length: 474725   epsilon: 0.25804252000932365    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 8.13\n",
      "episode: 1858   score: 5.0   memory length: 475049   epsilon: 0.2574010000093196    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 8.07\n",
      "episode: 1859   score: 8.0   memory length: 475443   epsilon: 0.25662088000931466    steps: 394    lr: 6.400000000000001e-06     evaluation reward: 8.11\n",
      "episode: 1860   score: 9.0   memory length: 475946   epsilon: 0.25562494000930835    steps: 503    lr: 6.400000000000001e-06     evaluation reward: 8.13\n",
      "episode: 1861   score: 7.0   memory length: 476349   epsilon: 0.2548270000093033    steps: 403    lr: 6.400000000000001e-06     evaluation reward: 8.14\n",
      "episode: 1862   score: 7.0   memory length: 476774   epsilon: 0.253985500009298    steps: 425    lr: 6.400000000000001e-06     evaluation reward: 8.12\n",
      "episode: 1863   score: 11.0   memory length: 477303   epsilon: 0.25293808000929136    steps: 529    lr: 6.400000000000001e-06     evaluation reward: 8.17\n",
      "episode: 1864   score: 11.0   memory length: 477812   epsilon: 0.251930260009285    steps: 509    lr: 6.400000000000001e-06     evaluation reward: 8.19\n",
      "episode: 1865   score: 12.0   memory length: 478300   epsilon: 0.25096402000927887    steps: 488    lr: 6.400000000000001e-06     evaluation reward: 8.2\n",
      "episode: 1866   score: 12.0   memory length: 478894   epsilon: 0.24978790000927142    steps: 594    lr: 6.400000000000001e-06     evaluation reward: 8.19\n",
      "episode: 1867   score: 8.0   memory length: 479345   epsilon: 0.24889492000926577    steps: 451    lr: 6.400000000000001e-06     evaluation reward: 8.22\n",
      "episode: 1868   score: 9.0   memory length: 479844   epsilon: 0.24790690000925952    steps: 499    lr: 6.400000000000001e-06     evaluation reward: 8.22\n",
      "episode: 1869   score: 15.0   memory length: 480383   epsilon: 0.24683968000925277    steps: 539    lr: 6.400000000000001e-06     evaluation reward: 8.29\n",
      "episode: 1870   score: 5.0   memory length: 480729   epsilon: 0.24615460000924844    steps: 346    lr: 6.400000000000001e-06     evaluation reward: 8.3\n",
      "episode: 1871   score: 8.0   memory length: 481117   epsilon: 0.24538636000924358    steps: 388    lr: 6.400000000000001e-06     evaluation reward: 8.31\n",
      "episode: 1872   score: 8.0   memory length: 481549   epsilon: 0.24453100000923816    steps: 432    lr: 6.400000000000001e-06     evaluation reward: 8.34\n",
      "episode: 1873   score: 9.0   memory length: 482015   epsilon: 0.24360832000923233    steps: 466    lr: 6.400000000000001e-06     evaluation reward: 8.32\n",
      "episode: 1874   score: 11.0   memory length: 482479   epsilon: 0.2426896000092265    steps: 464    lr: 6.400000000000001e-06     evaluation reward: 8.34\n",
      "episode: 1875   score: 8.0   memory length: 482888   epsilon: 0.2418797800092214    steps: 409    lr: 6.400000000000001e-06     evaluation reward: 8.37\n",
      "episode: 1876   score: 12.0   memory length: 483510   epsilon: 0.2406482200092136    steps: 622    lr: 6.400000000000001e-06     evaluation reward: 8.43\n",
      "episode: 1877   score: 11.0   memory length: 483895   epsilon: 0.23988592000920878    steps: 385    lr: 6.400000000000001e-06     evaluation reward: 8.46\n",
      "episode: 1878   score: 10.0   memory length: 484416   epsilon: 0.23885434000920225    steps: 521    lr: 6.400000000000001e-06     evaluation reward: 8.51\n",
      "episode: 1879   score: 15.0   memory length: 484989   epsilon: 0.23771980000919507    steps: 573    lr: 6.400000000000001e-06     evaluation reward: 8.55\n",
      "episode: 1880   score: 9.0   memory length: 485445   epsilon: 0.23681692000918936    steps: 456    lr: 6.400000000000001e-06     evaluation reward: 8.59\n",
      "episode: 1881   score: 9.0   memory length: 485864   epsilon: 0.2359873000091841    steps: 419    lr: 6.400000000000001e-06     evaluation reward: 8.6\n",
      "episode: 1882   score: 5.0   memory length: 486184   epsilon: 0.2353537000091801    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 8.53\n",
      "episode: 1883   score: 7.0   memory length: 486565   epsilon: 0.23459932000917533    steps: 381    lr: 6.400000000000001e-06     evaluation reward: 8.53\n",
      "episode: 1884   score: 16.0   memory length: 487154   epsilon: 0.23343310000916795    steps: 589    lr: 6.400000000000001e-06     evaluation reward: 8.61\n",
      "episode: 1885   score: 9.0   memory length: 487629   epsilon: 0.232492600009162    steps: 475    lr: 6.400000000000001e-06     evaluation reward: 8.62\n",
      "episode: 1886   score: 9.0   memory length: 487975   epsilon: 0.23180752000915766    steps: 346    lr: 6.400000000000001e-06     evaluation reward: 8.64\n",
      "episode: 1887   score: 7.0   memory length: 488398   epsilon: 0.23096998000915236    steps: 423    lr: 6.400000000000001e-06     evaluation reward: 8.61\n",
      "episode: 1888   score: 13.0   memory length: 489009   epsilon: 0.2297602000091447    steps: 611    lr: 6.400000000000001e-06     evaluation reward: 8.62\n",
      "episode: 1889   score: 15.0   memory length: 489574   epsilon: 0.22864150000913763    steps: 565    lr: 6.400000000000001e-06     evaluation reward: 8.67\n",
      "episode: 1890   score: 5.0   memory length: 489863   epsilon: 0.228069280009134    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 8.68\n",
      "episode: 1891   score: 6.0   memory length: 490233   epsilon: 0.22733668000912938    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 8.68\n",
      "episode: 1892   score: 14.0   memory length: 490772   epsilon: 0.22626946000912262    steps: 539    lr: 6.400000000000001e-06     evaluation reward: 8.73\n",
      "episode: 1893   score: 10.0   memory length: 491310   epsilon: 0.22520422000911589    steps: 538    lr: 6.400000000000001e-06     evaluation reward: 8.75\n",
      "episode: 1894   score: 7.0   memory length: 491686   epsilon: 0.22445974000911117    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 8.78\n",
      "episode: 1895   score: 8.0   memory length: 492089   epsilon: 0.22366180000910613    steps: 403    lr: 6.400000000000001e-06     evaluation reward: 8.72\n",
      "episode: 1896   score: 4.0   memory length: 492329   epsilon: 0.22318660000910312    steps: 240    lr: 6.400000000000001e-06     evaluation reward: 8.72\n",
      "episode: 1897   score: 20.0   memory length: 492956   epsilon: 0.22194514000909527    steps: 627    lr: 6.400000000000001e-06     evaluation reward: 8.83\n",
      "episode: 1898   score: 13.0   memory length: 493560   epsilon: 0.2207492200090877    steps: 604    lr: 6.400000000000001e-06     evaluation reward: 8.85\n",
      "episode: 1899   score: 10.0   memory length: 494069   epsilon: 0.21974140000908132    steps: 509    lr: 6.400000000000001e-06     evaluation reward: 8.88\n",
      "episode: 1900   score: 10.0   memory length: 494485   epsilon: 0.2189177200090761    steps: 416    lr: 6.400000000000001e-06     evaluation reward: 8.93\n",
      "episode: 1901   score: 9.0   memory length: 494971   epsilon: 0.21795544000907002    steps: 486    lr: 6.400000000000001e-06     evaluation reward: 8.94\n",
      "episode: 1902   score: 5.0   memory length: 495257   epsilon: 0.21738916000906644    steps: 286    lr: 6.400000000000001e-06     evaluation reward: 8.82\n",
      "episode: 1903   score: 4.0   memory length: 495500   epsilon: 0.2169080200090634    steps: 243    lr: 6.400000000000001e-06     evaluation reward: 8.8\n",
      "episode: 1904   score: 12.0   memory length: 496062   epsilon: 0.21579526000905636    steps: 562    lr: 6.400000000000001e-06     evaluation reward: 8.83\n",
      "episode: 1905   score: 14.0   memory length: 496709   epsilon: 0.21451420000904825    steps: 647    lr: 6.400000000000001e-06     evaluation reward: 8.92\n",
      "episode: 1906   score: 13.0   memory length: 497197   epsilon: 0.21354796000904214    steps: 488    lr: 6.400000000000001e-06     evaluation reward: 9.0\n",
      "episode: 1907   score: 10.0   memory length: 497588   epsilon: 0.21277378000903724    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 9.0\n",
      "episode: 1908   score: 13.0   memory length: 498097   epsilon: 0.21176596000903086    steps: 509    lr: 6.400000000000001e-06     evaluation reward: 9.08\n",
      "episode: 1909   score: 9.0   memory length: 498612   epsilon: 0.2107462600090244    steps: 515    lr: 6.400000000000001e-06     evaluation reward: 9.12\n",
      "episode: 1910   score: 7.0   memory length: 499035   epsilon: 0.2099087200090191    steps: 423    lr: 6.400000000000001e-06     evaluation reward: 9.12\n",
      "episode: 1911   score: 9.0   memory length: 499515   epsilon: 0.2089583200090131    steps: 480    lr: 6.400000000000001e-06     evaluation reward: 9.12\n",
      "episode: 1912   score: 5.0   memory length: 499818   epsilon: 0.2083583800090093    steps: 303    lr: 6.400000000000001e-06     evaluation reward: 9.12\n",
      "episode: 1913   score: 8.0   memory length: 500207   epsilon: 0.20758816000900443    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 9.09\n",
      "episode: 1914   score: 10.0   memory length: 500685   epsilon: 0.20664172000899844    steps: 478    lr: 2.560000000000001e-06     evaluation reward: 9.13\n",
      "episode: 1915   score: 9.0   memory length: 501139   epsilon: 0.20574280000899275    steps: 454    lr: 2.560000000000001e-06     evaluation reward: 9.14\n",
      "episode: 1916   score: 11.0   memory length: 501671   epsilon: 0.2046894400089861    steps: 532    lr: 2.560000000000001e-06     evaluation reward: 9.19\n",
      "episode: 1917   score: 11.0   memory length: 502230   epsilon: 0.2035826200089791    steps: 559    lr: 2.560000000000001e-06     evaluation reward: 9.23\n",
      "episode: 1918   score: 15.0   memory length: 502801   epsilon: 0.20245204000897193    steps: 571    lr: 2.560000000000001e-06     evaluation reward: 9.27\n",
      "episode: 1919   score: 10.0   memory length: 503286   epsilon: 0.20149174000896586    steps: 485    lr: 2.560000000000001e-06     evaluation reward: 9.28\n",
      "episode: 1920   score: 10.0   memory length: 503765   epsilon: 0.20054332000895986    steps: 479    lr: 2.560000000000001e-06     evaluation reward: 9.29\n",
      "episode: 1921   score: 14.0   memory length: 504285   epsilon: 0.19951372000895334    steps: 520    lr: 2.560000000000001e-06     evaluation reward: 9.28\n",
      "episode: 1922   score: 11.0   memory length: 504830   epsilon: 0.19843462000894652    steps: 545    lr: 2.560000000000001e-06     evaluation reward: 9.27\n",
      "episode: 1923   score: 9.0   memory length: 505285   epsilon: 0.19753372000894082    steps: 455    lr: 2.560000000000001e-06     evaluation reward: 9.31\n",
      "episode: 1924   score: 8.0   memory length: 505690   epsilon: 0.19673182000893574    steps: 405    lr: 2.560000000000001e-06     evaluation reward: 9.3\n",
      "episode: 1925   score: 8.0   memory length: 506099   epsilon: 0.19592200000893062    steps: 409    lr: 2.560000000000001e-06     evaluation reward: 9.33\n",
      "episode: 1926   score: 14.0   memory length: 506701   epsilon: 0.19473004000892308    steps: 602    lr: 2.560000000000001e-06     evaluation reward: 9.39\n",
      "episode: 1927   score: 7.0   memory length: 507087   epsilon: 0.19396576000891824    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 9.39\n",
      "episode: 1928   score: 11.0   memory length: 507579   epsilon: 0.19299160000891208    steps: 492    lr: 2.560000000000001e-06     evaluation reward: 9.41\n",
      "episode: 1929   score: 13.0   memory length: 508220   epsilon: 0.19172242000890405    steps: 641    lr: 2.560000000000001e-06     evaluation reward: 9.44\n",
      "episode: 1930   score: 9.0   memory length: 508691   epsilon: 0.19078984000889815    steps: 471    lr: 2.560000000000001e-06     evaluation reward: 9.44\n",
      "episode: 1931   score: 5.0   memory length: 508993   epsilon: 0.19019188000889437    steps: 302    lr: 2.560000000000001e-06     evaluation reward: 9.41\n",
      "episode: 1932   score: 5.0   memory length: 509317   epsilon: 0.1895503600088903    steps: 324    lr: 2.560000000000001e-06     evaluation reward: 9.41\n",
      "episode: 1933   score: 8.0   memory length: 509729   epsilon: 0.18873460000888514    steps: 412    lr: 2.560000000000001e-06     evaluation reward: 9.37\n",
      "episode: 1934   score: 9.0   memory length: 510183   epsilon: 0.18783568000887946    steps: 454    lr: 2.560000000000001e-06     evaluation reward: 9.42\n",
      "episode: 1935   score: 11.0   memory length: 510721   epsilon: 0.18677044000887272    steps: 538    lr: 2.560000000000001e-06     evaluation reward: 9.46\n",
      "episode: 1936   score: 6.0   memory length: 511079   epsilon: 0.18606160000886823    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 9.37\n",
      "episode: 1937   score: 14.0   memory length: 511647   epsilon: 0.18493696000886112    steps: 568    lr: 2.560000000000001e-06     evaluation reward: 9.44\n",
      "episode: 1938   score: 7.0   memory length: 512030   epsilon: 0.18417862000885632    steps: 383    lr: 2.560000000000001e-06     evaluation reward: 9.4\n",
      "episode: 1939   score: 10.0   memory length: 512534   epsilon: 0.18318070000885    steps: 504    lr: 2.560000000000001e-06     evaluation reward: 9.47\n",
      "episode: 1940   score: 9.0   memory length: 512973   epsilon: 0.1823114800088445    steps: 439    lr: 2.560000000000001e-06     evaluation reward: 9.47\n",
      "episode: 1941   score: 5.0   memory length: 513298   epsilon: 0.18166798000884044    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 9.46\n",
      "episode: 1942   score: 8.0   memory length: 513727   epsilon: 0.18081856000883506    steps: 429    lr: 2.560000000000001e-06     evaluation reward: 9.5\n",
      "episode: 1943   score: 7.0   memory length: 514114   epsilon: 0.1800523000088302    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 9.51\n",
      "episode: 1944   score: 6.0   memory length: 514436   epsilon: 0.17941474000882618    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 9.47\n",
      "episode: 1945   score: 6.0   memory length: 514792   epsilon: 0.17870986000882172    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 9.38\n",
      "episode: 1946   score: 15.0   memory length: 515356   epsilon: 0.17759314000881465    steps: 564    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 1947   score: 11.0   memory length: 515926   epsilon: 0.1764645400088075    steps: 570    lr: 2.560000000000001e-06     evaluation reward: 9.44\n",
      "episode: 1948   score: 8.0   memory length: 516358   epsilon: 0.1756091800088021    steps: 432    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 1949   score: 7.0   memory length: 516740   epsilon: 0.17485282000879732    steps: 382    lr: 2.560000000000001e-06     evaluation reward: 9.42\n",
      "episode: 1950   score: 12.0   memory length: 517326   epsilon: 0.17369254000878998    steps: 586    lr: 2.560000000000001e-06     evaluation reward: 9.5\n",
      "episode: 1951   score: 12.0   memory length: 517920   epsilon: 0.17251642000878253    steps: 594    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 1952   score: 8.0   memory length: 518376   epsilon: 0.17161354000877682    steps: 456    lr: 2.560000000000001e-06     evaluation reward: 9.42\n",
      "episode: 1953   score: 11.0   memory length: 518944   epsilon: 0.1704889000087697    steps: 568    lr: 2.560000000000001e-06     evaluation reward: 9.42\n",
      "episode: 1954   score: 6.0   memory length: 519282   epsilon: 0.16981966000876547    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 9.42\n",
      "episode: 1955   score: 7.0   memory length: 519663   epsilon: 0.1690652800087607    steps: 381    lr: 2.560000000000001e-06     evaluation reward: 9.41\n",
      "episode: 1956   score: 13.0   memory length: 520114   epsilon: 0.16817230000875505    steps: 451    lr: 2.560000000000001e-06     evaluation reward: 9.47\n",
      "episode: 1957   score: 5.0   memory length: 520425   epsilon: 0.16755652000875115    steps: 311    lr: 2.560000000000001e-06     evaluation reward: 9.46\n",
      "episode: 1958   score: 10.0   memory length: 520878   epsilon: 0.16665958000874548    steps: 453    lr: 2.560000000000001e-06     evaluation reward: 9.51\n",
      "episode: 1959   score: 7.0   memory length: 521251   epsilon: 0.1659210400087408    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 9.5\n",
      "episode: 1960   score: 9.0   memory length: 521714   epsilon: 0.165004300008735    steps: 463    lr: 2.560000000000001e-06     evaluation reward: 9.5\n",
      "episode: 1961   score: 8.0   memory length: 522117   epsilon: 0.16420636000872996    steps: 403    lr: 2.560000000000001e-06     evaluation reward: 9.51\n",
      "episode: 1962   score: 22.0   memory length: 522803   epsilon: 0.16284808000872136    steps: 686    lr: 2.560000000000001e-06     evaluation reward: 9.66\n",
      "episode: 1963   score: 11.0   memory length: 523338   epsilon: 0.16178878000871466    steps: 535    lr: 2.560000000000001e-06     evaluation reward: 9.66\n",
      "episode: 1964   score: 5.0   memory length: 523650   epsilon: 0.16117102000871075    steps: 312    lr: 2.560000000000001e-06     evaluation reward: 9.6\n",
      "episode: 1965   score: 10.0   memory length: 524126   epsilon: 0.1602285400087048    steps: 476    lr: 2.560000000000001e-06     evaluation reward: 9.58\n",
      "episode: 1966   score: 7.0   memory length: 524511   epsilon: 0.15946624000869997    steps: 385    lr: 2.560000000000001e-06     evaluation reward: 9.53\n",
      "episode: 1967   score: 10.0   memory length: 524995   epsilon: 0.1585079200086939    steps: 484    lr: 2.560000000000001e-06     evaluation reward: 9.55\n",
      "episode: 1968   score: 4.0   memory length: 525268   epsilon: 0.15796738000869048    steps: 273    lr: 2.560000000000001e-06     evaluation reward: 9.5\n",
      "episode: 1969   score: 8.0   memory length: 525705   epsilon: 0.157102120008685    steps: 437    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 1970   score: 9.0   memory length: 526227   epsilon: 0.15606856000867847    steps: 522    lr: 2.560000000000001e-06     evaluation reward: 9.47\n",
      "episode: 1971   score: 9.0   memory length: 526665   epsilon: 0.15520132000867298    steps: 438    lr: 2.560000000000001e-06     evaluation reward: 9.48\n",
      "episode: 1972   score: 8.0   memory length: 527113   epsilon: 0.15431428000866737    steps: 448    lr: 2.560000000000001e-06     evaluation reward: 9.48\n",
      "episode: 1973   score: 4.0   memory length: 527390   epsilon: 0.1537658200086639    steps: 277    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 1974   score: 10.0   memory length: 527852   epsilon: 0.1528510600086581    steps: 462    lr: 2.560000000000001e-06     evaluation reward: 9.42\n",
      "episode: 1975   score: 8.0   memory length: 528233   epsilon: 0.15209668000865334    steps: 381    lr: 2.560000000000001e-06     evaluation reward: 9.42\n",
      "episode: 1976   score: 10.0   memory length: 528727   epsilon: 0.15111856000864715    steps: 494    lr: 2.560000000000001e-06     evaluation reward: 9.4\n",
      "episode: 1977   score: 8.0   memory length: 529102   epsilon: 0.15037606000864245    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 9.37\n",
      "episode: 1978   score: 15.0   memory length: 529765   epsilon: 0.14906332000863415    steps: 663    lr: 2.560000000000001e-06     evaluation reward: 9.42\n",
      "episode: 1979   score: 16.0   memory length: 530375   epsilon: 0.1478555200086265    steps: 610    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 1980   score: 9.0   memory length: 530860   epsilon: 0.14689522000862043    steps: 485    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 1981   score: 10.0   memory length: 531374   epsilon: 0.145877500008614    steps: 514    lr: 2.560000000000001e-06     evaluation reward: 9.44\n",
      "episode: 1982   score: 14.0   memory length: 531908   epsilon: 0.1448201800086073    steps: 534    lr: 2.560000000000001e-06     evaluation reward: 9.53\n",
      "episode: 1983   score: 9.0   memory length: 532372   epsilon: 0.1439014600086015    steps: 464    lr: 2.560000000000001e-06     evaluation reward: 9.55\n",
      "episode: 1984   score: 15.0   memory length: 532965   epsilon: 0.14272732000859406    steps: 593    lr: 2.560000000000001e-06     evaluation reward: 9.54\n",
      "episode: 1985   score: 5.0   memory length: 533256   epsilon: 0.14215114000859042    steps: 291    lr: 2.560000000000001e-06     evaluation reward: 9.5\n",
      "episode: 1986   score: 8.0   memory length: 533708   epsilon: 0.14125618000858475    steps: 452    lr: 2.560000000000001e-06     evaluation reward: 9.49\n",
      "episode: 1987   score: 8.0   memory length: 534139   epsilon: 0.14040280000857935    steps: 431    lr: 2.560000000000001e-06     evaluation reward: 9.5\n",
      "episode: 1988   score: 8.0   memory length: 534566   epsilon: 0.139557340008574    steps: 427    lr: 2.560000000000001e-06     evaluation reward: 9.45\n",
      "episode: 1989   score: 6.0   memory length: 534919   epsilon: 0.13885840000856958    steps: 353    lr: 2.560000000000001e-06     evaluation reward: 9.36\n",
      "episode: 1990   score: 11.0   memory length: 535478   epsilon: 0.13775158000856258    steps: 559    lr: 2.560000000000001e-06     evaluation reward: 9.42\n",
      "episode: 1991   score: 7.0   memory length: 535879   epsilon: 0.13695760000855756    steps: 401    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 1992   score: 6.0   memory length: 536249   epsilon: 0.13622500000855292    steps: 370    lr: 2.560000000000001e-06     evaluation reward: 9.35\n",
      "episode: 1993   score: 17.0   memory length: 536986   epsilon: 0.1347657400085437    steps: 737    lr: 2.560000000000001e-06     evaluation reward: 9.42\n",
      "episode: 1994   score: 6.0   memory length: 537359   epsilon: 0.13402720000853902    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 9.41\n",
      "episode: 1995   score: 10.0   memory length: 537820   epsilon: 0.13311442000853324    steps: 461    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 1996   score: 8.0   memory length: 538228   epsilon: 0.13230658000852813    steps: 408    lr: 2.560000000000001e-06     evaluation reward: 9.47\n",
      "episode: 1997   score: 7.0   memory length: 538611   epsilon: 0.13154824000852333    steps: 383    lr: 2.560000000000001e-06     evaluation reward: 9.34\n",
      "episode: 1998   score: 11.0   memory length: 539120   epsilon: 0.13054042000851696    steps: 509    lr: 2.560000000000001e-06     evaluation reward: 9.32\n",
      "episode: 1999   score: 12.0   memory length: 539590   epsilon: 0.12960982000851107    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 9.34\n",
      "episode: 2000   score: 15.0   memory length: 540161   epsilon: 0.12847924000850391    steps: 571    lr: 2.560000000000001e-06     evaluation reward: 9.39\n",
      "episode: 2001   score: 11.0   memory length: 540715   epsilon: 0.12738232000849697    steps: 554    lr: 2.560000000000001e-06     evaluation reward: 9.41\n",
      "episode: 2002   score: 7.0   memory length: 541139   epsilon: 0.12654280000849166    steps: 424    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 2003   score: 10.0   memory length: 541636   epsilon: 0.12555874000848544    steps: 497    lr: 2.560000000000001e-06     evaluation reward: 9.49\n",
      "episode: 2004   score: 16.0   memory length: 542366   epsilon: 0.12411334000848251    steps: 730    lr: 2.560000000000001e-06     evaluation reward: 9.53\n",
      "episode: 2005   score: 11.0   memory length: 542904   epsilon: 0.12304810000848324    steps: 538    lr: 2.560000000000001e-06     evaluation reward: 9.5\n",
      "episode: 2006   score: 6.0   memory length: 543277   epsilon: 0.12230956000848374    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 2007   score: 12.0   memory length: 543818   epsilon: 0.12123838000848447    steps: 541    lr: 2.560000000000001e-06     evaluation reward: 9.45\n",
      "episode: 2008   score: 10.0   memory length: 544321   epsilon: 0.12024244000848515    steps: 503    lr: 2.560000000000001e-06     evaluation reward: 9.42\n",
      "episode: 2009   score: 8.0   memory length: 544737   epsilon: 0.11941876000848571    steps: 416    lr: 2.560000000000001e-06     evaluation reward: 9.41\n",
      "episode: 2010   score: 11.0   memory length: 545233   epsilon: 0.11843668000848638    steps: 496    lr: 2.560000000000001e-06     evaluation reward: 9.45\n",
      "episode: 2011   score: 4.0   memory length: 545489   epsilon: 0.11792980000848673    steps: 256    lr: 2.560000000000001e-06     evaluation reward: 9.4\n",
      "episode: 2012   score: 11.0   memory length: 546008   epsilon: 0.11690218000848743    steps: 519    lr: 2.560000000000001e-06     evaluation reward: 9.46\n",
      "episode: 2013   score: 15.0   memory length: 546571   epsilon: 0.11578744000848819    steps: 563    lr: 2.560000000000001e-06     evaluation reward: 9.53\n",
      "episode: 2014   score: 15.0   memory length: 547160   epsilon: 0.11462122000848898    steps: 589    lr: 2.560000000000001e-06     evaluation reward: 9.58\n",
      "episode: 2015   score: 9.0   memory length: 547638   epsilon: 0.11367478000848963    steps: 478    lr: 2.560000000000001e-06     evaluation reward: 9.58\n",
      "episode: 2016   score: 8.0   memory length: 548091   epsilon: 0.11277784000849024    steps: 453    lr: 2.560000000000001e-06     evaluation reward: 9.55\n",
      "episode: 2017   score: 4.0   memory length: 548345   epsilon: 0.11227492000849058    steps: 254    lr: 2.560000000000001e-06     evaluation reward: 9.48\n",
      "episode: 2018   score: 10.0   memory length: 548804   epsilon: 0.1113661000084912    steps: 459    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 2019   score: 12.0   memory length: 549379   epsilon: 0.11022760000849198    steps: 575    lr: 2.560000000000001e-06     evaluation reward: 9.45\n",
      "episode: 2020   score: 9.0   memory length: 549791   epsilon: 0.10941184000849254    steps: 412    lr: 2.560000000000001e-06     evaluation reward: 9.44\n",
      "episode: 2021   score: 14.0   memory length: 550266   epsilon: 0.10847134000849318    steps: 475    lr: 2.560000000000001e-06     evaluation reward: 9.44\n",
      "episode: 2022   score: 9.0   memory length: 550722   epsilon: 0.1075684600084938    steps: 456    lr: 2.560000000000001e-06     evaluation reward: 9.42\n",
      "episode: 2023   score: 11.0   memory length: 551267   epsilon: 0.10648936000849453    steps: 545    lr: 2.560000000000001e-06     evaluation reward: 9.44\n",
      "episode: 2024   score: 10.0   memory length: 551768   epsilon: 0.1054973800084952    steps: 501    lr: 2.560000000000001e-06     evaluation reward: 9.46\n",
      "episode: 2025   score: 10.0   memory length: 552267   epsilon: 0.10450936000849588    steps: 499    lr: 2.560000000000001e-06     evaluation reward: 9.48\n",
      "episode: 2026   score: 10.0   memory length: 552766   epsilon: 0.10352134000849655    steps: 499    lr: 2.560000000000001e-06     evaluation reward: 9.44\n",
      "episode: 2027   score: 6.0   memory length: 553106   epsilon: 0.10284814000849701    steps: 340    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 2028   score: 9.0   memory length: 553590   epsilon: 0.10188982000849767    steps: 484    lr: 2.560000000000001e-06     evaluation reward: 9.41\n",
      "episode: 2029   score: 8.0   memory length: 554031   epsilon: 0.10101664000849826    steps: 441    lr: 2.560000000000001e-06     evaluation reward: 9.36\n",
      "episode: 2030   score: 9.0   memory length: 554486   epsilon: 0.10011574000849888    steps: 455    lr: 2.560000000000001e-06     evaluation reward: 9.36\n",
      "episode: 2031   score: 12.0   memory length: 555057   epsilon: 0.09898516000849965    steps: 571    lr: 2.560000000000001e-06     evaluation reward: 9.43\n",
      "episode: 2032   score: 15.0   memory length: 555592   epsilon: 0.09792586000850037    steps: 535    lr: 2.560000000000001e-06     evaluation reward: 9.53\n",
      "episode: 2033   score: 13.0   memory length: 556198   epsilon: 0.09672598000850119    steps: 606    lr: 2.560000000000001e-06     evaluation reward: 9.58\n",
      "episode: 2034   score: 10.0   memory length: 556766   epsilon: 0.09560134000850196    steps: 568    lr: 2.560000000000001e-06     evaluation reward: 9.59\n",
      "episode: 2035   score: 10.0   memory length: 557252   epsilon: 0.09463906000850261    steps: 486    lr: 2.560000000000001e-06     evaluation reward: 9.58\n",
      "episode: 2036   score: 10.0   memory length: 557757   epsilon: 0.0936391600085033    steps: 505    lr: 2.560000000000001e-06     evaluation reward: 9.62\n",
      "episode: 2037   score: 19.0   memory length: 558256   epsilon: 0.09265114000850397    steps: 499    lr: 2.560000000000001e-06     evaluation reward: 9.67\n",
      "episode: 2038   score: 10.0   memory length: 558790   epsilon: 0.09159382000850469    steps: 534    lr: 2.560000000000001e-06     evaluation reward: 9.7\n",
      "episode: 2039   score: 16.0   memory length: 559383   epsilon: 0.09041968000850549    steps: 593    lr: 2.560000000000001e-06     evaluation reward: 9.76\n",
      "episode: 2040   score: 4.0   memory length: 559644   epsilon: 0.08990290000850584    steps: 261    lr: 2.560000000000001e-06     evaluation reward: 9.71\n",
      "episode: 2041   score: 8.0   memory length: 560072   epsilon: 0.08905546000850642    steps: 428    lr: 2.560000000000001e-06     evaluation reward: 9.74\n",
      "episode: 2042   score: 10.0   memory length: 560558   epsilon: 0.08809318000850708    steps: 486    lr: 2.560000000000001e-06     evaluation reward: 9.76\n",
      "episode: 2043   score: 8.0   memory length: 560991   epsilon: 0.08723584000850766    steps: 433    lr: 2.560000000000001e-06     evaluation reward: 9.77\n",
      "episode: 2044   score: 7.0   memory length: 561376   epsilon: 0.08647354000850818    steps: 385    lr: 2.560000000000001e-06     evaluation reward: 9.78\n",
      "episode: 2045   score: 19.0   memory length: 562133   epsilon: 0.0849746800085092    steps: 757    lr: 2.560000000000001e-06     evaluation reward: 9.91\n",
      "episode: 2046   score: 9.0   memory length: 562636   epsilon: 0.08397874000850988    steps: 503    lr: 2.560000000000001e-06     evaluation reward: 9.85\n",
      "episode: 2047   score: 8.0   memory length: 563086   epsilon: 0.08308774000851049    steps: 450    lr: 2.560000000000001e-06     evaluation reward: 9.82\n",
      "episode: 2048   score: 11.0   memory length: 563684   epsilon: 0.0819037000085113    steps: 598    lr: 2.560000000000001e-06     evaluation reward: 9.85\n",
      "episode: 2049   score: 10.0   memory length: 564218   epsilon: 0.08084638000851202    steps: 534    lr: 2.560000000000001e-06     evaluation reward: 9.88\n",
      "episode: 2050   score: 9.0   memory length: 564687   epsilon: 0.07991776000851265    steps: 469    lr: 2.560000000000001e-06     evaluation reward: 9.85\n",
      "episode: 2051   score: 9.0   memory length: 565198   epsilon: 0.07890598000851334    steps: 511    lr: 2.560000000000001e-06     evaluation reward: 9.82\n",
      "episode: 2052   score: 9.0   memory length: 565678   epsilon: 0.07795558000851399    steps: 480    lr: 2.560000000000001e-06     evaluation reward: 9.83\n",
      "episode: 2053   score: 13.0   memory length: 566264   epsilon: 0.07679530000851478    steps: 586    lr: 2.560000000000001e-06     evaluation reward: 9.85\n",
      "episode: 2054   score: 10.0   memory length: 566748   epsilon: 0.07583698000851544    steps: 484    lr: 2.560000000000001e-06     evaluation reward: 9.89\n",
      "episode: 2055   score: 8.0   memory length: 567183   epsilon: 0.07497568000851602    steps: 435    lr: 2.560000000000001e-06     evaluation reward: 9.9\n",
      "episode: 2056   score: 8.0   memory length: 567631   epsilon: 0.07408864000851663    steps: 448    lr: 2.560000000000001e-06     evaluation reward: 9.85\n",
      "episode: 2057   score: 10.0   memory length: 568136   epsilon: 0.07308874000851731    steps: 505    lr: 2.560000000000001e-06     evaluation reward: 9.9\n",
      "episode: 2058   score: 9.0   memory length: 568567   epsilon: 0.0722353600085179    steps: 431    lr: 2.560000000000001e-06     evaluation reward: 9.89\n",
      "episode: 2059   score: 13.0   memory length: 569185   epsilon: 0.07101172000851873    steps: 618    lr: 2.560000000000001e-06     evaluation reward: 9.95\n",
      "episode: 2060   score: 8.0   memory length: 569639   epsilon: 0.07011280000851934    steps: 454    lr: 2.560000000000001e-06     evaluation reward: 9.94\n",
      "episode: 2061   score: 7.0   memory length: 570041   epsilon: 0.06931684000851988    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 9.93\n",
      "episode: 2062   score: 8.0   memory length: 570485   epsilon: 0.06843772000852048    steps: 444    lr: 2.560000000000001e-06     evaluation reward: 9.79\n",
      "episode: 2063   score: 13.0   memory length: 571128   epsilon: 0.06716458000852135    steps: 643    lr: 2.560000000000001e-06     evaluation reward: 9.81\n",
      "episode: 2064   score: 8.0   memory length: 571581   epsilon: 0.06626764000852196    steps: 453    lr: 2.560000000000001e-06     evaluation reward: 9.84\n",
      "episode: 2065   score: 7.0   memory length: 571983   epsilon: 0.0654716800085225    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 9.81\n",
      "episode: 2066   score: 15.0   memory length: 572540   epsilon: 0.06436882000852326    steps: 557    lr: 2.560000000000001e-06     evaluation reward: 9.89\n",
      "episode: 2067   score: 9.0   memory length: 573023   epsilon: 0.06341248000852391    steps: 483    lr: 2.560000000000001e-06     evaluation reward: 9.88\n",
      "episode: 2068   score: 11.0   memory length: 573442   epsilon: 0.06258286000852448    steps: 419    lr: 2.560000000000001e-06     evaluation reward: 9.95\n",
      "episode: 2069   score: 12.0   memory length: 573975   epsilon: 0.0615275200085252    steps: 533    lr: 2.560000000000001e-06     evaluation reward: 9.99\n",
      "episode: 2070   score: 10.0   memory length: 574491   epsilon: 0.060505840008525894    steps: 516    lr: 2.560000000000001e-06     evaluation reward: 10.0\n",
      "episode: 2071   score: 9.0   memory length: 574937   epsilon: 0.059622760008526496    steps: 446    lr: 2.560000000000001e-06     evaluation reward: 10.0\n",
      "episode: 2072   score: 9.0   memory length: 575417   epsilon: 0.058672360008527144    steps: 480    lr: 2.560000000000001e-06     evaluation reward: 10.01\n",
      "episode: 2073   score: 5.0   memory length: 575706   epsilon: 0.058100140008527534    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 10.02\n",
      "episode: 2074   score: 5.0   memory length: 576011   epsilon: 0.057496240008527946    steps: 305    lr: 2.560000000000001e-06     evaluation reward: 9.97\n",
      "episode: 2075   score: 12.0   memory length: 576516   epsilon: 0.05649634000852863    steps: 505    lr: 2.560000000000001e-06     evaluation reward: 10.01\n",
      "episode: 2076   score: 9.0   memory length: 576947   epsilon: 0.05564296000852921    steps: 431    lr: 2.560000000000001e-06     evaluation reward: 10.0\n",
      "episode: 2077   score: 9.0   memory length: 577416   epsilon: 0.054714340008529844    steps: 469    lr: 2.560000000000001e-06     evaluation reward: 10.01\n",
      "episode: 2078   score: 10.0   memory length: 577901   epsilon: 0.0537540400085305    steps: 485    lr: 2.560000000000001e-06     evaluation reward: 9.96\n",
      "episode: 2079   score: 21.0   memory length: 578507   epsilon: 0.05255416000853132    steps: 606    lr: 2.560000000000001e-06     evaluation reward: 10.01\n",
      "episode: 2080   score: 11.0   memory length: 579069   epsilon: 0.051441400008532076    steps: 562    lr: 2.560000000000001e-06     evaluation reward: 10.03\n",
      "episode: 2081   score: 9.0   memory length: 579536   epsilon: 0.05051674000853271    steps: 467    lr: 2.560000000000001e-06     evaluation reward: 10.02\n",
      "episode: 2082   score: 11.0   memory length: 580050   epsilon: 0.0494990200085334    steps: 514    lr: 2.560000000000001e-06     evaluation reward: 9.99\n",
      "episode: 2083   score: 9.0   memory length: 580506   epsilon: 0.04859614000853402    steps: 456    lr: 2.560000000000001e-06     evaluation reward: 9.99\n",
      "episode: 2084   score: 10.0   memory length: 581007   epsilon: 0.04760416000853469    steps: 501    lr: 2.560000000000001e-06     evaluation reward: 9.94\n",
      "episode: 2085   score: 7.0   memory length: 581387   epsilon: 0.046851760008535207    steps: 380    lr: 2.560000000000001e-06     evaluation reward: 9.96\n",
      "episode: 2086   score: 9.0   memory length: 581875   epsilon: 0.045885520008535866    steps: 488    lr: 2.560000000000001e-06     evaluation reward: 9.97\n",
      "episode: 2087   score: 6.0   memory length: 582229   epsilon: 0.045184600008536344    steps: 354    lr: 2.560000000000001e-06     evaluation reward: 9.95\n",
      "episode: 2088   score: 8.0   memory length: 582642   epsilon: 0.0443668600085369    steps: 413    lr: 2.560000000000001e-06     evaluation reward: 9.95\n",
      "episode: 2089   score: 10.0   memory length: 583145   epsilon: 0.04337092000853758    steps: 503    lr: 2.560000000000001e-06     evaluation reward: 9.99\n",
      "episode: 2090   score: 12.0   memory length: 583705   epsilon: 0.04226212000853834    steps: 560    lr: 2.560000000000001e-06     evaluation reward: 10.0\n",
      "episode: 2091   score: 8.0   memory length: 584136   epsilon: 0.04140874000853892    steps: 431    lr: 2.560000000000001e-06     evaluation reward: 10.01\n",
      "episode: 2092   score: 10.0   memory length: 584639   epsilon: 0.0404128000085396    steps: 503    lr: 2.560000000000001e-06     evaluation reward: 10.05\n",
      "episode: 2093   score: 9.0   memory length: 585119   epsilon: 0.03946240000854025    steps: 480    lr: 2.560000000000001e-06     evaluation reward: 9.97\n",
      "episode: 2094   score: 11.0   memory length: 585649   epsilon: 0.03841300000854096    steps: 530    lr: 2.560000000000001e-06     evaluation reward: 10.02\n",
      "episode: 2095   score: 9.0   memory length: 586151   epsilon: 0.03741904000854164    steps: 502    lr: 2.560000000000001e-06     evaluation reward: 10.01\n",
      "episode: 2096   score: 8.0   memory length: 586619   epsilon: 0.03649240000854227    steps: 468    lr: 2.560000000000001e-06     evaluation reward: 10.01\n",
      "episode: 2097   score: 15.0   memory length: 587274   epsilon: 0.03519550000854316    steps: 655    lr: 2.560000000000001e-06     evaluation reward: 10.09\n",
      "episode: 2098   score: 9.0   memory length: 587735   epsilon: 0.03428272000854378    steps: 461    lr: 2.560000000000001e-06     evaluation reward: 10.07\n",
      "episode: 2099   score: 8.0   memory length: 588205   epsilon: 0.033352120008544414    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 10.03\n",
      "episode: 2100   score: 7.0   memory length: 588628   epsilon: 0.032514580008544985    steps: 423    lr: 2.560000000000001e-06     evaluation reward: 9.95\n",
      "episode: 2101   score: 7.0   memory length: 589032   epsilon: 0.03171466000854553    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 9.91\n",
      "episode: 2102   score: 7.0   memory length: 589437   epsilon: 0.030912760008546078    steps: 405    lr: 2.560000000000001e-06     evaluation reward: 9.91\n",
      "episode: 2103   score: 9.0   memory length: 589908   epsilon: 0.029980180008546714    steps: 471    lr: 2.560000000000001e-06     evaluation reward: 9.9\n",
      "episode: 2104   score: 8.0   memory length: 590321   epsilon: 0.029162440008547272    steps: 413    lr: 2.560000000000001e-06     evaluation reward: 9.82\n",
      "episode: 2105   score: 13.0   memory length: 590857   epsilon: 0.028101160008547996    steps: 536    lr: 2.560000000000001e-06     evaluation reward: 9.84\n",
      "episode: 2106   score: 9.0   memory length: 591310   epsilon: 0.027204220008548607    steps: 453    lr: 2.560000000000001e-06     evaluation reward: 9.87\n",
      "episode: 2107   score: 9.0   memory length: 591781   epsilon: 0.026271640008549244    steps: 471    lr: 2.560000000000001e-06     evaluation reward: 9.84\n",
      "episode: 2108   score: 7.0   memory length: 592161   epsilon: 0.025519240008549757    steps: 380    lr: 2.560000000000001e-06     evaluation reward: 9.81\n",
      "episode: 2109   score: 12.0   memory length: 592759   epsilon: 0.024335200008550564    steps: 598    lr: 2.560000000000001e-06     evaluation reward: 9.85\n",
      "episode: 2110   score: 11.0   memory length: 593269   epsilon: 0.023325400008551253    steps: 510    lr: 2.560000000000001e-06     evaluation reward: 9.85\n",
      "episode: 2111   score: 9.0   memory length: 593770   epsilon: 0.02233342000855193    steps: 501    lr: 2.560000000000001e-06     evaluation reward: 9.9\n",
      "episode: 2112   score: 10.0   memory length: 594258   epsilon: 0.02136718000855259    steps: 488    lr: 2.560000000000001e-06     evaluation reward: 9.89\n",
      "episode: 2113   score: 10.0   memory length: 594779   epsilon: 0.020335600008553292    steps: 521    lr: 2.560000000000001e-06     evaluation reward: 9.84\n",
      "episode: 2114   score: 8.0   memory length: 595195   epsilon: 0.019511920008553854    steps: 416    lr: 2.560000000000001e-06     evaluation reward: 9.77\n",
      "episode: 2115   score: 14.0   memory length: 595761   epsilon: 0.01839124000855462    steps: 566    lr: 2.560000000000001e-06     evaluation reward: 9.82\n",
      "episode: 2116   score: 9.0   memory length: 596216   epsilon: 0.017490340008555233    steps: 455    lr: 2.560000000000001e-06     evaluation reward: 9.83\n",
      "episode: 2117   score: 8.0   memory length: 596649   epsilon: 0.016633000008555818    steps: 433    lr: 2.560000000000001e-06     evaluation reward: 9.87\n",
      "episode: 2118   score: 6.0   memory length: 596981   epsilon: 0.015975640008556266    steps: 332    lr: 2.560000000000001e-06     evaluation reward: 9.83\n",
      "episode: 2119   score: 11.0   memory length: 597536   epsilon: 0.01487674000855636    steps: 555    lr: 2.560000000000001e-06     evaluation reward: 9.82\n",
      "episode: 2120   score: 6.0   memory length: 597872   epsilon: 0.01421146000855623    steps: 336    lr: 2.560000000000001e-06     evaluation reward: 9.79\n",
      "episode: 2121   score: 9.0   memory length: 598342   epsilon: 0.01328086000855605    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 9.74\n",
      "episode: 2122   score: 8.0   memory length: 598767   epsilon: 0.012439360008555887    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 9.73\n",
      "episode: 2123   score: 9.0   memory length: 599253   epsilon: 0.0114770800085557    steps: 486    lr: 2.560000000000001e-06     evaluation reward: 9.71\n",
      "episode: 2124   score: 9.0   memory length: 599733   epsilon: 0.010526680008555516    steps: 480    lr: 2.560000000000001e-06     evaluation reward: 9.7\n",
      "episode: 2125   score: 17.0   memory length: 600360   epsilon: 0.009998020008555413    steps: 627    lr: 1.0240000000000005e-06     evaluation reward: 9.77\n",
      "episode: 2126   score: 12.0   memory length: 600924   epsilon: 0.009998020008555413    steps: 564    lr: 1.0240000000000005e-06     evaluation reward: 9.79\n",
      "episode: 2127   score: 10.0   memory length: 601443   epsilon: 0.009998020008555413    steps: 519    lr: 1.0240000000000005e-06     evaluation reward: 9.83\n",
      "episode: 2128   score: 8.0   memory length: 601856   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 9.82\n",
      "episode: 2129   score: 9.0   memory length: 602337   epsilon: 0.009998020008555413    steps: 481    lr: 1.0240000000000005e-06     evaluation reward: 9.83\n",
      "episode: 2130   score: 12.0   memory length: 602866   epsilon: 0.009998020008555413    steps: 529    lr: 1.0240000000000005e-06     evaluation reward: 9.86\n",
      "episode: 2131   score: 7.0   memory length: 603232   epsilon: 0.009998020008555413    steps: 366    lr: 1.0240000000000005e-06     evaluation reward: 9.81\n",
      "episode: 2132   score: 17.0   memory length: 603982   epsilon: 0.009998020008555413    steps: 750    lr: 1.0240000000000005e-06     evaluation reward: 9.83\n",
      "episode: 2133   score: 10.0   memory length: 604477   epsilon: 0.009998020008555413    steps: 495    lr: 1.0240000000000005e-06     evaluation reward: 9.8\n",
      "episode: 2134   score: 10.0   memory length: 605006   epsilon: 0.009998020008555413    steps: 529    lr: 1.0240000000000005e-06     evaluation reward: 9.8\n",
      "episode: 2135   score: 8.0   memory length: 605474   epsilon: 0.009998020008555413    steps: 468    lr: 1.0240000000000005e-06     evaluation reward: 9.78\n",
      "episode: 2136   score: 6.0   memory length: 605829   epsilon: 0.009998020008555413    steps: 355    lr: 1.0240000000000005e-06     evaluation reward: 9.74\n",
      "episode: 2137   score: 12.0   memory length: 606405   epsilon: 0.009998020008555413    steps: 576    lr: 1.0240000000000005e-06     evaluation reward: 9.67\n",
      "episode: 2138   score: 8.0   memory length: 606818   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 9.65\n",
      "episode: 2139   score: 8.0   memory length: 607274   epsilon: 0.009998020008555413    steps: 456    lr: 1.0240000000000005e-06     evaluation reward: 9.57\n",
      "episode: 2140   score: 15.0   memory length: 607846   epsilon: 0.009998020008555413    steps: 572    lr: 1.0240000000000005e-06     evaluation reward: 9.68\n",
      "episode: 2141   score: 8.0   memory length: 608259   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 9.68\n",
      "episode: 2142   score: 9.0   memory length: 608741   epsilon: 0.009998020008555413    steps: 482    lr: 1.0240000000000005e-06     evaluation reward: 9.67\n",
      "episode: 2143   score: 17.0   memory length: 609310   epsilon: 0.009998020008555413    steps: 569    lr: 1.0240000000000005e-06     evaluation reward: 9.76\n",
      "episode: 2144   score: 9.0   memory length: 609790   epsilon: 0.009998020008555413    steps: 480    lr: 1.0240000000000005e-06     evaluation reward: 9.78\n",
      "episode: 2145   score: 9.0   memory length: 610224   epsilon: 0.009998020008555413    steps: 434    lr: 1.0240000000000005e-06     evaluation reward: 9.68\n",
      "episode: 2146   score: 8.0   memory length: 610664   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 9.67\n",
      "episode: 2147   score: 11.0   memory length: 611192   epsilon: 0.009998020008555413    steps: 528    lr: 1.0240000000000005e-06     evaluation reward: 9.7\n",
      "episode: 2148   score: 7.0   memory length: 611584   epsilon: 0.009998020008555413    steps: 392    lr: 1.0240000000000005e-06     evaluation reward: 9.66\n",
      "episode: 2149   score: 9.0   memory length: 612086   epsilon: 0.009998020008555413    steps: 502    lr: 1.0240000000000005e-06     evaluation reward: 9.65\n",
      "episode: 2150   score: 9.0   memory length: 612567   epsilon: 0.009998020008555413    steps: 481    lr: 1.0240000000000005e-06     evaluation reward: 9.65\n",
      "episode: 2151   score: 9.0   memory length: 613069   epsilon: 0.009998020008555413    steps: 502    lr: 1.0240000000000005e-06     evaluation reward: 9.65\n",
      "episode: 2152   score: 9.0   memory length: 613509   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 9.65\n",
      "episode: 2153   score: 12.0   memory length: 613979   epsilon: 0.009998020008555413    steps: 470    lr: 1.0240000000000005e-06     evaluation reward: 9.64\n",
      "episode: 2154   score: 8.0   memory length: 614394   epsilon: 0.009998020008555413    steps: 415    lr: 1.0240000000000005e-06     evaluation reward: 9.62\n",
      "episode: 2155   score: 10.0   memory length: 614897   epsilon: 0.009998020008555413    steps: 503    lr: 1.0240000000000005e-06     evaluation reward: 9.64\n",
      "episode: 2156   score: 7.0   memory length: 615300   epsilon: 0.009998020008555413    steps: 403    lr: 1.0240000000000005e-06     evaluation reward: 9.63\n",
      "episode: 2157   score: 8.0   memory length: 615713   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 9.61\n",
      "episode: 2158   score: 11.0   memory length: 616247   epsilon: 0.009998020008555413    steps: 534    lr: 1.0240000000000005e-06     evaluation reward: 9.63\n",
      "episode: 2159   score: 8.0   memory length: 616717   epsilon: 0.009998020008555413    steps: 470    lr: 1.0240000000000005e-06     evaluation reward: 9.58\n",
      "episode: 2160   score: 18.0   memory length: 617291   epsilon: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     evaluation reward: 9.68\n",
      "episode: 2161   score: 22.0   memory length: 617987   epsilon: 0.009998020008555413    steps: 696    lr: 1.0240000000000005e-06     evaluation reward: 9.83\n",
      "episode: 2162   score: 9.0   memory length: 618487   epsilon: 0.009998020008555413    steps: 500    lr: 1.0240000000000005e-06     evaluation reward: 9.84\n",
      "episode: 2163   score: 9.0   memory length: 618919   epsilon: 0.009998020008555413    steps: 432    lr: 1.0240000000000005e-06     evaluation reward: 9.8\n",
      "episode: 2164   score: 10.0   memory length: 619435   epsilon: 0.009998020008555413    steps: 516    lr: 1.0240000000000005e-06     evaluation reward: 9.82\n",
      "episode: 2165   score: 7.0   memory length: 619838   epsilon: 0.009998020008555413    steps: 403    lr: 1.0240000000000005e-06     evaluation reward: 9.82\n",
      "episode: 2166   score: 10.0   memory length: 620335   epsilon: 0.009998020008555413    steps: 497    lr: 1.0240000000000005e-06     evaluation reward: 9.77\n",
      "episode: 2167   score: 10.0   memory length: 620839   epsilon: 0.009998020008555413    steps: 504    lr: 1.0240000000000005e-06     evaluation reward: 9.78\n",
      "episode: 2168   score: 10.0   memory length: 621334   epsilon: 0.009998020008555413    steps: 495    lr: 1.0240000000000005e-06     evaluation reward: 9.77\n",
      "episode: 2169   score: 12.0   memory length: 621817   epsilon: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     evaluation reward: 9.77\n",
      "episode: 2170   score: 15.0   memory length: 622364   epsilon: 0.009998020008555413    steps: 547    lr: 1.0240000000000005e-06     evaluation reward: 9.82\n",
      "episode: 2171   score: 10.0   memory length: 622896   epsilon: 0.009998020008555413    steps: 532    lr: 1.0240000000000005e-06     evaluation reward: 9.83\n",
      "episode: 2172   score: 11.0   memory length: 623430   epsilon: 0.009998020008555413    steps: 534    lr: 1.0240000000000005e-06     evaluation reward: 9.85\n",
      "episode: 2173   score: 9.0   memory length: 623916   epsilon: 0.009998020008555413    steps: 486    lr: 1.0240000000000005e-06     evaluation reward: 9.89\n",
      "episode: 2174   score: 10.0   memory length: 624411   epsilon: 0.009998020008555413    steps: 495    lr: 1.0240000000000005e-06     evaluation reward: 9.94\n",
      "episode: 2175   score: 10.0   memory length: 624927   epsilon: 0.009998020008555413    steps: 516    lr: 1.0240000000000005e-06     evaluation reward: 9.92\n",
      "episode: 2176   score: 12.0   memory length: 625481   epsilon: 0.009998020008555413    steps: 554    lr: 1.0240000000000005e-06     evaluation reward: 9.95\n",
      "episode: 2177   score: 10.0   memory length: 625968   epsilon: 0.009998020008555413    steps: 487    lr: 1.0240000000000005e-06     evaluation reward: 9.96\n",
      "episode: 2178   score: 9.0   memory length: 626423   epsilon: 0.009998020008555413    steps: 455    lr: 1.0240000000000005e-06     evaluation reward: 9.95\n",
      "episode: 2179   score: 9.0   memory length: 626909   epsilon: 0.009998020008555413    steps: 486    lr: 1.0240000000000005e-06     evaluation reward: 9.83\n",
      "episode: 2180   score: 18.0   memory length: 627483   epsilon: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     evaluation reward: 9.9\n",
      "episode: 2181   score: 19.0   memory length: 628105   epsilon: 0.009998020008555413    steps: 622    lr: 1.0240000000000005e-06     evaluation reward: 10.0\n",
      "episode: 2182   score: 18.0   memory length: 628679   epsilon: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     evaluation reward: 10.07\n",
      "episode: 2183   score: 18.0   memory length: 629253   epsilon: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     evaluation reward: 10.16\n",
      "episode: 2184   score: 7.0   memory length: 629636   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 10.13\n",
      "episode: 2185   score: 9.0   memory length: 630117   epsilon: 0.009998020008555413    steps: 481    lr: 1.0240000000000005e-06     evaluation reward: 10.15\n",
      "episode: 2186   score: 7.0   memory length: 630520   epsilon: 0.009998020008555413    steps: 403    lr: 1.0240000000000005e-06     evaluation reward: 10.13\n",
      "episode: 2187   score: 10.0   memory length: 631028   epsilon: 0.009998020008555413    steps: 508    lr: 1.0240000000000005e-06     evaluation reward: 10.17\n",
      "episode: 2188   score: 9.0   memory length: 631474   epsilon: 0.009998020008555413    steps: 446    lr: 1.0240000000000005e-06     evaluation reward: 10.18\n",
      "episode: 2189   score: 7.0   memory length: 631856   epsilon: 0.009998020008555413    steps: 382    lr: 1.0240000000000005e-06     evaluation reward: 10.15\n",
      "episode: 2190   score: 8.0   memory length: 632271   epsilon: 0.009998020008555413    steps: 415    lr: 1.0240000000000005e-06     evaluation reward: 10.11\n",
      "episode: 2191   score: 18.0   memory length: 632845   epsilon: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     evaluation reward: 10.21\n",
      "episode: 2192   score: 8.0   memory length: 633296   epsilon: 0.009998020008555413    steps: 451    lr: 1.0240000000000005e-06     evaluation reward: 10.19\n",
      "episode: 2193   score: 14.0   memory length: 633827   epsilon: 0.009998020008555413    steps: 531    lr: 1.0240000000000005e-06     evaluation reward: 10.24\n",
      "episode: 2194   score: 9.0   memory length: 634298   epsilon: 0.009998020008555413    steps: 471    lr: 1.0240000000000005e-06     evaluation reward: 10.22\n",
      "episode: 2195   score: 7.0   memory length: 634698   epsilon: 0.009998020008555413    steps: 400    lr: 1.0240000000000005e-06     evaluation reward: 10.2\n",
      "episode: 2196   score: 8.0   memory length: 635111   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 10.2\n",
      "episode: 2197   score: 18.0   memory length: 635685   epsilon: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     evaluation reward: 10.23\n",
      "episode: 2198   score: 13.0   memory length: 636221   epsilon: 0.009998020008555413    steps: 536    lr: 1.0240000000000005e-06     evaluation reward: 10.27\n",
      "episode: 2199   score: 7.0   memory length: 636624   epsilon: 0.009998020008555413    steps: 403    lr: 1.0240000000000005e-06     evaluation reward: 10.26\n",
      "episode: 2200   score: 11.0   memory length: 637174   epsilon: 0.009998020008555413    steps: 550    lr: 1.0240000000000005e-06     evaluation reward: 10.3\n",
      "episode: 2201   score: 10.0   memory length: 637664   epsilon: 0.009998020008555413    steps: 490    lr: 1.0240000000000005e-06     evaluation reward: 10.33\n",
      "episode: 2202   score: 14.0   memory length: 638269   epsilon: 0.009998020008555413    steps: 605    lr: 1.0240000000000005e-06     evaluation reward: 10.4\n",
      "episode: 2203   score: 7.0   memory length: 638651   epsilon: 0.009998020008555413    steps: 382    lr: 1.0240000000000005e-06     evaluation reward: 10.38\n",
      "episode: 2204   score: 5.0   memory length: 638976   epsilon: 0.009998020008555413    steps: 325    lr: 1.0240000000000005e-06     evaluation reward: 10.35\n",
      "episode: 2205   score: 9.0   memory length: 639479   epsilon: 0.009998020008555413    steps: 503    lr: 1.0240000000000005e-06     evaluation reward: 10.31\n",
      "episode: 2206   score: 8.0   memory length: 639954   epsilon: 0.009998020008555413    steps: 475    lr: 1.0240000000000005e-06     evaluation reward: 10.3\n",
      "episode: 2207   score: 18.0   memory length: 640528   epsilon: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     evaluation reward: 10.39\n",
      "episode: 2208   score: 11.0   memory length: 641040   epsilon: 0.009998020008555413    steps: 512    lr: 1.0240000000000005e-06     evaluation reward: 10.43\n",
      "episode: 2209   score: 20.0   memory length: 641700   epsilon: 0.009998020008555413    steps: 660    lr: 1.0240000000000005e-06     evaluation reward: 10.51\n",
      "episode: 2210   score: 8.0   memory length: 642131   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 10.48\n",
      "episode: 2211   score: 8.0   memory length: 642583   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 10.47\n",
      "episode: 2212   score: 7.0   memory length: 642984   epsilon: 0.009998020008555413    steps: 401    lr: 1.0240000000000005e-06     evaluation reward: 10.44\n",
      "episode: 2213   score: 9.0   memory length: 643470   epsilon: 0.009998020008555413    steps: 486    lr: 1.0240000000000005e-06     evaluation reward: 10.43\n",
      "episode: 2214   score: 8.0   memory length: 643883   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 10.43\n",
      "episode: 2215   score: 19.0   memory length: 644602   epsilon: 0.009998020008555413    steps: 719    lr: 1.0240000000000005e-06     evaluation reward: 10.48\n",
      "episode: 2216   score: 10.0   memory length: 645116   epsilon: 0.009998020008555413    steps: 514    lr: 1.0240000000000005e-06     evaluation reward: 10.49\n",
      "episode: 2217   score: 9.0   memory length: 645602   epsilon: 0.009998020008555413    steps: 486    lr: 1.0240000000000005e-06     evaluation reward: 10.5\n",
      "episode: 2218   score: 8.0   memory length: 646015   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 10.52\n",
      "episode: 2219   score: 9.0   memory length: 646520   epsilon: 0.009998020008555413    steps: 505    lr: 1.0240000000000005e-06     evaluation reward: 10.5\n",
      "episode: 2220   score: 8.0   memory length: 646933   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 10.52\n",
      "episode: 2221   score: 8.0   memory length: 647364   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 10.51\n",
      "episode: 2222   score: 10.0   memory length: 647871   epsilon: 0.009998020008555413    steps: 507    lr: 1.0240000000000005e-06     evaluation reward: 10.53\n",
      "episode: 2223   score: 8.0   memory length: 648322   epsilon: 0.009998020008555413    steps: 451    lr: 1.0240000000000005e-06     evaluation reward: 10.52\n",
      "episode: 2224   score: 18.0   memory length: 648896   epsilon: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     evaluation reward: 10.61\n",
      "episode: 2225   score: 10.0   memory length: 649405   epsilon: 0.009998020008555413    steps: 509    lr: 1.0240000000000005e-06     evaluation reward: 10.54\n",
      "episode: 2226   score: 10.0   memory length: 649910   epsilon: 0.009998020008555413    steps: 505    lr: 1.0240000000000005e-06     evaluation reward: 10.52\n",
      "episode: 2227   score: 7.0   memory length: 650292   epsilon: 0.009998020008555413    steps: 382    lr: 1.0240000000000005e-06     evaluation reward: 10.49\n",
      "episode: 2228   score: 11.0   memory length: 650826   epsilon: 0.009998020008555413    steps: 534    lr: 1.0240000000000005e-06     evaluation reward: 10.52\n",
      "episode: 2229   score: 10.0   memory length: 651377   epsilon: 0.009998020008555413    steps: 551    lr: 1.0240000000000005e-06     evaluation reward: 10.53\n",
      "episode: 2230   score: 16.0   memory length: 651962   epsilon: 0.009998020008555413    steps: 585    lr: 1.0240000000000005e-06     evaluation reward: 10.57\n",
      "episode: 2231   score: 12.0   memory length: 652447   epsilon: 0.009998020008555413    steps: 485    lr: 1.0240000000000005e-06     evaluation reward: 10.62\n",
      "episode: 2232   score: 8.0   memory length: 652852   epsilon: 0.009998020008555413    steps: 405    lr: 1.0240000000000005e-06     evaluation reward: 10.53\n",
      "episode: 2233   score: 16.0   memory length: 653437   epsilon: 0.009998020008555413    steps: 585    lr: 1.0240000000000005e-06     evaluation reward: 10.59\n",
      "episode: 2234   score: 10.0   memory length: 653942   epsilon: 0.009998020008555413    steps: 505    lr: 1.0240000000000005e-06     evaluation reward: 10.59\n",
      "episode: 2235   score: 9.0   memory length: 654382   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 10.6\n",
      "episode: 2236   score: 10.0   memory length: 654903   epsilon: 0.009998020008555413    steps: 521    lr: 1.0240000000000005e-06     evaluation reward: 10.64\n",
      "episode: 2237   score: 11.0   memory length: 655461   epsilon: 0.009998020008555413    steps: 558    lr: 1.0240000000000005e-06     evaluation reward: 10.63\n",
      "episode: 2238   score: 7.0   memory length: 655862   epsilon: 0.009998020008555413    steps: 401    lr: 1.0240000000000005e-06     evaluation reward: 10.62\n",
      "episode: 2239   score: 7.0   memory length: 656263   epsilon: 0.009998020008555413    steps: 401    lr: 1.0240000000000005e-06     evaluation reward: 10.61\n",
      "episode: 2240   score: 10.0   memory length: 656797   epsilon: 0.009998020008555413    steps: 534    lr: 1.0240000000000005e-06     evaluation reward: 10.56\n",
      "episode: 2241   score: 10.0   memory length: 657318   epsilon: 0.009998020008555413    steps: 521    lr: 1.0240000000000005e-06     evaluation reward: 10.58\n",
      "episode: 2242   score: 9.0   memory length: 657801   epsilon: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     evaluation reward: 10.58\n",
      "episode: 2243   score: 9.0   memory length: 658241   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 10.5\n",
      "episode: 2244   score: 11.0   memory length: 658787   epsilon: 0.009998020008555413    steps: 546    lr: 1.0240000000000005e-06     evaluation reward: 10.52\n",
      "episode: 2245   score: 17.0   memory length: 659345   epsilon: 0.009998020008555413    steps: 558    lr: 1.0240000000000005e-06     evaluation reward: 10.6\n",
      "episode: 2246   score: 18.0   memory length: 659919   epsilon: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     evaluation reward: 10.7\n",
      "episode: 2247   score: 18.0   memory length: 660493   epsilon: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     evaluation reward: 10.77\n",
      "episode: 2248   score: 10.0   memory length: 660997   epsilon: 0.009998020008555413    steps: 504    lr: 1.0240000000000005e-06     evaluation reward: 10.8\n",
      "episode: 2249   score: 10.0   memory length: 661531   epsilon: 0.009998020008555413    steps: 534    lr: 1.0240000000000005e-06     evaluation reward: 10.81\n",
      "episode: 2250   score: 10.0   memory length: 662021   epsilon: 0.009998020008555413    steps: 490    lr: 1.0240000000000005e-06     evaluation reward: 10.82\n",
      "episode: 2251   score: 9.0   memory length: 662495   epsilon: 0.009998020008555413    steps: 474    lr: 1.0240000000000005e-06     evaluation reward: 10.82\n",
      "episode: 2252   score: 8.0   memory length: 662910   epsilon: 0.009998020008555413    steps: 415    lr: 1.0240000000000005e-06     evaluation reward: 10.81\n",
      "episode: 2253   score: 9.0   memory length: 663393   epsilon: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     evaluation reward: 10.78\n",
      "episode: 2254   score: 4.0   memory length: 663648   epsilon: 0.009998020008555413    steps: 255    lr: 1.0240000000000005e-06     evaluation reward: 10.74\n",
      "episode: 2255   score: 12.0   memory length: 664133   epsilon: 0.009998020008555413    steps: 485    lr: 1.0240000000000005e-06     evaluation reward: 10.76\n",
      "episode: 2256   score: 9.0   memory length: 664616   epsilon: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     evaluation reward: 10.78\n",
      "episode: 2257   score: 19.0   memory length: 665238   epsilon: 0.009998020008555413    steps: 622    lr: 1.0240000000000005e-06     evaluation reward: 10.89\n",
      "episode: 2258   score: 18.0   memory length: 665812   epsilon: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     evaluation reward: 10.96\n",
      "episode: 2259   score: 7.0   memory length: 666233   epsilon: 0.009998020008555413    steps: 421    lr: 1.0240000000000005e-06     evaluation reward: 10.95\n",
      "episode: 2260   score: 10.0   memory length: 666738   epsilon: 0.009998020008555413    steps: 505    lr: 1.0240000000000005e-06     evaluation reward: 10.87\n",
      "episode: 2261   score: 8.0   memory length: 667169   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 10.73\n",
      "episode: 2262   score: 10.0   memory length: 667674   epsilon: 0.009998020008555413    steps: 505    lr: 1.0240000000000005e-06     evaluation reward: 10.74\n",
      "episode: 2263   score: 18.0   memory length: 668248   epsilon: 0.009998020008555413    steps: 574    lr: 1.0240000000000005e-06     evaluation reward: 10.83\n",
      "episode: 2264   score: 12.0   memory length: 668779   epsilon: 0.009998020008555413    steps: 531    lr: 1.0240000000000005e-06     evaluation reward: 10.85\n",
      "episode: 2265   score: 8.0   memory length: 669215   epsilon: 0.009998020008555413    steps: 436    lr: 1.0240000000000005e-06     evaluation reward: 10.86\n",
      "episode: 2266   score: 9.0   memory length: 669696   epsilon: 0.009998020008555413    steps: 481    lr: 1.0240000000000005e-06     evaluation reward: 10.85\n",
      "episode: 2267   score: 10.0   memory length: 670181   epsilon: 0.009998020008555413    steps: 485    lr: 1.0240000000000005e-06     evaluation reward: 10.85\n",
      "episode: 2268   score: 9.0   memory length: 670652   epsilon: 0.009998020008555413    steps: 471    lr: 1.0240000000000005e-06     evaluation reward: 10.84\n",
      "episode: 2269   score: 10.0   memory length: 671173   epsilon: 0.009998020008555413    steps: 521    lr: 1.0240000000000005e-06     evaluation reward: 10.82\n",
      "episode: 2270   score: 12.0   memory length: 671753   epsilon: 0.009998020008555413    steps: 580    lr: 1.0240000000000005e-06     evaluation reward: 10.79\n",
      "episode: 2271   score: 9.0   memory length: 672212   epsilon: 0.009998020008555413    steps: 459    lr: 1.0240000000000005e-06     evaluation reward: 10.78\n",
      "episode: 2272   score: 8.0   memory length: 672643   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 10.75\n",
      "episode: 2273   score: 10.0   memory length: 673177   epsilon: 0.009998020008555413    steps: 534    lr: 1.0240000000000005e-06     evaluation reward: 10.76\n",
      "episode: 2274   score: 9.0   memory length: 673680   epsilon: 0.009998020008555413    steps: 503    lr: 1.0240000000000005e-06     evaluation reward: 10.75\n",
      "episode: 2275   score: 19.0   memory length: 674389   epsilon: 0.009998020008555413    steps: 709    lr: 1.0240000000000005e-06     evaluation reward: 10.84\n",
      "episode: 2276   score: 9.0   memory length: 674845   epsilon: 0.009998020008555413    steps: 456    lr: 1.0240000000000005e-06     evaluation reward: 10.81\n",
      "episode: 2277   score: 9.0   memory length: 675309   epsilon: 0.009998020008555413    steps: 464    lr: 1.0240000000000005e-06     evaluation reward: 10.8\n",
      "episode: 2278   score: 8.0   memory length: 675761   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 10.79\n",
      "episode: 2279   score: 8.0   memory length: 676231   epsilon: 0.009998020008555413    steps: 470    lr: 1.0240000000000005e-06     evaluation reward: 10.78\n",
      "episode: 2280   score: 8.0   memory length: 676662   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 10.68\n",
      "episode: 2281   score: 8.0   memory length: 677096   epsilon: 0.009998020008555413    steps: 434    lr: 1.0240000000000005e-06     evaluation reward: 10.57\n",
      "episode: 2282   score: 8.0   memory length: 677566   epsilon: 0.009998020008555413    steps: 470    lr: 1.0240000000000005e-06     evaluation reward: 10.47\n",
      "episode: 2283   score: 10.0   memory length: 678087   epsilon: 0.009998020008555413    steps: 521    lr: 1.0240000000000005e-06     evaluation reward: 10.39\n",
      "episode: 2284   score: 9.0   memory length: 678551   epsilon: 0.009998020008555413    steps: 464    lr: 1.0240000000000005e-06     evaluation reward: 10.41\n",
      "episode: 2285   score: 11.0   memory length: 679106   epsilon: 0.009998020008555413    steps: 555    lr: 1.0240000000000005e-06     evaluation reward: 10.43\n",
      "episode: 2286   score: 8.0   memory length: 679537   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 10.44\n",
      "episode: 2287   score: 9.0   memory length: 679987   epsilon: 0.009998020008555413    steps: 450    lr: 1.0240000000000005e-06     evaluation reward: 10.43\n",
      "episode: 2288   score: 10.0   memory length: 680521   epsilon: 0.009998020008555413    steps: 534    lr: 1.0240000000000005e-06     evaluation reward: 10.44\n",
      "episode: 2289   score: 8.0   memory length: 680952   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 10.45\n",
      "episode: 2290   score: 9.0   memory length: 681415   epsilon: 0.009998020008555413    steps: 463    lr: 1.0240000000000005e-06     evaluation reward: 10.46\n",
      "episode: 2291   score: 9.0   memory length: 681901   epsilon: 0.009998020008555413    steps: 486    lr: 1.0240000000000005e-06     evaluation reward: 10.37\n",
      "episode: 2292   score: 8.0   memory length: 682367   epsilon: 0.009998020008555413    steps: 466    lr: 1.0240000000000005e-06     evaluation reward: 10.37\n",
      "episode: 2293   score: 11.0   memory length: 682903   epsilon: 0.009998020008555413    steps: 536    lr: 1.0240000000000005e-06     evaluation reward: 10.34\n",
      "episode: 2294   score: 9.0   memory length: 683389   epsilon: 0.009998020008555413    steps: 486    lr: 1.0240000000000005e-06     evaluation reward: 10.34\n",
      "episode: 2295   score: 17.0   memory length: 683947   epsilon: 0.009998020008555413    steps: 558    lr: 1.0240000000000005e-06     evaluation reward: 10.44\n",
      "episode: 2296   score: 18.0   memory length: 684605   epsilon: 0.009998020008555413    steps: 658    lr: 1.0240000000000005e-06     evaluation reward: 10.54\n",
      "episode: 2297   score: 8.0   memory length: 685036   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 10.44\n",
      "episode: 2298   score: 8.0   memory length: 685467   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 10.39\n",
      "episode: 2299   score: 9.0   memory length: 685924   epsilon: 0.009998020008555413    steps: 457    lr: 1.0240000000000005e-06     evaluation reward: 10.41\n",
      "episode: 2300   score: 8.0   memory length: 686356   epsilon: 0.009998020008555413    steps: 432    lr: 1.0240000000000005e-06     evaluation reward: 10.38\n",
      "episode: 2301   score: 8.0   memory length: 686809   epsilon: 0.009998020008555413    steps: 453    lr: 1.0240000000000005e-06     evaluation reward: 10.36\n",
      "episode: 2302   score: 11.0   memory length: 687392   epsilon: 0.009998020008555413    steps: 583    lr: 1.0240000000000005e-06     evaluation reward: 10.33\n",
      "episode: 2303   score: 8.0   memory length: 687826   epsilon: 0.009998020008555413    steps: 434    lr: 1.0240000000000005e-06     evaluation reward: 10.34\n",
      "episode: 2304   score: 9.0   memory length: 688312   epsilon: 0.009998020008555413    steps: 486    lr: 1.0240000000000005e-06     evaluation reward: 10.38\n",
      "episode: 2305   score: 8.0   memory length: 688782   epsilon: 0.009998020008555413    steps: 470    lr: 1.0240000000000005e-06     evaluation reward: 10.37\n",
      "episode: 2306   score: 12.0   memory length: 689402   epsilon: 0.009998020008555413    steps: 620    lr: 1.0240000000000005e-06     evaluation reward: 10.41\n",
      "episode: 2307   score: 13.0   memory length: 689920   epsilon: 0.009998020008555413    steps: 518    lr: 1.0240000000000005e-06     evaluation reward: 10.36\n",
      "episode: 2308   score: 9.0   memory length: 690378   epsilon: 0.009998020008555413    steps: 458    lr: 1.0240000000000005e-06     evaluation reward: 10.34\n",
      "episode: 2309   score: 12.0   memory length: 690861   epsilon: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     evaluation reward: 10.26\n",
      "episode: 2310   score: 9.0   memory length: 691319   epsilon: 0.009998020008555413    steps: 458    lr: 1.0240000000000005e-06     evaluation reward: 10.27\n",
      "episode: 2311   score: 8.0   memory length: 691742   epsilon: 0.009998020008555413    steps: 423    lr: 1.0240000000000005e-06     evaluation reward: 10.27\n",
      "episode: 2312   score: 10.0   memory length: 692276   epsilon: 0.009998020008555413    steps: 534    lr: 1.0240000000000005e-06     evaluation reward: 10.3\n",
      "episode: 2313   score: 10.0   memory length: 692810   epsilon: 0.009998020008555413    steps: 534    lr: 1.0240000000000005e-06     evaluation reward: 10.31\n",
      "episode: 2314   score: 8.0   memory length: 693244   epsilon: 0.009998020008555413    steps: 434    lr: 1.0240000000000005e-06     evaluation reward: 10.31\n",
      "episode: 2315   score: 12.0   memory length: 693729   epsilon: 0.009998020008555413    steps: 485    lr: 1.0240000000000005e-06     evaluation reward: 10.24\n",
      "episode: 2316   score: 9.0   memory length: 694188   epsilon: 0.009998020008555413    steps: 459    lr: 1.0240000000000005e-06     evaluation reward: 10.23\n",
      "episode: 2317   score: 7.0   memory length: 694575   epsilon: 0.009998020008555413    steps: 387    lr: 1.0240000000000005e-06     evaluation reward: 10.21\n",
      "episode: 2318   score: 13.0   memory length: 695191   epsilon: 0.009998020008555413    steps: 616    lr: 1.0240000000000005e-06     evaluation reward: 10.26\n",
      "episode: 2319   score: 9.0   memory length: 695650   epsilon: 0.009998020008555413    steps: 459    lr: 1.0240000000000005e-06     evaluation reward: 10.26\n",
      "episode: 2320   score: 10.0   memory length: 696184   epsilon: 0.009998020008555413    steps: 534    lr: 1.0240000000000005e-06     evaluation reward: 10.28\n",
      "episode: 2321   score: 9.0   memory length: 696643   epsilon: 0.009998020008555413    steps: 459    lr: 1.0240000000000005e-06     evaluation reward: 10.29\n",
      "episode: 2322   score: 9.0   memory length: 697164   epsilon: 0.009998020008555413    steps: 521    lr: 1.0240000000000005e-06     evaluation reward: 10.28\n",
      "episode: 2323   score: 11.0   memory length: 697695   epsilon: 0.009998020008555413    steps: 531    lr: 1.0240000000000005e-06     evaluation reward: 10.31\n",
      "episode: 2324   score: 8.0   memory length: 698147   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 10.21\n",
      "episode: 2325   score: 8.0   memory length: 698622   epsilon: 0.009998020008555413    steps: 475    lr: 1.0240000000000005e-06     evaluation reward: 10.19\n",
      "episode: 2326   score: 10.0   memory length: 699105   epsilon: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     evaluation reward: 10.19\n",
      "episode: 2327   score: 11.0   memory length: 699602   epsilon: 0.009998020008555413    steps: 497    lr: 1.0240000000000005e-06     evaluation reward: 10.23\n",
      "episode: 2328   score: 9.0   memory length: 700073   epsilon: 0.009998020008555413    steps: 471    lr: 4.0960000000000023e-07     evaluation reward: 10.21\n",
      "episode: 2329   score: 8.0   memory length: 700496   epsilon: 0.009998020008555413    steps: 423    lr: 4.0960000000000023e-07     evaluation reward: 10.19\n",
      "episode: 2330   score: 16.0   memory length: 701099   epsilon: 0.009998020008555413    steps: 603    lr: 4.0960000000000023e-07     evaluation reward: 10.19\n",
      "episode: 2331   score: 10.0   memory length: 701605   epsilon: 0.009998020008555413    steps: 506    lr: 4.0960000000000023e-07     evaluation reward: 10.17\n",
      "episode: 2332   score: 8.0   memory length: 702039   epsilon: 0.009998020008555413    steps: 434    lr: 4.0960000000000023e-07     evaluation reward: 10.17\n",
      "episode: 2333   score: 10.0   memory length: 702573   epsilon: 0.009998020008555413    steps: 534    lr: 4.0960000000000023e-07     evaluation reward: 10.11\n",
      "episode: 2334   score: 9.0   memory length: 703044   epsilon: 0.009998020008555413    steps: 471    lr: 4.0960000000000023e-07     evaluation reward: 10.1\n",
      "episode: 2335   score: 9.0   memory length: 703515   epsilon: 0.009998020008555413    steps: 471    lr: 4.0960000000000023e-07     evaluation reward: 10.1\n",
      "episode: 2336   score: 10.0   memory length: 704049   epsilon: 0.009998020008555413    steps: 534    lr: 4.0960000000000023e-07     evaluation reward: 10.1\n",
      "episode: 2337   score: 10.0   memory length: 704542   epsilon: 0.009998020008555413    steps: 493    lr: 4.0960000000000023e-07     evaluation reward: 10.09\n",
      "episode: 2338   score: 9.0   memory length: 705000   epsilon: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     evaluation reward: 10.11\n",
      "episode: 2339   score: 7.0   memory length: 705382   epsilon: 0.009998020008555413    steps: 382    lr: 4.0960000000000023e-07     evaluation reward: 10.11\n",
      "episode: 2340   score: 13.0   memory length: 705892   epsilon: 0.009998020008555413    steps: 510    lr: 4.0960000000000023e-07     evaluation reward: 10.14\n",
      "episode: 2341   score: 11.0   memory length: 706448   epsilon: 0.009998020008555413    steps: 556    lr: 4.0960000000000023e-07     evaluation reward: 10.15\n",
      "episode: 2342   score: 9.0   memory length: 706905   epsilon: 0.009998020008555413    steps: 457    lr: 4.0960000000000023e-07     evaluation reward: 10.15\n",
      "episode: 2343   score: 10.0   memory length: 707439   epsilon: 0.009998020008555413    steps: 534    lr: 4.0960000000000023e-07     evaluation reward: 10.16\n",
      "episode: 2344   score: 11.0   memory length: 707995   epsilon: 0.009998020008555413    steps: 556    lr: 4.0960000000000023e-07     evaluation reward: 10.16\n",
      "episode: 2345   score: 9.0   memory length: 708451   epsilon: 0.009998020008555413    steps: 456    lr: 4.0960000000000023e-07     evaluation reward: 10.08\n",
      "episode: 2346   score: 10.0   memory length: 708965   epsilon: 0.009998020008555413    steps: 514    lr: 4.0960000000000023e-07     evaluation reward: 10.0\n",
      "episode: 2347   score: 8.0   memory length: 709399   epsilon: 0.009998020008555413    steps: 434    lr: 4.0960000000000023e-07     evaluation reward: 9.9\n",
      "episode: 2348   score: 10.0   memory length: 709904   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.9\n",
      "episode: 2349   score: 9.0   memory length: 710375   epsilon: 0.009998020008555413    steps: 471    lr: 4.0960000000000023e-07     evaluation reward: 9.89\n",
      "episode: 2350   score: 10.0   memory length: 710880   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.89\n",
      "episode: 2351   score: 10.0   memory length: 711367   epsilon: 0.009998020008555413    steps: 487    lr: 4.0960000000000023e-07     evaluation reward: 9.9\n",
      "episode: 2352   score: 9.0   memory length: 711824   epsilon: 0.009998020008555413    steps: 457    lr: 4.0960000000000023e-07     evaluation reward: 9.91\n",
      "episode: 2353   score: 9.0   memory length: 712326   epsilon: 0.009998020008555413    steps: 502    lr: 4.0960000000000023e-07     evaluation reward: 9.91\n",
      "episode: 2354   score: 11.0   memory length: 712881   epsilon: 0.009998020008555413    steps: 555    lr: 4.0960000000000023e-07     evaluation reward: 9.98\n",
      "episode: 2355   score: 9.0   memory length: 713339   epsilon: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     evaluation reward: 9.95\n",
      "episode: 2356   score: 9.0   memory length: 713798   epsilon: 0.009998020008555413    steps: 459    lr: 4.0960000000000023e-07     evaluation reward: 9.95\n",
      "episode: 2357   score: 10.0   memory length: 714303   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.86\n",
      "episode: 2358   score: 7.0   memory length: 714685   epsilon: 0.009998020008555413    steps: 382    lr: 4.0960000000000023e-07     evaluation reward: 9.75\n",
      "episode: 2359   score: 9.0   memory length: 715143   epsilon: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     evaluation reward: 9.77\n",
      "episode: 2360   score: 9.0   memory length: 715601   epsilon: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     evaluation reward: 9.76\n",
      "episode: 2361   score: 9.0   memory length: 716060   epsilon: 0.009998020008555413    steps: 459    lr: 4.0960000000000023e-07     evaluation reward: 9.77\n",
      "episode: 2362   score: 9.0   memory length: 716518   epsilon: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     evaluation reward: 9.76\n",
      "episode: 2363   score: 11.0   memory length: 717107   epsilon: 0.009998020008555413    steps: 589    lr: 4.0960000000000023e-07     evaluation reward: 9.69\n",
      "episode: 2364   score: 9.0   memory length: 717566   epsilon: 0.009998020008555413    steps: 459    lr: 4.0960000000000023e-07     evaluation reward: 9.66\n",
      "episode: 2365   score: 8.0   memory length: 717972   epsilon: 0.009998020008555413    steps: 406    lr: 4.0960000000000023e-07     evaluation reward: 9.66\n",
      "episode: 2366   score: 11.0   memory length: 718561   epsilon: 0.009998020008555413    steps: 589    lr: 4.0960000000000023e-07     evaluation reward: 9.68\n",
      "episode: 2367   score: 9.0   memory length: 719019   epsilon: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     evaluation reward: 9.67\n",
      "episode: 2368   score: 9.0   memory length: 719478   epsilon: 0.009998020008555413    steps: 459    lr: 4.0960000000000023e-07     evaluation reward: 9.67\n",
      "episode: 2369   score: 10.0   memory length: 719983   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.67\n",
      "episode: 2370   score: 10.0   memory length: 720465   epsilon: 0.009998020008555413    steps: 482    lr: 4.0960000000000023e-07     evaluation reward: 9.65\n",
      "episode: 2371   score: 11.0   memory length: 721010   epsilon: 0.009998020008555413    steps: 545    lr: 4.0960000000000023e-07     evaluation reward: 9.67\n",
      "episode: 2372   score: 10.0   memory length: 721515   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.69\n",
      "episode: 2373   score: 10.0   memory length: 722020   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.69\n",
      "episode: 2374   score: 13.0   memory length: 722558   epsilon: 0.009998020008555413    steps: 538    lr: 4.0960000000000023e-07     evaluation reward: 9.73\n",
      "episode: 2375   score: 10.0   memory length: 723063   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.64\n",
      "episode: 2376   score: 10.0   memory length: 723553   epsilon: 0.009998020008555413    steps: 490    lr: 4.0960000000000023e-07     evaluation reward: 9.65\n",
      "episode: 2377   score: 10.0   memory length: 724077   epsilon: 0.009998020008555413    steps: 524    lr: 4.0960000000000023e-07     evaluation reward: 9.66\n",
      "episode: 2378   score: 10.0   memory length: 724582   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.68\n",
      "episode: 2379   score: 9.0   memory length: 725062   epsilon: 0.009998020008555413    steps: 480    lr: 4.0960000000000023e-07     evaluation reward: 9.69\n",
      "episode: 2380   score: 10.0   memory length: 725586   epsilon: 0.009998020008555413    steps: 524    lr: 4.0960000000000023e-07     evaluation reward: 9.71\n",
      "episode: 2381   score: 10.0   memory length: 726091   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.73\n",
      "episode: 2382   score: 9.0   memory length: 726593   epsilon: 0.009998020008555413    steps: 502    lr: 4.0960000000000023e-07     evaluation reward: 9.74\n",
      "episode: 2383   score: 9.0   memory length: 727080   epsilon: 0.009998020008555413    steps: 487    lr: 4.0960000000000023e-07     evaluation reward: 9.73\n",
      "episode: 2384   score: 10.0   memory length: 727585   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.74\n",
      "episode: 2385   score: 10.0   memory length: 728090   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.73\n",
      "episode: 2386   score: 10.0   memory length: 728594   epsilon: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     evaluation reward: 9.75\n",
      "episode: 2387   score: 9.0   memory length: 729049   epsilon: 0.009998020008555413    steps: 455    lr: 4.0960000000000023e-07     evaluation reward: 9.75\n",
      "episode: 2388   score: 16.0   memory length: 729652   epsilon: 0.009998020008555413    steps: 603    lr: 4.0960000000000023e-07     evaluation reward: 9.81\n",
      "episode: 2389   score: 13.0   memory length: 730162   epsilon: 0.009998020008555413    steps: 510    lr: 4.0960000000000023e-07     evaluation reward: 9.86\n",
      "episode: 2390   score: 11.0   memory length: 730712   epsilon: 0.009998020008555413    steps: 550    lr: 4.0960000000000023e-07     evaluation reward: 9.88\n",
      "episode: 2391   score: 9.0   memory length: 731192   epsilon: 0.009998020008555413    steps: 480    lr: 4.0960000000000023e-07     evaluation reward: 9.88\n",
      "episode: 2392   score: 10.0   memory length: 731687   epsilon: 0.009998020008555413    steps: 495    lr: 4.0960000000000023e-07     evaluation reward: 9.9\n",
      "episode: 2393   score: 9.0   memory length: 732189   epsilon: 0.009998020008555413    steps: 502    lr: 4.0960000000000023e-07     evaluation reward: 9.88\n",
      "episode: 2394   score: 11.0   memory length: 732720   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 9.9\n",
      "episode: 2395   score: 8.0   memory length: 733125   epsilon: 0.009998020008555413    steps: 405    lr: 4.0960000000000023e-07     evaluation reward: 9.81\n",
      "episode: 2396   score: 11.0   memory length: 733710   epsilon: 0.009998020008555413    steps: 585    lr: 4.0960000000000023e-07     evaluation reward: 9.74\n",
      "episode: 2397   score: 10.0   memory length: 734205   epsilon: 0.009998020008555413    steps: 495    lr: 4.0960000000000023e-07     evaluation reward: 9.76\n",
      "episode: 2398   score: 9.0   memory length: 734688   epsilon: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     evaluation reward: 9.77\n",
      "episode: 2399   score: 11.0   memory length: 735219   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 9.79\n",
      "episode: 2400   score: 11.0   memory length: 735750   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 9.82\n",
      "episode: 2401   score: 11.0   memory length: 736281   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 9.85\n",
      "episode: 2402   score: 11.0   memory length: 736812   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 9.85\n",
      "episode: 2403   score: 11.0   memory length: 737343   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 9.88\n",
      "episode: 2404   score: 11.0   memory length: 737874   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 9.9\n",
      "episode: 2405   score: 10.0   memory length: 738357   epsilon: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     evaluation reward: 9.92\n",
      "episode: 2406   score: 11.0   memory length: 738888   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 9.91\n",
      "episode: 2407   score: 8.0   memory length: 739340   epsilon: 0.009998020008555413    steps: 452    lr: 4.0960000000000023e-07     evaluation reward: 9.86\n",
      "episode: 2408   score: 8.0   memory length: 739792   epsilon: 0.009998020008555413    steps: 452    lr: 4.0960000000000023e-07     evaluation reward: 9.85\n",
      "episode: 2409   score: 20.0   memory length: 740399   epsilon: 0.009998020008555413    steps: 607    lr: 4.0960000000000023e-07     evaluation reward: 9.93\n",
      "episode: 2410   score: 11.0   memory length: 740931   epsilon: 0.009998020008555413    steps: 532    lr: 4.0960000000000023e-07     evaluation reward: 9.95\n",
      "episode: 2411   score: 9.0   memory length: 741401   epsilon: 0.009998020008555413    steps: 470    lr: 4.0960000000000023e-07     evaluation reward: 9.96\n",
      "episode: 2412   score: 11.0   memory length: 741932   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 9.97\n",
      "episode: 2413   score: 11.0   memory length: 742464   epsilon: 0.009998020008555413    steps: 532    lr: 4.0960000000000023e-07     evaluation reward: 9.98\n",
      "episode: 2414   score: 8.0   memory length: 742916   epsilon: 0.009998020008555413    steps: 452    lr: 4.0960000000000023e-07     evaluation reward: 9.98\n",
      "episode: 2415   score: 11.0   memory length: 743447   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 9.97\n",
      "episode: 2416   score: 11.0   memory length: 743972   epsilon: 0.009998020008555413    steps: 525    lr: 4.0960000000000023e-07     evaluation reward: 9.99\n",
      "episode: 2417   score: 11.0   memory length: 744557   epsilon: 0.009998020008555413    steps: 585    lr: 4.0960000000000023e-07     evaluation reward: 10.03\n",
      "episode: 2418   score: 13.0   memory length: 745091   epsilon: 0.009998020008555413    steps: 534    lr: 4.0960000000000023e-07     evaluation reward: 10.03\n",
      "episode: 2419   score: 11.0   memory length: 745676   epsilon: 0.009998020008555413    steps: 585    lr: 4.0960000000000023e-07     evaluation reward: 10.05\n",
      "episode: 2420   score: 10.0   memory length: 746159   epsilon: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     evaluation reward: 10.05\n",
      "episode: 2421   score: 10.0   memory length: 746663   epsilon: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     evaluation reward: 10.06\n",
      "episode: 2422   score: 10.0   memory length: 747184   epsilon: 0.009998020008555413    steps: 521    lr: 4.0960000000000023e-07     evaluation reward: 10.07\n",
      "episode: 2423   score: 9.0   memory length: 747670   epsilon: 0.009998020008555413    steps: 486    lr: 4.0960000000000023e-07     evaluation reward: 10.05\n",
      "episode: 2424   score: 11.0   memory length: 748239   epsilon: 0.009998020008555413    steps: 569    lr: 4.0960000000000023e-07     evaluation reward: 10.08\n",
      "episode: 2425   score: 10.0   memory length: 748744   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 10.1\n",
      "episode: 2426   score: 10.0   memory length: 749227   epsilon: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     evaluation reward: 10.1\n",
      "episode: 2427   score: 9.0   memory length: 749684   epsilon: 0.009998020008555413    steps: 457    lr: 4.0960000000000023e-07     evaluation reward: 10.08\n",
      "episode: 2428   score: 11.0   memory length: 750215   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.1\n",
      "episode: 2429   score: 10.0   memory length: 750720   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 10.12\n",
      "episode: 2430   score: 11.0   memory length: 751251   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.07\n",
      "episode: 2431   score: 11.0   memory length: 751748   epsilon: 0.009998020008555413    steps: 497    lr: 4.0960000000000023e-07     evaluation reward: 10.08\n",
      "episode: 2432   score: 12.0   memory length: 752304   epsilon: 0.009998020008555413    steps: 556    lr: 4.0960000000000023e-07     evaluation reward: 10.12\n",
      "episode: 2433   score: 11.0   memory length: 752859   epsilon: 0.009998020008555413    steps: 555    lr: 4.0960000000000023e-07     evaluation reward: 10.13\n",
      "episode: 2434   score: 10.0   memory length: 753363   epsilon: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     evaluation reward: 10.14\n",
      "episode: 2435   score: 11.0   memory length: 753921   epsilon: 0.009998020008555413    steps: 558    lr: 4.0960000000000023e-07     evaluation reward: 10.16\n",
      "episode: 2436   score: 10.0   memory length: 754425   epsilon: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     evaluation reward: 10.16\n",
      "episode: 2437   score: 10.0   memory length: 754929   epsilon: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     evaluation reward: 10.16\n",
      "episode: 2438   score: 10.0   memory length: 755433   epsilon: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     evaluation reward: 10.17\n",
      "episode: 2439   score: 6.0   memory length: 755808   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 10.16\n",
      "episode: 2440   score: 11.0   memory length: 756339   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.14\n",
      "episode: 2441   score: 11.0   memory length: 756870   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.14\n",
      "episode: 2442   score: 11.0   memory length: 757401   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.16\n",
      "episode: 2443   score: 12.0   memory length: 757956   epsilon: 0.009998020008555413    steps: 555    lr: 4.0960000000000023e-07     evaluation reward: 10.18\n",
      "episode: 2444   score: 11.0   memory length: 758487   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.18\n",
      "episode: 2445   score: 9.0   memory length: 758973   epsilon: 0.009998020008555413    steps: 486    lr: 4.0960000000000023e-07     evaluation reward: 10.18\n",
      "episode: 2446   score: 11.0   memory length: 759504   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.19\n",
      "episode: 2447   score: 15.0   memory length: 760073   epsilon: 0.009998020008555413    steps: 569    lr: 4.0960000000000023e-07     evaluation reward: 10.26\n",
      "episode: 2448   score: 15.0   memory length: 760642   epsilon: 0.009998020008555413    steps: 569    lr: 4.0960000000000023e-07     evaluation reward: 10.31\n",
      "episode: 2449   score: 15.0   memory length: 761211   epsilon: 0.009998020008555413    steps: 569    lr: 4.0960000000000023e-07     evaluation reward: 10.37\n",
      "episode: 2450   score: 12.0   memory length: 761785   epsilon: 0.009998020008555413    steps: 574    lr: 4.0960000000000023e-07     evaluation reward: 10.39\n",
      "episode: 2451   score: 8.0   memory length: 762216   epsilon: 0.009998020008555413    steps: 431    lr: 4.0960000000000023e-07     evaluation reward: 10.37\n",
      "episode: 2452   score: 9.0   memory length: 762701   epsilon: 0.009998020008555413    steps: 485    lr: 4.0960000000000023e-07     evaluation reward: 10.37\n",
      "episode: 2453   score: 10.0   memory length: 763166   epsilon: 0.009998020008555413    steps: 465    lr: 4.0960000000000023e-07     evaluation reward: 10.38\n",
      "episode: 2454   score: 10.0   memory length: 763670   epsilon: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     evaluation reward: 10.37\n",
      "episode: 2455   score: 6.0   memory length: 764045   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 10.34\n",
      "episode: 2456   score: 9.0   memory length: 764503   epsilon: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     evaluation reward: 10.34\n",
      "episode: 2457   score: 11.0   memory length: 765058   epsilon: 0.009998020008555413    steps: 555    lr: 4.0960000000000023e-07     evaluation reward: 10.35\n",
      "episode: 2458   score: 16.0   memory length: 765660   epsilon: 0.009998020008555413    steps: 602    lr: 4.0960000000000023e-07     evaluation reward: 10.44\n",
      "episode: 2459   score: 9.0   memory length: 766116   epsilon: 0.009998020008555413    steps: 456    lr: 4.0960000000000023e-07     evaluation reward: 10.44\n",
      "episode: 2460   score: 8.0   memory length: 766547   epsilon: 0.009998020008555413    steps: 431    lr: 4.0960000000000023e-07     evaluation reward: 10.43\n",
      "episode: 2461   score: 11.0   memory length: 767101   epsilon: 0.009998020008555413    steps: 554    lr: 4.0960000000000023e-07     evaluation reward: 10.45\n",
      "episode: 2462   score: 11.0   memory length: 767562   epsilon: 0.009998020008555413    steps: 461    lr: 4.0960000000000023e-07     evaluation reward: 10.47\n",
      "episode: 2463   score: 10.0   memory length: 768008   epsilon: 0.009998020008555413    steps: 446    lr: 4.0960000000000023e-07     evaluation reward: 10.46\n",
      "episode: 2464   score: 11.0   memory length: 768539   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.48\n",
      "episode: 2465   score: 11.0   memory length: 769097   epsilon: 0.009998020008555413    steps: 558    lr: 4.0960000000000023e-07     evaluation reward: 10.51\n",
      "episode: 2466   score: 11.0   memory length: 769651   epsilon: 0.009998020008555413    steps: 554    lr: 4.0960000000000023e-07     evaluation reward: 10.51\n",
      "episode: 2467   score: 8.0   memory length: 770064   epsilon: 0.009998020008555413    steps: 413    lr: 4.0960000000000023e-07     evaluation reward: 10.5\n",
      "episode: 2468   score: 8.0   memory length: 770495   epsilon: 0.009998020008555413    steps: 431    lr: 4.0960000000000023e-07     evaluation reward: 10.49\n",
      "episode: 2469   score: 11.0   memory length: 771026   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.5\n",
      "episode: 2470   score: 8.0   memory length: 771460   epsilon: 0.009998020008555413    steps: 434    lr: 4.0960000000000023e-07     evaluation reward: 10.48\n",
      "episode: 2471   score: 9.0   memory length: 771916   epsilon: 0.009998020008555413    steps: 456    lr: 4.0960000000000023e-07     evaluation reward: 10.46\n",
      "episode: 2472   score: 10.0   memory length: 772421   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 10.46\n",
      "episode: 2473   score: 6.0   memory length: 772796   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 10.42\n",
      "episode: 2474   score: 11.0   memory length: 773312   epsilon: 0.009998020008555413    steps: 516    lr: 4.0960000000000023e-07     evaluation reward: 10.4\n",
      "episode: 2475   score: 6.0   memory length: 773687   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 10.36\n",
      "episode: 2476   score: 10.0   memory length: 774150   epsilon: 0.009998020008555413    steps: 463    lr: 4.0960000000000023e-07     evaluation reward: 10.36\n",
      "episode: 2477   score: 10.0   memory length: 774613   epsilon: 0.009998020008555413    steps: 463    lr: 4.0960000000000023e-07     evaluation reward: 10.36\n",
      "episode: 2478   score: 11.0   memory length: 775144   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.37\n",
      "episode: 2479   score: 8.0   memory length: 775575   epsilon: 0.009998020008555413    steps: 431    lr: 4.0960000000000023e-07     evaluation reward: 10.36\n",
      "episode: 2480   score: 9.0   memory length: 776039   epsilon: 0.009998020008555413    steps: 464    lr: 4.0960000000000023e-07     evaluation reward: 10.35\n",
      "episode: 2481   score: 11.0   memory length: 776570   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.36\n",
      "episode: 2482   score: 11.0   memory length: 777101   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.38\n",
      "episode: 2483   score: 11.0   memory length: 777632   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.4\n",
      "episode: 2484   score: 10.0   memory length: 778115   epsilon: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     evaluation reward: 10.4\n",
      "episode: 2485   score: 10.0   memory length: 778598   epsilon: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     evaluation reward: 10.4\n",
      "episode: 2486   score: 11.0   memory length: 779129   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.41\n",
      "episode: 2487   score: 11.0   memory length: 779661   epsilon: 0.009998020008555413    steps: 532    lr: 4.0960000000000023e-07     evaluation reward: 10.43\n",
      "episode: 2488   score: 9.0   memory length: 780163   epsilon: 0.009998020008555413    steps: 502    lr: 4.0960000000000023e-07     evaluation reward: 10.36\n",
      "episode: 2489   score: 8.0   memory length: 780597   epsilon: 0.009998020008555413    steps: 434    lr: 4.0960000000000023e-07     evaluation reward: 10.31\n",
      "episode: 2490   score: 9.0   memory length: 781060   epsilon: 0.009998020008555413    steps: 463    lr: 4.0960000000000023e-07     evaluation reward: 10.29\n",
      "episode: 2491   score: 11.0   memory length: 781591   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.31\n",
      "episode: 2492   score: 9.0   memory length: 782054   epsilon: 0.009998020008555413    steps: 463    lr: 4.0960000000000023e-07     evaluation reward: 10.3\n",
      "episode: 2493   score: 11.0   memory length: 782585   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.32\n",
      "episode: 2494   score: 7.0   memory length: 783012   epsilon: 0.009998020008555413    steps: 427    lr: 4.0960000000000023e-07     evaluation reward: 10.28\n",
      "episode: 2495   score: 11.0   memory length: 783543   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 10.31\n",
      "episode: 2496   score: 9.0   memory length: 784007   epsilon: 0.009998020008555413    steps: 464    lr: 4.0960000000000023e-07     evaluation reward: 10.29\n",
      "episode: 2497   score: 11.0   memory length: 784504   epsilon: 0.009998020008555413    steps: 497    lr: 4.0960000000000023e-07     evaluation reward: 10.3\n",
      "episode: 2498   score: 10.0   memory length: 784967   epsilon: 0.009998020008555413    steps: 463    lr: 4.0960000000000023e-07     evaluation reward: 10.31\n",
      "episode: 2499   score: 10.0   memory length: 785430   epsilon: 0.009998020008555413    steps: 463    lr: 4.0960000000000023e-07     evaluation reward: 10.3\n",
      "episode: 2500   score: 10.0   memory length: 785913   epsilon: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     evaluation reward: 10.29\n",
      "episode: 2501   score: 9.0   memory length: 786374   epsilon: 0.009998020008555413    steps: 461    lr: 4.0960000000000023e-07     evaluation reward: 10.27\n",
      "episode: 2502   score: 6.0   memory length: 786749   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 10.22\n",
      "episode: 2503   score: 7.0   memory length: 787177   epsilon: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     evaluation reward: 10.18\n",
      "episode: 2504   score: 11.0   memory length: 787674   epsilon: 0.009998020008555413    steps: 497    lr: 4.0960000000000023e-07     evaluation reward: 10.18\n",
      "episode: 2505   score: 15.0   memory length: 788243   epsilon: 0.009998020008555413    steps: 569    lr: 4.0960000000000023e-07     evaluation reward: 10.23\n",
      "episode: 2506   score: 10.0   memory length: 788726   epsilon: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     evaluation reward: 10.22\n",
      "episode: 2507   score: 11.0   memory length: 789258   epsilon: 0.009998020008555413    steps: 532    lr: 4.0960000000000023e-07     evaluation reward: 10.25\n",
      "episode: 2508   score: 8.0   memory length: 789692   epsilon: 0.009998020008555413    steps: 434    lr: 4.0960000000000023e-07     evaluation reward: 10.25\n",
      "episode: 2509   score: 7.0   memory length: 790120   epsilon: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     evaluation reward: 10.12\n",
      "episode: 2510   score: 6.0   memory length: 790495   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 10.07\n",
      "episode: 2511   score: 6.0   memory length: 790870   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 10.04\n",
      "episode: 2512   score: 7.0   memory length: 791319   epsilon: 0.009998020008555413    steps: 449    lr: 4.0960000000000023e-07     evaluation reward: 10.0\n",
      "episode: 2513   score: 7.0   memory length: 791747   epsilon: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     evaluation reward: 9.96\n",
      "episode: 2514   score: 7.0   memory length: 792174   epsilon: 0.009998020008555413    steps: 427    lr: 4.0960000000000023e-07     evaluation reward: 9.95\n",
      "episode: 2515   score: 11.0   memory length: 792723   epsilon: 0.009998020008555413    steps: 549    lr: 4.0960000000000023e-07     evaluation reward: 9.95\n",
      "episode: 2516   score: 7.0   memory length: 793172   epsilon: 0.009998020008555413    steps: 449    lr: 4.0960000000000023e-07     evaluation reward: 9.91\n",
      "episode: 2517   score: 6.0   memory length: 793547   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 9.86\n",
      "episode: 2518   score: 7.0   memory length: 793948   epsilon: 0.009998020008555413    steps: 401    lr: 4.0960000000000023e-07     evaluation reward: 9.8\n",
      "episode: 2519   score: 8.0   memory length: 794381   epsilon: 0.009998020008555413    steps: 433    lr: 4.0960000000000023e-07     evaluation reward: 9.77\n",
      "episode: 2520   score: 7.0   memory length: 794787   epsilon: 0.009998020008555413    steps: 406    lr: 4.0960000000000023e-07     evaluation reward: 9.74\n",
      "episode: 2521   score: 10.0   memory length: 795321   epsilon: 0.009998020008555413    steps: 534    lr: 4.0960000000000023e-07     evaluation reward: 9.74\n",
      "episode: 2522   score: 6.0   memory length: 795698   epsilon: 0.009998020008555413    steps: 377    lr: 4.0960000000000023e-07     evaluation reward: 9.7\n",
      "episode: 2523   score: 7.0   memory length: 796147   epsilon: 0.009998020008555413    steps: 449    lr: 4.0960000000000023e-07     evaluation reward: 9.68\n",
      "episode: 2524   score: 8.0   memory length: 796604   epsilon: 0.009998020008555413    steps: 457    lr: 4.0960000000000023e-07     evaluation reward: 9.65\n",
      "episode: 2525   score: 7.0   memory length: 797031   epsilon: 0.009998020008555413    steps: 427    lr: 4.0960000000000023e-07     evaluation reward: 9.62\n",
      "episode: 2526   score: 8.0   memory length: 797465   epsilon: 0.009998020008555413    steps: 434    lr: 4.0960000000000023e-07     evaluation reward: 9.6\n",
      "episode: 2527   score: 6.0   memory length: 797840   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 9.57\n",
      "episode: 2528   score: 7.0   memory length: 798268   epsilon: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     evaluation reward: 9.53\n",
      "episode: 2529   score: 7.0   memory length: 798696   epsilon: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     evaluation reward: 9.5\n",
      "episode: 2530   score: 7.0   memory length: 799124   epsilon: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     evaluation reward: 9.46\n",
      "episode: 2531   score: 6.0   memory length: 799499   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 9.41\n",
      "episode: 2532   score: 9.0   memory length: 800005   epsilon: 0.009998020008555413    steps: 506    lr: 1.638400000000001e-07     evaluation reward: 9.38\n",
      "episode: 2533   score: 7.0   memory length: 800433   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 9.34\n",
      "episode: 2534   score: 7.0   memory length: 800861   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 9.31\n",
      "episode: 2535   score: 7.0   memory length: 801289   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 9.27\n",
      "episode: 2536   score: 15.0   memory length: 801893   epsilon: 0.009998020008555413    steps: 604    lr: 1.638400000000001e-07     evaluation reward: 9.32\n",
      "episode: 2537   score: 7.0   memory length: 802321   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 9.29\n",
      "episode: 2538   score: 7.0   memory length: 802749   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 9.26\n",
      "episode: 2539   score: 7.0   memory length: 803177   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 9.27\n",
      "episode: 2540   score: 7.0   memory length: 803605   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 9.23\n",
      "episode: 2541   score: 9.0   memory length: 804060   epsilon: 0.009998020008555413    steps: 455    lr: 1.638400000000001e-07     evaluation reward: 9.21\n",
      "episode: 2542   score: 12.0   memory length: 804503   epsilon: 0.009998020008555413    steps: 443    lr: 1.638400000000001e-07     evaluation reward: 9.22\n",
      "episode: 2543   score: 7.0   memory length: 804931   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 9.17\n",
      "episode: 2544   score: 7.0   memory length: 805359   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 9.13\n",
      "episode: 2545   score: 14.0   memory length: 805967   epsilon: 0.009998020008555413    steps: 608    lr: 1.638400000000001e-07     evaluation reward: 9.18\n",
      "episode: 2546   score: 7.0   memory length: 806395   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 9.14\n",
      "episode: 2547   score: 12.0   memory length: 806950   epsilon: 0.009998020008555413    steps: 555    lr: 1.638400000000001e-07     evaluation reward: 9.11\n",
      "episode: 2548   score: 8.0   memory length: 807427   epsilon: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     evaluation reward: 9.04\n",
      "episode: 2549   score: 7.0   memory length: 807876   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.96\n",
      "episode: 2550   score: 7.0   memory length: 808325   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.91\n",
      "episode: 2551   score: 6.0   memory length: 808700   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.89\n",
      "episode: 2552   score: 7.0   memory length: 809128   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.87\n",
      "episode: 2553   score: 7.0   memory length: 809556   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.84\n",
      "episode: 2554   score: 7.0   memory length: 809984   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.81\n",
      "episode: 2555   score: 6.0   memory length: 810357   epsilon: 0.009998020008555413    steps: 373    lr: 1.638400000000001e-07     evaluation reward: 8.81\n",
      "episode: 2556   score: 10.0   memory length: 810866   epsilon: 0.009998020008555413    steps: 509    lr: 1.638400000000001e-07     evaluation reward: 8.82\n",
      "episode: 2557   score: 10.0   memory length: 811400   epsilon: 0.009998020008555413    steps: 534    lr: 1.638400000000001e-07     evaluation reward: 8.81\n",
      "episode: 2558   score: 8.0   memory length: 811859   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 8.73\n",
      "episode: 2559   score: 10.0   memory length: 812368   epsilon: 0.009998020008555413    steps: 509    lr: 1.638400000000001e-07     evaluation reward: 8.74\n",
      "episode: 2560   score: 10.0   memory length: 812877   epsilon: 0.009998020008555413    steps: 509    lr: 1.638400000000001e-07     evaluation reward: 8.76\n",
      "episode: 2561   score: 10.0   memory length: 813411   epsilon: 0.009998020008555413    steps: 534    lr: 1.638400000000001e-07     evaluation reward: 8.75\n",
      "episode: 2562   score: 7.0   memory length: 813839   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.71\n",
      "episode: 2563   score: 7.0   memory length: 814288   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.68\n",
      "episode: 2564   score: 7.0   memory length: 814716   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.64\n",
      "episode: 2565   score: 7.0   memory length: 815165   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.6\n",
      "episode: 2566   score: 7.0   memory length: 815614   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.56\n",
      "episode: 2567   score: 7.0   memory length: 816042   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.55\n",
      "episode: 2568   score: 7.0   memory length: 816491   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.54\n",
      "episode: 2569   score: 7.0   memory length: 816919   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.5\n",
      "episode: 2570   score: 7.0   memory length: 817346   epsilon: 0.009998020008555413    steps: 427    lr: 1.638400000000001e-07     evaluation reward: 8.49\n",
      "episode: 2571   score: 7.0   memory length: 817773   epsilon: 0.009998020008555413    steps: 427    lr: 1.638400000000001e-07     evaluation reward: 8.47\n",
      "episode: 2572   score: 7.0   memory length: 818222   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.44\n",
      "episode: 2573   score: 7.0   memory length: 818671   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.45\n",
      "episode: 2574   score: 7.0   memory length: 819099   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.41\n",
      "episode: 2575   score: 7.0   memory length: 819505   epsilon: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     evaluation reward: 8.42\n",
      "episode: 2576   score: 7.0   memory length: 819933   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.39\n",
      "episode: 2577   score: 7.0   memory length: 820382   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.36\n",
      "episode: 2578   score: 7.0   memory length: 820831   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.32\n",
      "episode: 2579   score: 7.0   memory length: 821280   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.31\n",
      "episode: 2580   score: 6.0   memory length: 821655   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.28\n",
      "episode: 2581   score: 11.0   memory length: 822210   epsilon: 0.009998020008555413    steps: 555    lr: 1.638400000000001e-07     evaluation reward: 8.28\n",
      "episode: 2582   score: 8.0   memory length: 822669   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 8.25\n",
      "episode: 2583   score: 6.0   memory length: 823044   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.2\n",
      "episode: 2584   score: 10.0   memory length: 823558   epsilon: 0.009998020008555413    steps: 514    lr: 1.638400000000001e-07     evaluation reward: 8.2\n",
      "episode: 2585   score: 9.0   memory length: 824064   epsilon: 0.009998020008555413    steps: 506    lr: 1.638400000000001e-07     evaluation reward: 8.19\n",
      "episode: 2586   score: 10.0   memory length: 824543   epsilon: 0.009998020008555413    steps: 479    lr: 1.638400000000001e-07     evaluation reward: 8.18\n",
      "episode: 2587   score: 10.0   memory length: 825052   epsilon: 0.009998020008555413    steps: 509    lr: 1.638400000000001e-07     evaluation reward: 8.17\n",
      "episode: 2588   score: 10.0   memory length: 825586   epsilon: 0.009998020008555413    steps: 534    lr: 1.638400000000001e-07     evaluation reward: 8.18\n",
      "episode: 2589   score: 8.0   memory length: 826045   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 8.18\n",
      "episode: 2590   score: 10.0   memory length: 826524   epsilon: 0.009998020008555413    steps: 479    lr: 1.638400000000001e-07     evaluation reward: 8.19\n",
      "episode: 2591   score: 7.0   memory length: 826932   epsilon: 0.009998020008555413    steps: 408    lr: 1.638400000000001e-07     evaluation reward: 8.15\n",
      "episode: 2592   score: 6.0   memory length: 827309   epsilon: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     evaluation reward: 8.12\n",
      "episode: 2593   score: 7.0   memory length: 827737   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.08\n",
      "episode: 2594   score: 6.0   memory length: 828112   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.07\n",
      "episode: 2595   score: 10.0   memory length: 828663   epsilon: 0.009998020008555413    steps: 551    lr: 1.638400000000001e-07     evaluation reward: 8.06\n",
      "episode: 2596   score: 7.0   memory length: 829091   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.04\n",
      "episode: 2597   score: 6.0   memory length: 829468   epsilon: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     evaluation reward: 7.99\n",
      "episode: 2598   score: 6.0   memory length: 829843   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.95\n",
      "episode: 2599   score: 6.0   memory length: 830218   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.91\n",
      "episode: 2600   score: 6.0   memory length: 830595   epsilon: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     evaluation reward: 7.87\n",
      "episode: 2601   score: 11.0   memory length: 831150   epsilon: 0.009998020008555413    steps: 555    lr: 1.638400000000001e-07     evaluation reward: 7.89\n",
      "episode: 2602   score: 6.0   memory length: 831525   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.89\n",
      "episode: 2603   score: 6.0   memory length: 831900   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.88\n",
      "episode: 2604   score: 7.0   memory length: 832349   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.84\n",
      "episode: 2605   score: 6.0   memory length: 832724   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.75\n",
      "episode: 2606   score: 7.0   memory length: 833152   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.72\n",
      "episode: 2607   score: 7.0   memory length: 833601   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.68\n",
      "episode: 2608   score: 6.0   memory length: 833976   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.66\n",
      "episode: 2609   score: 6.0   memory length: 834353   epsilon: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     evaluation reward: 7.65\n",
      "episode: 2610   score: 7.0   memory length: 834802   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.66\n",
      "episode: 2611   score: 7.0   memory length: 835208   epsilon: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2612   score: 6.0   memory length: 835583   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.66\n",
      "episode: 2613   score: 6.0   memory length: 835958   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.65\n",
      "episode: 2614   score: 7.0   memory length: 836407   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.65\n",
      "episode: 2615   score: 7.0   memory length: 836856   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.61\n",
      "episode: 2616   score: 7.0   memory length: 837305   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.61\n",
      "episode: 2617   score: 7.0   memory length: 837733   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.62\n",
      "episode: 2618   score: 7.0   memory length: 838161   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.62\n",
      "episode: 2619   score: 9.0   memory length: 838616   epsilon: 0.009998020008555413    steps: 455    lr: 1.638400000000001e-07     evaluation reward: 7.63\n",
      "episode: 2620   score: 7.0   memory length: 839065   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.63\n",
      "episode: 2621   score: 7.0   memory length: 839514   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.6\n",
      "episode: 2622   score: 7.0   memory length: 839963   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.61\n",
      "episode: 2623   score: 9.0   memory length: 840318   epsilon: 0.009998020008555413    steps: 355    lr: 1.638400000000001e-07     evaluation reward: 7.63\n",
      "episode: 2624   score: 9.0   memory length: 840673   epsilon: 0.009998020008555413    steps: 355    lr: 1.638400000000001e-07     evaluation reward: 7.64\n",
      "episode: 2625   score: 10.0   memory length: 841040   epsilon: 0.009998020008555413    steps: 367    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2626   score: 11.0   memory length: 841571   epsilon: 0.009998020008555413    steps: 531    lr: 1.638400000000001e-07     evaluation reward: 7.7\n",
      "episode: 2627   score: 7.0   memory length: 841999   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.71\n",
      "episode: 2628   score: 6.0   memory length: 842374   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.7\n",
      "episode: 2629   score: 7.0   memory length: 842758   epsilon: 0.009998020008555413    steps: 384    lr: 1.638400000000001e-07     evaluation reward: 7.7\n",
      "episode: 2630   score: 8.0   memory length: 843195   epsilon: 0.009998020008555413    steps: 437    lr: 1.638400000000001e-07     evaluation reward: 7.71\n",
      "episode: 2631   score: 6.0   memory length: 843570   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.71\n",
      "episode: 2632   score: 6.0   memory length: 843945   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.68\n",
      "episode: 2633   score: 7.0   memory length: 844373   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.68\n",
      "episode: 2634   score: 6.0   memory length: 844750   epsilon: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2635   score: 7.0   memory length: 845177   epsilon: 0.009998020008555413    steps: 427    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2636   score: 7.0   memory length: 845605   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.59\n",
      "episode: 2637   score: 6.0   memory length: 845982   epsilon: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     evaluation reward: 7.58\n",
      "episode: 2638   score: 7.0   memory length: 846410   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.58\n",
      "episode: 2639   score: 7.0   memory length: 846838   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.58\n",
      "episode: 2640   score: 12.0   memory length: 847431   epsilon: 0.009998020008555413    steps: 593    lr: 1.638400000000001e-07     evaluation reward: 7.63\n",
      "episode: 2641   score: 7.0   memory length: 847880   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.61\n",
      "episode: 2642   score: 8.0   memory length: 848339   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 7.57\n",
      "episode: 2643   score: 7.0   memory length: 848723   epsilon: 0.009998020008555413    steps: 384    lr: 1.638400000000001e-07     evaluation reward: 7.57\n",
      "episode: 2644   score: 9.0   memory length: 849178   epsilon: 0.009998020008555413    steps: 455    lr: 1.638400000000001e-07     evaluation reward: 7.59\n",
      "episode: 2645   score: 7.0   memory length: 849605   epsilon: 0.009998020008555413    steps: 427    lr: 1.638400000000001e-07     evaluation reward: 7.52\n",
      "episode: 2646   score: 7.0   memory length: 850033   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.52\n",
      "episode: 2647   score: 11.0   memory length: 850588   epsilon: 0.009998020008555413    steps: 555    lr: 1.638400000000001e-07     evaluation reward: 7.51\n",
      "episode: 2648   score: 11.0   memory length: 851119   epsilon: 0.009998020008555413    steps: 531    lr: 1.638400000000001e-07     evaluation reward: 7.54\n",
      "episode: 2649   score: 7.0   memory length: 851547   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.54\n",
      "episode: 2650   score: 6.0   memory length: 851924   epsilon: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     evaluation reward: 7.53\n",
      "episode: 2651   score: 8.0   memory length: 852383   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 7.55\n",
      "episode: 2652   score: 7.0   memory length: 852811   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.55\n",
      "episode: 2653   score: 7.0   memory length: 853239   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.55\n",
      "episode: 2654   score: 8.0   memory length: 853714   epsilon: 0.009998020008555413    steps: 475    lr: 1.638400000000001e-07     evaluation reward: 7.56\n",
      "episode: 2655   score: 12.0   memory length: 854338   epsilon: 0.009998020008555413    steps: 624    lr: 1.638400000000001e-07     evaluation reward: 7.62\n",
      "episode: 2656   score: 7.0   memory length: 854787   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.59\n",
      "episode: 2657   score: 7.0   memory length: 855215   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.56\n",
      "episode: 2658   score: 7.0   memory length: 855599   epsilon: 0.009998020008555413    steps: 384    lr: 1.638400000000001e-07     evaluation reward: 7.55\n",
      "episode: 2659   score: 6.0   memory length: 855976   epsilon: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     evaluation reward: 7.51\n",
      "episode: 2660   score: 7.0   memory length: 856404   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.48\n",
      "episode: 2661   score: 7.0   memory length: 856809   epsilon: 0.009998020008555413    steps: 405    lr: 1.638400000000001e-07     evaluation reward: 7.45\n",
      "episode: 2662   score: 9.0   memory length: 857296   epsilon: 0.009998020008555413    steps: 487    lr: 1.638400000000001e-07     evaluation reward: 7.47\n",
      "episode: 2663   score: 10.0   memory length: 857837   epsilon: 0.009998020008555413    steps: 541    lr: 1.638400000000001e-07     evaluation reward: 7.5\n",
      "episode: 2664   score: 7.0   memory length: 858265   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.5\n",
      "episode: 2665   score: 10.0   memory length: 858766   epsilon: 0.009998020008555413    steps: 501    lr: 1.638400000000001e-07     evaluation reward: 7.53\n",
      "episode: 2666   score: 7.0   memory length: 859194   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.53\n",
      "episode: 2667   score: 10.0   memory length: 859674   epsilon: 0.009998020008555413    steps: 480    lr: 1.638400000000001e-07     evaluation reward: 7.56\n",
      "episode: 2668   score: 7.0   memory length: 860123   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.56\n",
      "episode: 2669   score: 6.0   memory length: 860498   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.55\n",
      "episode: 2670   score: 7.0   memory length: 860882   epsilon: 0.009998020008555413    steps: 384    lr: 1.638400000000001e-07     evaluation reward: 7.55\n",
      "episode: 2671   score: 10.0   memory length: 861455   epsilon: 0.009998020008555413    steps: 573    lr: 1.638400000000001e-07     evaluation reward: 7.58\n",
      "episode: 2672   score: 6.0   memory length: 861830   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.57\n",
      "episode: 2673   score: 11.0   memory length: 862258   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.61\n",
      "episode: 2674   score: 7.0   memory length: 862680   epsilon: 0.009998020008555413    steps: 422    lr: 1.638400000000001e-07     evaluation reward: 7.61\n",
      "episode: 2675   score: 6.0   memory length: 863036   epsilon: 0.009998020008555413    steps: 356    lr: 1.638400000000001e-07     evaluation reward: 7.6\n",
      "episode: 2676   score: 7.0   memory length: 863464   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.6\n",
      "episode: 2677   score: 11.0   memory length: 863995   epsilon: 0.009998020008555413    steps: 531    lr: 1.638400000000001e-07     evaluation reward: 7.64\n",
      "episode: 2678   score: 11.0   memory length: 864526   epsilon: 0.009998020008555413    steps: 531    lr: 1.638400000000001e-07     evaluation reward: 7.68\n",
      "episode: 2679   score: 9.0   memory length: 865008   epsilon: 0.009998020008555413    steps: 482    lr: 1.638400000000001e-07     evaluation reward: 7.7\n",
      "episode: 2680   score: 6.0   memory length: 865383   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.7\n",
      "episode: 2681   score: 16.0   memory length: 866027   epsilon: 0.009998020008555413    steps: 644    lr: 1.638400000000001e-07     evaluation reward: 7.75\n",
      "episode: 2682   score: 6.0   memory length: 866402   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.73\n",
      "episode: 2683   score: 6.0   memory length: 866777   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.73\n",
      "episode: 2684   score: 6.0   memory length: 867152   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.69\n",
      "episode: 2685   score: 10.0   memory length: 867705   epsilon: 0.009998020008555413    steps: 553    lr: 1.638400000000001e-07     evaluation reward: 7.7\n",
      "episode: 2686   score: 6.0   memory length: 868043   epsilon: 0.009998020008555413    steps: 338    lr: 1.638400000000001e-07     evaluation reward: 7.66\n",
      "episode: 2687   score: 16.0   memory length: 868662   epsilon: 0.009998020008555413    steps: 619    lr: 1.638400000000001e-07     evaluation reward: 7.72\n",
      "episode: 2688   score: 8.0   memory length: 869135   epsilon: 0.009998020008555413    steps: 473    lr: 1.638400000000001e-07     evaluation reward: 7.7\n",
      "episode: 2689   score: 8.0   memory length: 869590   epsilon: 0.009998020008555413    steps: 455    lr: 1.638400000000001e-07     evaluation reward: 7.7\n",
      "episode: 2690   score: 8.0   memory length: 870049   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 7.68\n",
      "episode: 2691   score: 7.0   memory length: 870433   epsilon: 0.009998020008555413    steps: 384    lr: 1.638400000000001e-07     evaluation reward: 7.68\n",
      "episode: 2692   score: 7.0   memory length: 870882   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 7.69\n",
      "episode: 2693   score: 6.0   memory length: 871256   epsilon: 0.009998020008555413    steps: 374    lr: 1.638400000000001e-07     evaluation reward: 7.68\n",
      "episode: 2694   score: 8.0   memory length: 871676   epsilon: 0.009998020008555413    steps: 420    lr: 1.638400000000001e-07     evaluation reward: 7.7\n",
      "episode: 2695   score: 7.0   memory length: 872126   epsilon: 0.009998020008555413    steps: 450    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2696   score: 6.0   memory length: 872501   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.66\n",
      "episode: 2697   score: 9.0   memory length: 872963   epsilon: 0.009998020008555413    steps: 462    lr: 1.638400000000001e-07     evaluation reward: 7.69\n",
      "episode: 2698   score: 6.0   memory length: 873338   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.69\n",
      "episode: 2699   score: 9.0   memory length: 873840   epsilon: 0.009998020008555413    steps: 502    lr: 1.638400000000001e-07     evaluation reward: 7.72\n",
      "episode: 2700   score: 11.0   memory length: 874352   epsilon: 0.009998020008555413    steps: 512    lr: 1.638400000000001e-07     evaluation reward: 7.77\n",
      "episode: 2701   score: 11.0   memory length: 874780   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.77\n",
      "episode: 2702   score: 7.0   memory length: 875164   epsilon: 0.009998020008555413    steps: 384    lr: 1.638400000000001e-07     evaluation reward: 7.78\n",
      "episode: 2703   score: 6.0   memory length: 875539   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.78\n",
      "episode: 2704   score: 8.0   memory length: 876016   epsilon: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     evaluation reward: 7.79\n",
      "episode: 2705   score: 7.0   memory length: 876444   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.8\n",
      "episode: 2706   score: 13.0   memory length: 877073   epsilon: 0.009998020008555413    steps: 629    lr: 1.638400000000001e-07     evaluation reward: 7.86\n",
      "episode: 2707   score: 6.0   memory length: 877448   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.85\n",
      "episode: 2708   score: 7.0   memory length: 877876   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.86\n",
      "episode: 2709   score: 7.0   memory length: 878304   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.87\n",
      "episode: 2710   score: 10.0   memory length: 878855   epsilon: 0.009998020008555413    steps: 551    lr: 1.638400000000001e-07     evaluation reward: 7.9\n",
      "episode: 2711   score: 8.0   memory length: 879314   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 7.91\n",
      "episode: 2712   score: 7.0   memory length: 879742   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.92\n",
      "episode: 2713   score: 7.0   memory length: 880170   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.93\n",
      "episode: 2714   score: 14.0   memory length: 880736   epsilon: 0.009998020008555413    steps: 566    lr: 1.638400000000001e-07     evaluation reward: 8.0\n",
      "episode: 2715   score: 7.0   memory length: 881164   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.0\n",
      "episode: 2716   score: 7.0   memory length: 881592   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.0\n",
      "episode: 2717   score: 7.0   memory length: 882020   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.0\n",
      "episode: 2718   score: 7.0   memory length: 882447   epsilon: 0.009998020008555413    steps: 427    lr: 1.638400000000001e-07     evaluation reward: 8.0\n",
      "episode: 2719   score: 7.0   memory length: 882875   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.98\n",
      "episode: 2720   score: 6.0   memory length: 883250   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.97\n",
      "episode: 2721   score: 7.0   memory length: 883678   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.97\n",
      "episode: 2722   score: 11.0   memory length: 884236   epsilon: 0.009998020008555413    steps: 558    lr: 1.638400000000001e-07     evaluation reward: 8.01\n",
      "episode: 2723   score: 7.0   memory length: 884637   epsilon: 0.009998020008555413    steps: 401    lr: 1.638400000000001e-07     evaluation reward: 7.99\n",
      "episode: 2724   score: 7.0   memory length: 885065   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.97\n",
      "episode: 2725   score: 7.0   memory length: 885493   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.94\n",
      "episode: 2726   score: 10.0   memory length: 885975   epsilon: 0.009998020008555413    steps: 482    lr: 1.638400000000001e-07     evaluation reward: 7.93\n",
      "episode: 2727   score: 6.0   memory length: 886350   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 7.92\n",
      "episode: 2728   score: 10.0   memory length: 886849   epsilon: 0.009998020008555413    steps: 499    lr: 1.638400000000001e-07     evaluation reward: 7.96\n",
      "episode: 2729   score: 6.0   memory length: 887203   epsilon: 0.009998020008555413    steps: 354    lr: 1.638400000000001e-07     evaluation reward: 7.95\n",
      "episode: 2730   score: 8.0   memory length: 887661   epsilon: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     evaluation reward: 7.95\n",
      "episode: 2731   score: 13.0   memory length: 888276   epsilon: 0.009998020008555413    steps: 615    lr: 1.638400000000001e-07     evaluation reward: 8.02\n",
      "episode: 2732   score: 14.0   memory length: 888822   epsilon: 0.009998020008555413    steps: 546    lr: 1.638400000000001e-07     evaluation reward: 8.1\n",
      "episode: 2733   score: 6.0   memory length: 889197   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.09\n",
      "episode: 2734   score: 6.0   memory length: 889572   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.09\n",
      "episode: 2735   score: 7.0   memory length: 890021   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.09\n",
      "episode: 2736   score: 9.0   memory length: 890506   epsilon: 0.009998020008555413    steps: 485    lr: 1.638400000000001e-07     evaluation reward: 8.11\n",
      "episode: 2737   score: 11.0   memory length: 891038   epsilon: 0.009998020008555413    steps: 532    lr: 1.638400000000001e-07     evaluation reward: 8.16\n",
      "episode: 2738   score: 12.0   memory length: 891595   epsilon: 0.009998020008555413    steps: 557    lr: 1.638400000000001e-07     evaluation reward: 8.21\n",
      "episode: 2739   score: 6.0   memory length: 891970   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.2\n",
      "episode: 2740   score: 10.0   memory length: 892471   epsilon: 0.009998020008555413    steps: 501    lr: 1.638400000000001e-07     evaluation reward: 8.18\n",
      "episode: 2741   score: 12.0   memory length: 892949   epsilon: 0.009998020008555413    steps: 478    lr: 1.638400000000001e-07     evaluation reward: 8.23\n",
      "episode: 2742   score: 11.0   memory length: 893505   epsilon: 0.009998020008555413    steps: 556    lr: 1.638400000000001e-07     evaluation reward: 8.26\n",
      "episode: 2743   score: 6.0   memory length: 893880   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.25\n",
      "episode: 2744   score: 6.0   memory length: 894255   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.22\n",
      "episode: 2745   score: 6.0   memory length: 894630   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.21\n",
      "episode: 2746   score: 15.0   memory length: 895240   epsilon: 0.009998020008555413    steps: 610    lr: 1.638400000000001e-07     evaluation reward: 8.29\n",
      "episode: 2747   score: 8.0   memory length: 895713   epsilon: 0.009998020008555413    steps: 473    lr: 1.638400000000001e-07     evaluation reward: 8.26\n",
      "episode: 2748   score: 6.0   memory length: 896088   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.21\n",
      "episode: 2749   score: 8.0   memory length: 896545   epsilon: 0.009998020008555413    steps: 457    lr: 1.638400000000001e-07     evaluation reward: 8.22\n",
      "episode: 2750   score: 6.0   memory length: 896920   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.22\n",
      "episode: 2751   score: 6.0   memory length: 897295   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.2\n",
      "episode: 2752   score: 16.0   memory length: 897990   epsilon: 0.009998020008555413    steps: 695    lr: 1.638400000000001e-07     evaluation reward: 8.29\n",
      "episode: 2753   score: 7.0   memory length: 898439   epsilon: 0.009998020008555413    steps: 449    lr: 1.638400000000001e-07     evaluation reward: 8.29\n",
      "episode: 2754   score: 11.0   memory length: 898970   epsilon: 0.009998020008555413    steps: 531    lr: 1.638400000000001e-07     evaluation reward: 8.32\n",
      "episode: 2755   score: 5.0   memory length: 899295   epsilon: 0.009998020008555413    steps: 325    lr: 1.638400000000001e-07     evaluation reward: 8.25\n",
      "episode: 2756   score: 6.0   memory length: 899670   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 8.24\n",
      "episode: 2757   score: 7.0   memory length: 900098   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.24\n",
      "episode: 2758   score: 7.0   memory length: 900526   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.24\n",
      "episode: 2759   score: 6.0   memory length: 900901   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.24\n",
      "episode: 2760   score: 6.0   memory length: 901276   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.23\n",
      "episode: 2761   score: 6.0   memory length: 901651   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.22\n",
      "episode: 2762   score: 6.0   memory length: 902026   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.19\n",
      "episode: 2763   score: 7.0   memory length: 902454   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.16\n",
      "episode: 2764   score: 6.0   memory length: 902829   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.15\n",
      "episode: 2765   score: 10.0   memory length: 903308   epsilon: 0.009998020008555413    steps: 479    lr: 6.553600000000004e-08     evaluation reward: 8.15\n",
      "episode: 2766   score: 6.0   memory length: 903683   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.14\n",
      "episode: 2767   score: 6.0   memory length: 904058   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.1\n",
      "episode: 2768   score: 7.0   memory length: 904467   epsilon: 0.009998020008555413    steps: 409    lr: 6.553600000000004e-08     evaluation reward: 8.1\n",
      "episode: 2769   score: 11.0   memory length: 904964   epsilon: 0.009998020008555413    steps: 497    lr: 6.553600000000004e-08     evaluation reward: 8.15\n",
      "episode: 2770   score: 9.0   memory length: 905426   epsilon: 0.009998020008555413    steps: 462    lr: 6.553600000000004e-08     evaluation reward: 8.17\n",
      "episode: 2771   score: 6.0   memory length: 905801   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.13\n",
      "episode: 2772   score: 12.0   memory length: 906392   epsilon: 0.009998020008555413    steps: 591    lr: 6.553600000000004e-08     evaluation reward: 8.19\n",
      "episode: 2773   score: 8.0   memory length: 906865   epsilon: 0.009998020008555413    steps: 473    lr: 6.553600000000004e-08     evaluation reward: 8.16\n",
      "episode: 2774   score: 7.0   memory length: 907293   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.16\n",
      "episode: 2775   score: 7.0   memory length: 907721   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.17\n",
      "episode: 2776   score: 10.0   memory length: 908200   epsilon: 0.009998020008555413    steps: 479    lr: 6.553600000000004e-08     evaluation reward: 8.2\n",
      "episode: 2777   score: 7.0   memory length: 908628   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.16\n",
      "episode: 2778   score: 7.0   memory length: 909056   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.12\n",
      "episode: 2779   score: 7.0   memory length: 909484   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.1\n",
      "episode: 2780   score: 7.0   memory length: 909911   epsilon: 0.009998020008555413    steps: 427    lr: 6.553600000000004e-08     evaluation reward: 8.11\n",
      "episode: 2781   score: 7.0   memory length: 910339   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.02\n",
      "episode: 2782   score: 7.0   memory length: 910767   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.03\n",
      "episode: 2783   score: 7.0   memory length: 911195   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.04\n",
      "episode: 2784   score: 7.0   memory length: 911623   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.05\n",
      "episode: 2785   score: 7.0   memory length: 912051   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.02\n",
      "episode: 2786   score: 7.0   memory length: 912479   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 8.03\n",
      "episode: 2787   score: 7.0   memory length: 912907   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 7.94\n",
      "episode: 2788   score: 7.0   memory length: 913335   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 7.93\n",
      "episode: 2789   score: 9.0   memory length: 913788   epsilon: 0.009998020008555413    steps: 453    lr: 6.553600000000004e-08     evaluation reward: 7.94\n",
      "episode: 2790   score: 9.0   memory length: 914294   epsilon: 0.009998020008555413    steps: 506    lr: 6.553600000000004e-08     evaluation reward: 7.95\n",
      "episode: 2791   score: 9.0   memory length: 914758   epsilon: 0.009998020008555413    steps: 464    lr: 6.553600000000004e-08     evaluation reward: 7.97\n",
      "episode: 2792   score: 8.0   memory length: 915181   epsilon: 0.009998020008555413    steps: 423    lr: 6.553600000000004e-08     evaluation reward: 7.98\n",
      "episode: 2793   score: 6.0   memory length: 915556   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 7.98\n",
      "episode: 2794   score: 10.0   memory length: 916063   epsilon: 0.009998020008555413    steps: 507    lr: 6.553600000000004e-08     evaluation reward: 8.0\n",
      "episode: 2795   score: 11.0   memory length: 916612   epsilon: 0.009998020008555413    steps: 549    lr: 6.553600000000004e-08     evaluation reward: 8.04\n",
      "episode: 2796   score: 6.0   memory length: 916987   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.04\n",
      "episode: 2797   score: 6.0   memory length: 917362   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.01\n",
      "episode: 2798   score: 6.0   memory length: 917737   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.01\n",
      "episode: 2799   score: 11.0   memory length: 918262   epsilon: 0.009998020008555413    steps: 525    lr: 6.553600000000004e-08     evaluation reward: 8.03\n",
      "episode: 2800   score: 11.0   memory length: 918820   epsilon: 0.009998020008555413    steps: 558    lr: 6.553600000000004e-08     evaluation reward: 8.03\n",
      "episode: 2801   score: 11.0   memory length: 919369   epsilon: 0.009998020008555413    steps: 549    lr: 6.553600000000004e-08     evaluation reward: 8.03\n",
      "episode: 2802   score: 6.0   memory length: 919744   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.02\n",
      "episode: 2803   score: 14.0   memory length: 920398   epsilon: 0.009998020008555413    steps: 654    lr: 6.553600000000004e-08     evaluation reward: 8.1\n",
      "episode: 2804   score: 6.0   memory length: 920773   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.08\n",
      "episode: 2805   score: 8.0   memory length: 921230   epsilon: 0.009998020008555413    steps: 457    lr: 6.553600000000004e-08     evaluation reward: 8.09\n",
      "episode: 2806   score: 6.0   memory length: 921605   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.02\n",
      "episode: 2807   score: 6.0   memory length: 921980   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.02\n",
      "episode: 2808   score: 6.0   memory length: 922355   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.01\n",
      "episode: 2809   score: 6.0   memory length: 922713   epsilon: 0.009998020008555413    steps: 358    lr: 6.553600000000004e-08     evaluation reward: 8.0\n",
      "episode: 2810   score: 6.0   memory length: 923088   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 7.96\n",
      "episode: 2811   score: 6.0   memory length: 923463   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 7.94\n",
      "episode: 2812   score: 6.0   memory length: 923838   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 7.93\n",
      "episode: 2813   score: 11.0   memory length: 924370   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 7.97\n",
      "episode: 2814   score: 8.0   memory length: 924783   epsilon: 0.009998020008555413    steps: 413    lr: 6.553600000000004e-08     evaluation reward: 7.91\n",
      "episode: 2815   score: 11.0   memory length: 925314   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 7.95\n",
      "episode: 2816   score: 11.0   memory length: 925847   epsilon: 0.009998020008555413    steps: 533    lr: 6.553600000000004e-08     evaluation reward: 7.99\n",
      "episode: 2817   score: 15.0   memory length: 926429   epsilon: 0.009998020008555413    steps: 582    lr: 6.553600000000004e-08     evaluation reward: 8.07\n",
      "episode: 2818   score: 11.0   memory length: 926961   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 8.11\n",
      "episode: 2819   score: 11.0   memory length: 927564   epsilon: 0.009998020008555413    steps: 603    lr: 6.553600000000004e-08     evaluation reward: 8.15\n",
      "episode: 2820   score: 13.0   memory length: 928166   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 8.22\n",
      "episode: 2821   score: 11.0   memory length: 928698   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 8.26\n",
      "episode: 2822   score: 17.0   memory length: 929327   epsilon: 0.009998020008555413    steps: 629    lr: 6.553600000000004e-08     evaluation reward: 8.32\n",
      "episode: 2823   score: 10.0   memory length: 929829   epsilon: 0.009998020008555413    steps: 502    lr: 6.553600000000004e-08     evaluation reward: 8.35\n",
      "episode: 2824   score: 10.0   memory length: 930317   epsilon: 0.009998020008555413    steps: 488    lr: 6.553600000000004e-08     evaluation reward: 8.38\n",
      "episode: 2825   score: 12.0   memory length: 930921   epsilon: 0.009998020008555413    steps: 604    lr: 6.553600000000004e-08     evaluation reward: 8.43\n",
      "episode: 2826   score: 6.0   memory length: 931296   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.39\n",
      "episode: 2827   score: 17.0   memory length: 931925   epsilon: 0.009998020008555413    steps: 629    lr: 6.553600000000004e-08     evaluation reward: 8.5\n",
      "episode: 2828   score: 11.0   memory length: 932457   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 8.51\n",
      "episode: 2829   score: 10.0   memory length: 932940   epsilon: 0.009998020008555413    steps: 483    lr: 6.553600000000004e-08     evaluation reward: 8.55\n",
      "episode: 2830   score: 8.0   memory length: 933353   epsilon: 0.009998020008555413    steps: 413    lr: 6.553600000000004e-08     evaluation reward: 8.55\n",
      "episode: 2831   score: 9.0   memory length: 933855   epsilon: 0.009998020008555413    steps: 502    lr: 6.553600000000004e-08     evaluation reward: 8.51\n",
      "episode: 2832   score: 11.0   memory length: 934387   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 8.48\n",
      "episode: 2833   score: 10.0   memory length: 934888   epsilon: 0.009998020008555413    steps: 501    lr: 6.553600000000004e-08     evaluation reward: 8.52\n",
      "episode: 2834   score: 8.0   memory length: 935301   epsilon: 0.009998020008555413    steps: 413    lr: 6.553600000000004e-08     evaluation reward: 8.54\n",
      "episode: 2835   score: 11.0   memory length: 935832   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 8.58\n",
      "episode: 2836   score: 13.0   memory length: 936434   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 8.62\n",
      "episode: 2837   score: 13.0   memory length: 937036   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 8.64\n",
      "episode: 2838   score: 11.0   memory length: 937568   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 8.63\n",
      "episode: 2839   score: 5.0   memory length: 937893   epsilon: 0.009998020008555413    steps: 325    lr: 6.553600000000004e-08     evaluation reward: 8.62\n",
      "episode: 2840   score: 13.0   memory length: 938495   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 8.65\n",
      "episode: 2841   score: 11.0   memory length: 939026   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 8.64\n",
      "episode: 2842   score: 10.0   memory length: 939509   epsilon: 0.009998020008555413    steps: 483    lr: 6.553600000000004e-08     evaluation reward: 8.63\n",
      "episode: 2843   score: 11.0   memory length: 940041   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 8.68\n",
      "episode: 2844   score: 11.0   memory length: 940572   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 8.73\n",
      "episode: 2845   score: 12.0   memory length: 941095   epsilon: 0.009998020008555413    steps: 523    lr: 6.553600000000004e-08     evaluation reward: 8.79\n",
      "episode: 2846   score: 11.0   memory length: 941626   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 8.75\n",
      "episode: 2847   score: 12.0   memory length: 942149   epsilon: 0.009998020008555413    steps: 523    lr: 6.553600000000004e-08     evaluation reward: 8.79\n",
      "episode: 2848   score: 7.0   memory length: 942573   epsilon: 0.009998020008555413    steps: 424    lr: 6.553600000000004e-08     evaluation reward: 8.8\n",
      "episode: 2849   score: 11.0   memory length: 943091   epsilon: 0.009998020008555413    steps: 518    lr: 6.553600000000004e-08     evaluation reward: 8.83\n",
      "episode: 2850   score: 10.0   memory length: 943556   epsilon: 0.009998020008555413    steps: 465    lr: 6.553600000000004e-08     evaluation reward: 8.87\n",
      "episode: 2851   score: 12.0   memory length: 944079   epsilon: 0.009998020008555413    steps: 523    lr: 6.553600000000004e-08     evaluation reward: 8.93\n",
      "episode: 2852   score: 13.0   memory length: 944681   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 8.9\n",
      "episode: 2853   score: 9.0   memory length: 945113   epsilon: 0.009998020008555413    steps: 432    lr: 6.553600000000004e-08     evaluation reward: 8.92\n",
      "episode: 2854   score: 11.0   memory length: 945647   epsilon: 0.009998020008555413    steps: 534    lr: 6.553600000000004e-08     evaluation reward: 8.92\n",
      "episode: 2855   score: 9.0   memory length: 946079   epsilon: 0.009998020008555413    steps: 432    lr: 6.553600000000004e-08     evaluation reward: 8.96\n",
      "episode: 2856   score: 9.0   memory length: 946511   epsilon: 0.009998020008555413    steps: 432    lr: 6.553600000000004e-08     evaluation reward: 8.99\n",
      "episode: 2857   score: 11.0   memory length: 947043   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 9.03\n",
      "episode: 2858   score: 13.0   memory length: 947645   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 9.09\n",
      "episode: 2859   score: 10.0   memory length: 948132   epsilon: 0.009998020008555413    steps: 487    lr: 6.553600000000004e-08     evaluation reward: 9.13\n",
      "episode: 2860   score: 11.0   memory length: 948664   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 9.18\n",
      "episode: 2861   score: 13.0   memory length: 949266   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 9.25\n",
      "episode: 2862   score: 11.0   memory length: 949763   epsilon: 0.009998020008555413    steps: 497    lr: 6.553600000000004e-08     evaluation reward: 9.3\n",
      "episode: 2863   score: 13.0   memory length: 950365   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 9.36\n",
      "episode: 2864   score: 11.0   memory length: 950897   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 9.41\n",
      "episode: 2865   score: 11.0   memory length: 951429   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 9.42\n",
      "episode: 2866   score: 11.0   memory length: 951961   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 9.47\n",
      "episode: 2867   score: 11.0   memory length: 952492   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 9.52\n",
      "episode: 2868   score: 11.0   memory length: 953024   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 9.56\n",
      "episode: 2869   score: 11.0   memory length: 953556   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 9.56\n",
      "episode: 2870   score: 20.0   memory length: 954164   epsilon: 0.009998020008555413    steps: 608    lr: 6.553600000000004e-08     evaluation reward: 9.67\n",
      "episode: 2871   score: 6.0   memory length: 954520   epsilon: 0.009998020008555413    steps: 356    lr: 6.553600000000004e-08     evaluation reward: 9.67\n",
      "episode: 2872   score: 11.0   memory length: 955052   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 9.66\n",
      "episode: 2873   score: 17.0   memory length: 955681   epsilon: 0.009998020008555413    steps: 629    lr: 6.553600000000004e-08     evaluation reward: 9.75\n",
      "episode: 2874   score: 11.0   memory length: 956212   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 9.79\n",
      "episode: 2875   score: 11.0   memory length: 956744   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 9.83\n",
      "episode: 2876   score: 13.0   memory length: 957346   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 9.86\n",
      "episode: 2877   score: 13.0   memory length: 957892   epsilon: 0.009998020008555413    steps: 546    lr: 6.553600000000004e-08     evaluation reward: 9.92\n",
      "episode: 2878   score: 12.0   memory length: 958415   epsilon: 0.009998020008555413    steps: 523    lr: 6.553600000000004e-08     evaluation reward: 9.97\n",
      "episode: 2879   score: 12.0   memory length: 958938   epsilon: 0.009998020008555413    steps: 523    lr: 6.553600000000004e-08     evaluation reward: 10.02\n",
      "episode: 2880   score: 12.0   memory length: 959461   epsilon: 0.009998020008555413    steps: 523    lr: 6.553600000000004e-08     evaluation reward: 10.07\n",
      "episode: 2881   score: 11.0   memory length: 959992   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 10.11\n",
      "episode: 2882   score: 8.0   memory length: 960465   epsilon: 0.009998020008555413    steps: 473    lr: 6.553600000000004e-08     evaluation reward: 10.12\n",
      "episode: 2883   score: 8.0   memory length: 960935   epsilon: 0.009998020008555413    steps: 470    lr: 6.553600000000004e-08     evaluation reward: 10.13\n",
      "episode: 2884   score: 6.0   memory length: 961308   epsilon: 0.009998020008555413    steps: 373    lr: 6.553600000000004e-08     evaluation reward: 10.12\n",
      "episode: 2885   score: 8.0   memory length: 961781   epsilon: 0.009998020008555413    steps: 473    lr: 6.553600000000004e-08     evaluation reward: 10.13\n",
      "episode: 2886   score: 9.0   memory length: 962301   epsilon: 0.009998020008555413    steps: 520    lr: 6.553600000000004e-08     evaluation reward: 10.15\n",
      "episode: 2887   score: 11.0   memory length: 962818   epsilon: 0.009998020008555413    steps: 517    lr: 6.553600000000004e-08     evaluation reward: 10.19\n",
      "episode: 2888   score: 8.0   memory length: 963291   epsilon: 0.009998020008555413    steps: 473    lr: 6.553600000000004e-08     evaluation reward: 10.2\n",
      "episode: 2889   score: 6.0   memory length: 963664   epsilon: 0.009998020008555413    steps: 373    lr: 6.553600000000004e-08     evaluation reward: 10.17\n",
      "episode: 2890   score: 8.0   memory length: 964137   epsilon: 0.009998020008555413    steps: 473    lr: 6.553600000000004e-08     evaluation reward: 10.16\n",
      "episode: 2891   score: 8.0   memory length: 964610   epsilon: 0.009998020008555413    steps: 473    lr: 6.553600000000004e-08     evaluation reward: 10.15\n",
      "episode: 2892   score: 9.0   memory length: 965109   epsilon: 0.009998020008555413    steps: 499    lr: 6.553600000000004e-08     evaluation reward: 10.16\n",
      "episode: 2893   score: 8.0   memory length: 965566   epsilon: 0.009998020008555413    steps: 457    lr: 6.553600000000004e-08     evaluation reward: 10.18\n",
      "episode: 2894   score: 8.0   memory length: 966039   epsilon: 0.009998020008555413    steps: 473    lr: 6.553600000000004e-08     evaluation reward: 10.16\n",
      "episode: 2895   score: 8.0   memory length: 966512   epsilon: 0.009998020008555413    steps: 473    lr: 6.553600000000004e-08     evaluation reward: 10.13\n",
      "episode: 2896   score: 8.0   memory length: 966985   epsilon: 0.009998020008555413    steps: 473    lr: 6.553600000000004e-08     evaluation reward: 10.15\n",
      "episode: 2897   score: 8.0   memory length: 967454   epsilon: 0.009998020008555413    steps: 469    lr: 6.553600000000004e-08     evaluation reward: 10.17\n",
      "episode: 2898   score: 8.0   memory length: 967928   epsilon: 0.009998020008555413    steps: 474    lr: 6.553600000000004e-08     evaluation reward: 10.19\n",
      "episode: 2899   score: 12.0   memory length: 968510   epsilon: 0.009998020008555413    steps: 582    lr: 6.553600000000004e-08     evaluation reward: 10.2\n",
      "episode: 2900   score: 8.0   memory length: 968948   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 10.17\n",
      "episode: 2901   score: 10.0   memory length: 969413   epsilon: 0.009998020008555413    steps: 465    lr: 6.553600000000004e-08     evaluation reward: 10.16\n",
      "episode: 2902   score: 9.0   memory length: 969863   epsilon: 0.009998020008555413    steps: 450    lr: 6.553600000000004e-08     evaluation reward: 10.19\n",
      "episode: 2903   score: 13.0   memory length: 970465   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 10.18\n",
      "episode: 2904   score: 11.0   memory length: 970996   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 10.23\n",
      "episode: 2905   score: 10.0   memory length: 971461   epsilon: 0.009998020008555413    steps: 465    lr: 6.553600000000004e-08     evaluation reward: 10.25\n",
      "episode: 2906   score: 13.0   memory length: 972063   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 10.32\n",
      "episode: 2907   score: 9.0   memory length: 972526   epsilon: 0.009998020008555413    steps: 463    lr: 6.553600000000004e-08     evaluation reward: 10.35\n",
      "episode: 2908   score: 13.0   memory length: 973128   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 10.42\n",
      "episode: 2909   score: 10.0   memory length: 973611   epsilon: 0.009998020008555413    steps: 483    lr: 6.553600000000004e-08     evaluation reward: 10.46\n",
      "episode: 2910   score: 13.0   memory length: 974197   epsilon: 0.009998020008555413    steps: 586    lr: 6.553600000000004e-08     evaluation reward: 10.53\n",
      "episode: 2911   score: 9.0   memory length: 974660   epsilon: 0.009998020008555413    steps: 463    lr: 6.553600000000004e-08     evaluation reward: 10.56\n",
      "episode: 2912   score: 9.0   memory length: 975123   epsilon: 0.009998020008555413    steps: 463    lr: 6.553600000000004e-08     evaluation reward: 10.59\n",
      "episode: 2913   score: 6.0   memory length: 975498   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 10.54\n",
      "episode: 2914   score: 9.0   memory length: 975961   epsilon: 0.009998020008555413    steps: 463    lr: 6.553600000000004e-08     evaluation reward: 10.55\n",
      "episode: 2915   score: 9.0   memory length: 976424   epsilon: 0.009998020008555413    steps: 463    lr: 6.553600000000004e-08     evaluation reward: 10.53\n",
      "episode: 2916   score: 19.0   memory length: 977015   epsilon: 0.009998020008555413    steps: 591    lr: 6.553600000000004e-08     evaluation reward: 10.61\n",
      "episode: 2917   score: 11.0   memory length: 977549   epsilon: 0.009998020008555413    steps: 534    lr: 6.553600000000004e-08     evaluation reward: 10.57\n",
      "episode: 2918   score: 9.0   memory length: 978012   epsilon: 0.009998020008555413    steps: 463    lr: 6.553600000000004e-08     evaluation reward: 10.55\n",
      "episode: 2919   score: 13.0   memory length: 978596   epsilon: 0.009998020008555413    steps: 584    lr: 6.553600000000004e-08     evaluation reward: 10.57\n",
      "episode: 2920   score: 12.0   memory length: 979213   epsilon: 0.009998020008555413    steps: 617    lr: 6.553600000000004e-08     evaluation reward: 10.56\n",
      "episode: 2921   score: 11.0   memory length: 979744   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 10.56\n",
      "episode: 2922   score: 11.0   memory length: 980275   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 10.5\n",
      "episode: 2923   score: 10.0   memory length: 980780   epsilon: 0.009998020008555413    steps: 505    lr: 6.553600000000004e-08     evaluation reward: 10.5\n",
      "episode: 2924   score: 8.0   memory length: 981253   epsilon: 0.009998020008555413    steps: 473    lr: 6.553600000000004e-08     evaluation reward: 10.48\n",
      "episode: 2925   score: 15.0   memory length: 981859   epsilon: 0.009998020008555413    steps: 606    lr: 6.553600000000004e-08     evaluation reward: 10.51\n",
      "episode: 2926   score: 10.0   memory length: 982324   epsilon: 0.009998020008555413    steps: 465    lr: 6.553600000000004e-08     evaluation reward: 10.55\n",
      "episode: 2927   score: 9.0   memory length: 982787   epsilon: 0.009998020008555413    steps: 463    lr: 6.553600000000004e-08     evaluation reward: 10.47\n",
      "episode: 2928   score: 13.0   memory length: 983388   epsilon: 0.009998020008555413    steps: 601    lr: 6.553600000000004e-08     evaluation reward: 10.49\n",
      "episode: 2929   score: 11.0   memory length: 983920   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 10.5\n",
      "episode: 2930   score: 10.0   memory length: 984385   epsilon: 0.009998020008555413    steps: 465    lr: 6.553600000000004e-08     evaluation reward: 10.52\n",
      "episode: 2931   score: 15.0   memory length: 984953   epsilon: 0.009998020008555413    steps: 568    lr: 6.553600000000004e-08     evaluation reward: 10.58\n",
      "episode: 2932   score: 9.0   memory length: 985416   epsilon: 0.009998020008555413    steps: 463    lr: 6.553600000000004e-08     evaluation reward: 10.56\n",
      "episode: 2933   score: 8.0   memory length: 985829   epsilon: 0.009998020008555413    steps: 413    lr: 6.553600000000004e-08     evaluation reward: 10.54\n",
      "episode: 2934   score: 11.0   memory length: 986361   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 10.57\n",
      "episode: 2935   score: 9.0   memory length: 986860   epsilon: 0.009998020008555413    steps: 499    lr: 6.553600000000004e-08     evaluation reward: 10.55\n",
      "episode: 2936   score: 11.0   memory length: 987392   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 10.53\n",
      "episode: 2937   score: 11.0   memory length: 987889   epsilon: 0.009998020008555413    steps: 497    lr: 6.553600000000004e-08     evaluation reward: 10.51\n",
      "episode: 2938   score: 10.0   memory length: 988372   epsilon: 0.009998020008555413    steps: 483    lr: 6.553600000000004e-08     evaluation reward: 10.5\n",
      "episode: 2939   score: 11.0   memory length: 988904   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 10.56\n",
      "episode: 2940   score: 15.0   memory length: 989472   epsilon: 0.009998020008555413    steps: 568    lr: 6.553600000000004e-08     evaluation reward: 10.58\n",
      "episode: 2941   score: 11.0   memory length: 990004   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 10.58\n",
      "episode: 2942   score: 15.0   memory length: 990572   epsilon: 0.009998020008555413    steps: 568    lr: 6.553600000000004e-08     evaluation reward: 10.63\n",
      "episode: 2943   score: 14.0   memory length: 991093   epsilon: 0.009998020008555413    steps: 521    lr: 6.553600000000004e-08     evaluation reward: 10.66\n",
      "episode: 2944   score: 9.0   memory length: 991595   epsilon: 0.009998020008555413    steps: 502    lr: 6.553600000000004e-08     evaluation reward: 10.64\n",
      "episode: 2945   score: 15.0   memory length: 992163   epsilon: 0.009998020008555413    steps: 568    lr: 6.553600000000004e-08     evaluation reward: 10.67\n",
      "episode: 2946   score: 9.0   memory length: 992625   epsilon: 0.009998020008555413    steps: 462    lr: 6.553600000000004e-08     evaluation reward: 10.65\n",
      "episode: 2947   score: 7.0   memory length: 992995   epsilon: 0.009998020008555413    steps: 370    lr: 6.553600000000004e-08     evaluation reward: 10.6\n",
      "episode: 2948   score: 9.0   memory length: 993458   epsilon: 0.009998020008555413    steps: 463    lr: 6.553600000000004e-08     evaluation reward: 10.62\n",
      "episode: 2949   score: 11.0   memory length: 993989   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 10.62\n",
      "episode: 2950   score: 10.0   memory length: 994494   epsilon: 0.009998020008555413    steps: 505    lr: 6.553600000000004e-08     evaluation reward: 10.62\n",
      "episode: 2951   score: 11.0   memory length: 995025   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 10.61\n",
      "episode: 2952   score: 11.0   memory length: 995556   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 10.59\n",
      "episode: 2953   score: 9.0   memory length: 996006   epsilon: 0.009998020008555413    steps: 450    lr: 6.553600000000004e-08     evaluation reward: 10.59\n",
      "episode: 2954   score: 13.0   memory length: 996608   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 10.61\n",
      "episode: 2955   score: 13.0   memory length: 997210   epsilon: 0.009998020008555413    steps: 602    lr: 6.553600000000004e-08     evaluation reward: 10.65\n",
      "episode: 2956   score: 11.0   memory length: 997768   epsilon: 0.009998020008555413    steps: 558    lr: 6.553600000000004e-08     evaluation reward: 10.67\n",
      "episode: 2957   score: 10.0   memory length: 998281   epsilon: 0.009998020008555413    steps: 513    lr: 6.553600000000004e-08     evaluation reward: 10.66\n",
      "episode: 2958   score: 10.0   memory length: 998782   epsilon: 0.009998020008555413    steps: 501    lr: 6.553600000000004e-08     evaluation reward: 10.63\n",
      "episode: 2959   score: 11.0   memory length: 999314   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 10.64\n",
      "episode: 2960   score: 11.0   memory length: 999846   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 10.64\n",
      "episode: 2961   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 509    lr: 2.6214400000000017e-08     evaluation reward: 10.61\n",
      "episode: 2962   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 10.6\n",
      "episode: 2963   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 497    lr: 2.6214400000000017e-08     evaluation reward: 10.58\n",
      "episode: 2964   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 10.57\n",
      "episode: 2965   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 10.57\n",
      "episode: 2966   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 432    lr: 2.6214400000000017e-08     evaluation reward: 10.55\n",
      "episode: 2967   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 602    lr: 2.6214400000000017e-08     evaluation reward: 10.57\n",
      "episode: 2968   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 485    lr: 2.6214400000000017e-08     evaluation reward: 10.56\n",
      "episode: 2969   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 497    lr: 2.6214400000000017e-08     evaluation reward: 10.55\n",
      "episode: 2970   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 483    lr: 2.6214400000000017e-08     evaluation reward: 10.45\n",
      "episode: 2971   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 2.6214400000000017e-08     evaluation reward: 10.5\n",
      "episode: 2972   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 2.6214400000000017e-08     evaluation reward: 10.5\n",
      "episode: 2973   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 2.6214400000000017e-08     evaluation reward: 10.44\n",
      "episode: 2974   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 2.6214400000000017e-08     evaluation reward: 10.44\n",
      "episode: 2975   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 450    lr: 2.6214400000000017e-08     evaluation reward: 10.42\n",
      "episode: 2976   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 2.6214400000000017e-08     evaluation reward: 10.4\n",
      "episode: 2977   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 483    lr: 2.6214400000000017e-08     evaluation reward: 10.37\n",
      "episode: 2978   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 10.34\n",
      "episode: 2979   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 2.6214400000000017e-08     evaluation reward: 10.33\n",
      "episode: 2980   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 536    lr: 2.6214400000000017e-08     evaluation reward: 10.34\n",
      "episode: 2981   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 602    lr: 2.6214400000000017e-08     evaluation reward: 10.36\n",
      "episode: 2982   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 2.6214400000000017e-08     evaluation reward: 10.39\n",
      "episode: 2983   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 518    lr: 2.6214400000000017e-08     evaluation reward: 10.42\n",
      "episode: 2984   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 602    lr: 2.6214400000000017e-08     evaluation reward: 10.49\n",
      "episode: 2985   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 2.6214400000000017e-08     evaluation reward: 10.47\n",
      "episode: 2986   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 10.5\n",
      "episode: 2987   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 10.51\n",
      "episode: 2988   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 568    lr: 2.6214400000000017e-08     evaluation reward: 10.58\n",
      "episode: 2989   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 602    lr: 2.6214400000000017e-08     evaluation reward: 10.65\n",
      "episode: 2990   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 602    lr: 2.6214400000000017e-08     evaluation reward: 10.7\n",
      "episode: 2991   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 602    lr: 2.6214400000000017e-08     evaluation reward: 10.75\n",
      "episode: 2992   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 10.76\n",
      "episode: 2993   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 602    lr: 2.6214400000000017e-08     evaluation reward: 10.81\n",
      "episode: 2994   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 10.85\n",
      "episode: 2995   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 568    lr: 2.6214400000000017e-08     evaluation reward: 10.92\n",
      "episode: 2996   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 10.95\n",
      "episode: 2997   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 2.6214400000000017e-08     evaluation reward: 10.98\n",
      "episode: 2998   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 482    lr: 2.6214400000000017e-08     evaluation reward: 11.0\n",
      "episode: 2999   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 10.98\n",
      "episode: 3000   score: 20.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 607    lr: 2.6214400000000017e-08     evaluation reward: 11.1\n",
      "episode: 3001   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.11\n",
      "episode: 3002   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 495    lr: 2.6214400000000017e-08     evaluation reward: 11.12\n",
      "episode: 3003   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.1\n",
      "episode: 3004   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 11.11\n",
      "episode: 3005   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 485    lr: 2.6214400000000017e-08     evaluation reward: 11.11\n",
      "episode: 3006   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 11.1\n",
      "episode: 3007   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 11.1\n",
      "episode: 3008   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 2.6214400000000017e-08     evaluation reward: 11.07\n",
      "episode: 3009   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.08\n",
      "episode: 3010   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 602    lr: 2.6214400000000017e-08     evaluation reward: 11.08\n",
      "episode: 3011   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 11.08\n",
      "episode: 3012   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.1\n",
      "episode: 3013   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 483    lr: 2.6214400000000017e-08     evaluation reward: 11.14\n",
      "episode: 3014   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 11.17\n",
      "episode: 3015   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 509    lr: 2.6214400000000017e-08     evaluation reward: 11.18\n",
      "episode: 3016   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.1\n",
      "episode: 3017   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.09\n",
      "episode: 3018   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.11\n",
      "episode: 3019   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.09\n",
      "episode: 3020   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.08\n",
      "episode: 3021   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.07\n",
      "episode: 3022   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 432    lr: 2.6214400000000017e-08     evaluation reward: 11.05\n",
      "episode: 3023   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.05\n",
      "episode: 3024   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.07\n",
      "episode: 3025   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 11.04\n",
      "episode: 3026   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.05\n",
      "episode: 3027   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.07\n",
      "episode: 3028   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 568    lr: 2.6214400000000017e-08     evaluation reward: 11.09\n",
      "episode: 3029   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 617    lr: 2.6214400000000017e-08     evaluation reward: 11.1\n",
      "episode: 3030   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 505    lr: 2.6214400000000017e-08     evaluation reward: 11.1\n",
      "episode: 3031   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 432    lr: 2.6214400000000017e-08     evaluation reward: 11.04\n",
      "episode: 3032   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.06\n",
      "episode: 3033   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.09\n",
      "episode: 3034   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 568    lr: 2.6214400000000017e-08     evaluation reward: 11.13\n",
      "episode: 3035   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 418    lr: 2.6214400000000017e-08     evaluation reward: 11.16\n",
      "episode: 3036   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.16\n",
      "episode: 3037   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 11.17\n",
      "episode: 3038   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 11.19\n",
      "episode: 3039   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 11.2\n",
      "episode: 3040   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.16\n",
      "episode: 3041   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 451    lr: 2.6214400000000017e-08     evaluation reward: 11.14\n",
      "episode: 3042   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 11.11\n",
      "episode: 3043   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 534    lr: 2.6214400000000017e-08     evaluation reward: 11.08\n",
      "episode: 3044   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.09\n",
      "episode: 3045   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.04\n",
      "episode: 3046   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.06\n",
      "episode: 3047   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.09\n",
      "episode: 3048   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 11.08\n",
      "episode: 3049   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.07\n",
      "episode: 3050   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.08\n",
      "episode: 3051   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 617    lr: 2.6214400000000017e-08     evaluation reward: 11.09\n",
      "episode: 3052   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 485    lr: 2.6214400000000017e-08     evaluation reward: 11.08\n",
      "episode: 3053   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.09\n",
      "episode: 3054   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.06\n",
      "episode: 3055   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 464    lr: 2.6214400000000017e-08     evaluation reward: 11.02\n",
      "episode: 3056   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.02\n",
      "episode: 3057   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.02\n",
      "episode: 3058   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.02\n",
      "episode: 3059   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.02\n",
      "episode: 3060   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.01\n",
      "episode: 3061   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 10.99\n",
      "episode: 3062   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 534    lr: 2.6214400000000017e-08     evaluation reward: 11.0\n",
      "episode: 3063   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 531    lr: 2.6214400000000017e-08     evaluation reward: 11.0\n",
      "episode: 3064   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 11.0\n",
      "episode: 3065   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 10.99\n",
      "episode: 3066   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 464    lr: 2.6214400000000017e-08     evaluation reward: 10.99\n",
      "episode: 3067   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 535    lr: 2.6214400000000017e-08     evaluation reward: 10.96\n",
      "episode: 3068   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 10.96\n",
      "episode: 3069   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 10.94\n",
      "episode: 3070   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 373    lr: 2.6214400000000017e-08     evaluation reward: 10.9\n",
      "episode: 3071   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 2.6214400000000017e-08     evaluation reward: 10.85\n",
      "episode: 3072   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 10.86\n",
      "episode: 3073   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 2.6214400000000017e-08     evaluation reward: 10.83\n",
      "episode: 3074   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 557    lr: 2.6214400000000017e-08     evaluation reward: 10.87\n",
      "episode: 3075   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 2.6214400000000017e-08     evaluation reward: 10.87\n",
      "episode: 3076   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 2.6214400000000017e-08     evaluation reward: 10.85\n",
      "episode: 3077   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 2.6214400000000017e-08     evaluation reward: 10.84\n",
      "episode: 3078   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 487    lr: 2.6214400000000017e-08     evaluation reward: 10.84\n",
      "episode: 3079   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 10.81\n",
      "episode: 3080   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 474    lr: 2.6214400000000017e-08     evaluation reward: 10.76\n",
      "episode: 3081   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 10.71\n",
      "episode: 3082   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 10.68\n",
      "episode: 3083   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 421    lr: 2.6214400000000017e-08     evaluation reward: 10.64\n",
      "episode: 3084   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 2.6214400000000017e-08     evaluation reward: 10.57\n",
      "episode: 3085   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 2.6214400000000017e-08     evaluation reward: 10.58\n",
      "episode: 3086   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 2.6214400000000017e-08     evaluation reward: 10.52\n",
      "episode: 3087   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 534    lr: 2.6214400000000017e-08     evaluation reward: 10.5\n",
      "episode: 3088   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 368    lr: 2.6214400000000017e-08     evaluation reward: 10.42\n",
      "episode: 3089   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 549    lr: 2.6214400000000017e-08     evaluation reward: 10.4\n",
      "episode: 3090   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 2.6214400000000017e-08     evaluation reward: 10.35\n",
      "episode: 3091   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 495    lr: 2.6214400000000017e-08     evaluation reward: 10.32\n",
      "episode: 3092   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 10.3\n",
      "episode: 3093   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 325    lr: 2.6214400000000017e-08     evaluation reward: 10.22\n",
      "episode: 3094   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 10.18\n",
      "episode: 3095   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 10.11\n",
      "episode: 3096   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 325    lr: 2.6214400000000017e-08     evaluation reward: 10.05\n",
      "episode: 3097   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 10.02\n",
      "episode: 3098   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 459    lr: 2.6214400000000017e-08     evaluation reward: 10.0\n",
      "episode: 3099   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 2.6214400000000017e-08     evaluation reward: 9.99\n",
      "episode: 3100   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.87\n",
      "episode: 3101   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.84\n",
      "episode: 3102   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.82\n",
      "episode: 3103   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.79\n",
      "episode: 3104   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.75\n",
      "episode: 3105   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.73\n",
      "episode: 3106   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.69\n",
      "episode: 3107   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.68\n",
      "episode: 3108   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 423    lr: 2.6214400000000017e-08     evaluation reward: 9.65\n",
      "episode: 3109   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.62\n",
      "episode: 3110   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 325    lr: 2.6214400000000017e-08     evaluation reward: 9.54\n",
      "episode: 3111   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 373    lr: 2.6214400000000017e-08     evaluation reward: 9.51\n",
      "episode: 3112   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.48\n",
      "episode: 3113   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 2.6214400000000017e-08     evaluation reward: 9.47\n",
      "episode: 3114   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.43\n",
      "episode: 3115   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.41\n",
      "episode: 3116   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 2.6214400000000017e-08     evaluation reward: 9.38\n",
      "episode: 3117   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 2.6214400000000017e-08     evaluation reward: 9.35\n",
      "episode: 3118   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 2.6214400000000017e-08     evaluation reward: 9.31\n",
      "episode: 3119   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.28\n",
      "episode: 3120   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.25\n",
      "episode: 3121   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.23\n",
      "episode: 3122   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.22\n",
      "episode: 3123   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 526    lr: 2.6214400000000017e-08     evaluation reward: 9.22\n",
      "episode: 3124   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 503    lr: 2.6214400000000017e-08     evaluation reward: 9.22\n",
      "episode: 3125   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.18\n",
      "episode: 3126   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.15\n",
      "episode: 3127   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 420    lr: 2.6214400000000017e-08     evaluation reward: 9.12\n",
      "episode: 3128   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 459    lr: 2.6214400000000017e-08     evaluation reward: 9.05\n",
      "episode: 3129   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 9.01\n",
      "episode: 3130   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.99\n",
      "episode: 3131   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.98\n",
      "episode: 3132   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 2.6214400000000017e-08     evaluation reward: 8.94\n",
      "episode: 3133   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 541    lr: 2.6214400000000017e-08     evaluation reward: 8.93\n",
      "episode: 3134   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 2.6214400000000017e-08     evaluation reward: 8.88\n",
      "episode: 3135   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.84\n",
      "episode: 3136   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.81\n",
      "episode: 3137   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.77\n",
      "episode: 3138   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.73\n",
      "episode: 3139   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 424    lr: 2.6214400000000017e-08     evaluation reward: 8.68\n",
      "episode: 3140   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.65\n",
      "episode: 3141   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 2.6214400000000017e-08     evaluation reward: 8.65\n",
      "episode: 3142   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.61\n",
      "episode: 3143   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 451    lr: 2.6214400000000017e-08     evaluation reward: 8.59\n",
      "episode: 3144   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.57\n",
      "episode: 3145   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 352    lr: 2.6214400000000017e-08     evaluation reward: 8.53\n",
      "episode: 3146   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.5\n",
      "episode: 3147   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.48\n",
      "episode: 3148   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 2.6214400000000017e-08     evaluation reward: 8.46\n",
      "episode: 3149   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.44\n",
      "episode: 3150   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 2.6214400000000017e-08     evaluation reward: 8.39\n",
      "episode: 3151   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 373    lr: 2.6214400000000017e-08     evaluation reward: 8.33\n",
      "episode: 3152   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.31\n",
      "episode: 3153   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 471    lr: 2.6214400000000017e-08     evaluation reward: 8.3\n",
      "episode: 3154   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.28\n",
      "episode: 3155   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 482    lr: 2.6214400000000017e-08     evaluation reward: 8.28\n",
      "episode: 3156   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.25\n",
      "episode: 3157   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.23\n",
      "episode: 3158   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.21\n",
      "episode: 3159   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 2.6214400000000017e-08     evaluation reward: 8.16\n",
      "episode: 3160   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.14\n",
      "episode: 3161   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.14\n",
      "episode: 3162   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 2.6214400000000017e-08     evaluation reward: 8.1\n",
      "episode: 3163   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.07\n",
      "episode: 3164   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 2.6214400000000017e-08     evaluation reward: 8.04\n",
      "episode: 3165   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 512    lr: 2.6214400000000017e-08     evaluation reward: 8.04\n",
      "episode: 3166   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 8.03\n",
      "episode: 3167   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 1.0485760000000008e-08     evaluation reward: 8.0\n",
      "episode: 3168   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.98\n",
      "episode: 3169   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.98\n",
      "episode: 3170   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 517    lr: 1.0485760000000008e-08     evaluation reward: 8.03\n",
      "episode: 3171   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 408    lr: 1.0485760000000008e-08     evaluation reward: 8.04\n",
      "episode: 3172   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 8.0\n",
      "episode: 3173   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 8.0\n",
      "episode: 3174   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.93\n",
      "episode: 3175   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.92\n",
      "episode: 3176   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.89\n",
      "episode: 3177   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 7.89\n",
      "episode: 3178   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3179   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3180   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3181   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3182   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 502    lr: 1.0485760000000008e-08     evaluation reward: 7.91\n",
      "episode: 3183   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.92\n",
      "episode: 3184   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.94\n",
      "episode: 3185   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.93\n",
      "episode: 3186   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 384    lr: 1.0485760000000008e-08     evaluation reward: 7.94\n",
      "episode: 3187   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.92\n",
      "episode: 3188   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 385    lr: 1.0485760000000008e-08     evaluation reward: 7.92\n",
      "episode: 3189   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 390    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3190   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 517    lr: 1.0485760000000008e-08     evaluation reward: 7.91\n",
      "episode: 3191   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.89\n",
      "episode: 3192   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.87\n",
      "episode: 3193   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3194   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3195   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 358    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3196   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 521    lr: 1.0485760000000008e-08     evaluation reward: 7.91\n",
      "episode: 3197   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.91\n",
      "episode: 3198   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.91\n",
      "episode: 3199   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3200   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3201   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3202   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3203   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 428    lr: 1.0485760000000008e-08     evaluation reward: 7.91\n",
      "episode: 3204   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 1.0485760000000008e-08     evaluation reward: 7.94\n",
      "episode: 3205   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.94\n",
      "episode: 3206   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.94\n",
      "episode: 3207   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 527    lr: 1.0485760000000008e-08     evaluation reward: 7.96\n",
      "episode: 3208   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.97\n",
      "episode: 3209   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 1.0485760000000008e-08     evaluation reward: 7.96\n",
      "episode: 3210   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.99\n",
      "episode: 3211   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.99\n",
      "episode: 3212   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 497    lr: 1.0485760000000008e-08     evaluation reward: 8.02\n",
      "episode: 3213   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 8.01\n",
      "episode: 3214   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 485    lr: 1.0485760000000008e-08     evaluation reward: 8.02\n",
      "episode: 3215   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 8.02\n",
      "episode: 3216   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 8.02\n",
      "episode: 3217   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 8.03\n",
      "episode: 3218   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 8.05\n",
      "episode: 3219   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 1.0485760000000008e-08     evaluation reward: 8.04\n",
      "episode: 3220   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 8.05\n",
      "episode: 3221   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 8.05\n",
      "episode: 3222   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 373    lr: 1.0485760000000008e-08     evaluation reward: 8.03\n",
      "episode: 3223   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 585    lr: 1.0485760000000008e-08     evaluation reward: 8.05\n",
      "episode: 3224   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 8.03\n",
      "episode: 3225   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 8.01\n",
      "episode: 3226   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 8.01\n",
      "episode: 3227   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 8.03\n",
      "episode: 3228   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 8.03\n",
      "episode: 3229   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 8.04\n",
      "episode: 3230   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 273    lr: 1.0485760000000008e-08     evaluation reward: 8.0\n",
      "episode: 3231   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 352    lr: 1.0485760000000008e-08     evaluation reward: 7.98\n",
      "episode: 3232   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.99\n",
      "episode: 3233   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.95\n",
      "episode: 3234   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.93\n",
      "episode: 3235   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.93\n",
      "episode: 3236   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 450    lr: 1.0485760000000008e-08     evaluation reward: 7.93\n",
      "episode: 3237   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.91\n",
      "episode: 3238   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.91\n",
      "episode: 3239   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3240   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3241   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3242   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3243   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.89\n",
      "episode: 3244   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 451    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3245   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 1.0485760000000008e-08     evaluation reward: 7.91\n",
      "episode: 3246   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.91\n",
      "episode: 3247   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.89\n",
      "episode: 3248   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.91\n",
      "episode: 3249   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 325    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3250   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 311    lr: 1.0485760000000008e-08     evaluation reward: 7.87\n",
      "episode: 3251   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.89\n",
      "episode: 3252   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 352    lr: 1.0485760000000008e-08     evaluation reward: 7.87\n",
      "episode: 3253   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3254   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 373    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3255   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.81\n",
      "episode: 3256   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.79\n",
      "episode: 3257   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.79\n",
      "episode: 3258   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.79\n",
      "episode: 3259   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3260   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3261   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3262   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 547    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3263   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3264   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.87\n",
      "episode: 3265   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.85\n",
      "episode: 3266   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.85\n",
      "episode: 3267   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3268   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 428    lr: 1.0485760000000008e-08     evaluation reward: 7.89\n",
      "episode: 3269   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 354    lr: 1.0485760000000008e-08     evaluation reward: 7.87\n",
      "episode: 3270   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 1.0485760000000008e-08     evaluation reward: 7.83\n",
      "episode: 3271   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3272   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3273   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3274   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3275   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3276   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 7.87\n",
      "episode: 3277   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3278   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3279   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3280   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3281   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3282   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.83\n",
      "episode: 3283   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.83\n",
      "episode: 3284   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.81\n",
      "episode: 3285   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 451    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3286   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.85\n",
      "episode: 3287   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.85\n",
      "episode: 3288   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3289   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3290   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.83\n",
      "episode: 3291   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 385    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3292   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3293   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3294   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3295   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3296   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3297   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3298   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3299   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3300   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 431    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3301   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 431    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3302   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3303   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 459    lr: 1.0485760000000008e-08     evaluation reward: 7.85\n",
      "episode: 3304   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3305   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3306   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3307   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.8\n",
      "episode: 3308   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.8\n",
      "episode: 3309   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.81\n",
      "episode: 3310   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.81\n",
      "episode: 3311   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.83\n",
      "episode: 3312   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.8\n",
      "episode: 3313   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3314   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.81\n",
      "episode: 3315   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 541    lr: 1.0485760000000008e-08     evaluation reward: 7.83\n",
      "episode: 3316   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 332    lr: 1.0485760000000008e-08     evaluation reward: 7.81\n",
      "episode: 3317   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 1.0485760000000008e-08     evaluation reward: 7.83\n",
      "episode: 3318   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3319   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 585    lr: 1.0485760000000008e-08     evaluation reward: 7.87\n",
      "episode: 3320   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3321   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3322   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 7.87\n",
      "episode: 3323   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 462    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3324   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 352    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3325   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3326   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3327   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.78\n",
      "episode: 3328   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 420    lr: 1.0485760000000008e-08     evaluation reward: 7.78\n",
      "episode: 3329   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 486    lr: 1.0485760000000008e-08     evaluation reward: 7.78\n",
      "episode: 3330   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3331   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3332   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 425    lr: 1.0485760000000008e-08     evaluation reward: 7.83\n",
      "episode: 3333   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.85\n",
      "episode: 3334   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3335   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 352    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3336   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3337   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3338   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3339   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3340   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3341   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 424    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3342   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3343   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 421    lr: 1.0485760000000008e-08     evaluation reward: 7.83\n",
      "episode: 3344   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3345   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3346   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3347   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3348   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 325    lr: 1.0485760000000008e-08     evaluation reward: 7.81\n",
      "episode: 3349   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 1.0485760000000008e-08     evaluation reward: 7.83\n",
      "episode: 3350   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3351   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 486    lr: 1.0485760000000008e-08     evaluation reward: 7.85\n",
      "episode: 3352   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.87\n",
      "episode: 3353   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.87\n",
      "episode: 3354   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3355   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3356   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.92\n",
      "episode: 3357   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 614    lr: 1.0485760000000008e-08     evaluation reward: 7.99\n",
      "episode: 3358   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.99\n",
      "episode: 3359   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.98\n",
      "episode: 3360   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.98\n",
      "episode: 3361   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 373    lr: 1.0485760000000008e-08     evaluation reward: 7.96\n",
      "episode: 3362   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 469    lr: 1.0485760000000008e-08     evaluation reward: 7.94\n",
      "episode: 3363   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 453    lr: 1.0485760000000008e-08     evaluation reward: 7.94\n",
      "episode: 3364   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 434    lr: 1.0485760000000008e-08     evaluation reward: 7.94\n",
      "episode: 3365   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.94\n",
      "episode: 3366   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 407    lr: 1.0485760000000008e-08     evaluation reward: 7.94\n",
      "episode: 3367   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 1.0485760000000008e-08     evaluation reward: 7.93\n",
      "episode: 3368   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 431    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3369   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3370   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 7.92\n",
      "episode: 3371   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3372   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3373   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 431    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3374   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 519    lr: 1.0485760000000008e-08     evaluation reward: 7.92\n",
      "episode: 3375   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.94\n",
      "episode: 3376   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.93\n",
      "episode: 3377   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 401    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3378   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3379   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3380   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.92\n",
      "episode: 3381   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 336    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3382   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3383   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 1.0485760000000008e-08     evaluation reward: 7.88\n",
      "episode: 3384   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3385   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.89\n",
      "episode: 3386   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 1.0485760000000008e-08     evaluation reward: 7.89\n",
      "episode: 3387   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.89\n",
      "episode: 3388   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 1.0485760000000008e-08     evaluation reward: 7.89\n",
      "episode: 3389   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 352    lr: 4.194304000000004e-09     evaluation reward: 7.88\n",
      "episode: 3390   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 4.194304000000004e-09     evaluation reward: 7.89\n",
      "episode: 3391   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.9\n",
      "episode: 3392   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.9\n",
      "episode: 3393   score: 16.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 547    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3394   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3395   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3396   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 4.194304000000004e-09     evaluation reward: 7.99\n",
      "episode: 3397   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 469    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3398   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3399   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3400   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3401   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 402    lr: 4.194304000000004e-09     evaluation reward: 7.99\n",
      "episode: 3402   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3403   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 373    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3404   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3405   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3406   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 406    lr: 4.194304000000004e-09     evaluation reward: 7.95\n",
      "episode: 3407   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.95\n",
      "episode: 3408   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.95\n",
      "episode: 3409   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.95\n",
      "episode: 3410   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.95\n",
      "episode: 3411   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.95\n",
      "episode: 3412   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 373    lr: 4.194304000000004e-09     evaluation reward: 7.93\n",
      "episode: 3413   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.91\n",
      "episode: 3414   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.91\n",
      "episode: 3415   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 527    lr: 4.194304000000004e-09     evaluation reward: 7.92\n",
      "episode: 3416   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 4.194304000000004e-09     evaluation reward: 7.94\n",
      "episode: 3417   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.92\n",
      "episode: 3418   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 4.194304000000004e-09     evaluation reward: 7.93\n",
      "episode: 3419   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 4.194304000000004e-09     evaluation reward: 7.91\n",
      "episode: 3420   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.91\n",
      "episode: 3421   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.93\n",
      "episode: 3422   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 4.194304000000004e-09     evaluation reward: 7.91\n",
      "episode: 3423   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.9\n",
      "episode: 3424   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.92\n",
      "episode: 3425   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.94\n",
      "episode: 3426   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 4.194304000000004e-09     evaluation reward: 7.92\n",
      "episode: 3427   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 4.194304000000004e-09     evaluation reward: 7.92\n",
      "episode: 3428   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 373    lr: 4.194304000000004e-09     evaluation reward: 7.9\n",
      "episode: 3429   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 4.194304000000004e-09     evaluation reward: 7.91\n",
      "episode: 3430   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 4.194304000000004e-09     evaluation reward: 7.91\n",
      "episode: 3431   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 541    lr: 4.194304000000004e-09     evaluation reward: 7.93\n",
      "episode: 3432   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 4.194304000000004e-09     evaluation reward: 7.93\n",
      "episode: 3433   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.93\n",
      "episode: 3434   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 431    lr: 4.194304000000004e-09     evaluation reward: 7.94\n",
      "episode: 3435   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3436   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3437   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3438   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 431    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3439   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 4.194304000000004e-09     evaluation reward: 7.94\n",
      "episode: 3440   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 4.194304000000004e-09     evaluation reward: 7.94\n",
      "episode: 3441   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 457    lr: 4.194304000000004e-09     evaluation reward: 7.95\n",
      "episode: 3442   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.95\n",
      "episode: 3443   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3444   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 4.194304000000004e-09     evaluation reward: 7.95\n",
      "episode: 3445   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 490    lr: 4.194304000000004e-09     evaluation reward: 7.97\n",
      "episode: 3446   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3447   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3448   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 4.194304000000004e-09     evaluation reward: 7.99\n",
      "episode: 3449   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3450   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 4.194304000000004e-09     evaluation reward: 8.01\n",
      "episode: 3451   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 332    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3452   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3453   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3454   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 451    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3455   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3456   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3457   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 614    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3458   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3459   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3460   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3461   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.02\n",
      "episode: 3462   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.01\n",
      "episode: 3463   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.01\n",
      "episode: 3464   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 352    lr: 4.194304000000004e-09     evaluation reward: 7.99\n",
      "episode: 3465   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.99\n",
      "episode: 3466   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.99\n",
      "episode: 3467   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3468   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.0\n",
      "episode: 3469   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 8.02\n",
      "episode: 3470   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 4.194304000000004e-09     evaluation reward: 7.99\n",
      "episode: 3471   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.99\n",
      "episode: 3472   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.99\n",
      "episode: 3473   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.99\n",
      "episode: 3474   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 4.194304000000004e-09     evaluation reward: 7.95\n",
      "episode: 3475   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 4.194304000000004e-09     evaluation reward: 7.93\n",
      "episode: 3476   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 422    lr: 4.194304000000004e-09     evaluation reward: 7.92\n",
      "episode: 3477   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.93\n",
      "episode: 3478   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.93\n",
      "episode: 3479   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 555    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3480   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3481   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3482   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3483   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3484   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3485   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3486   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 4.194304000000004e-09     evaluation reward: 7.99\n",
      "episode: 3487   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.99\n",
      "episode: 3488   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 325    lr: 4.194304000000004e-09     evaluation reward: 7.96\n",
      "episode: 3489   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.98\n",
      "episode: 3490   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 373    lr: 4.194304000000004e-09     evaluation reward: 7.95\n",
      "episode: 3491   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 373    lr: 4.194304000000004e-09     evaluation reward: 7.93\n",
      "episode: 3492   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 373    lr: 4.194304000000004e-09     evaluation reward: 7.91\n",
      "episode: 3493   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.83\n",
      "episode: 3494   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.81\n",
      "episode: 3495   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 502    lr: 4.194304000000004e-09     evaluation reward: 7.82\n",
      "episode: 3496   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.83\n",
      "episode: 3497   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.82\n",
      "episode: 3498   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.82\n",
      "episode: 3499   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 4.194304000000004e-09     evaluation reward: 7.82\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "rewards, episodes = [], []\n",
    "best_eval_reward = 5\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "    step = 0\n",
    "    state = env.reset()\n",
    "    next_state = state\n",
    "    life = number_lives\n",
    "\n",
    "    get_init_state(history, state[0], HISTORY_SIZE)\n",
    "\n",
    "    while not done:\n",
    "        step += 1\n",
    "        frame += 1\n",
    "\n",
    "        # Perform a fire action if ball is no longer on screen to continue onto next life\n",
    "        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "        state = next_state\n",
    "        #next_state, reward, done, info = env.step(action + 1)\n",
    "        observation, reward, terminated, truncated, info = env.step(action + 1)\n",
    "        next_state = observation\n",
    "        done = terminated\n",
    "        \n",
    "        \n",
    "        frame_next_state = get_frame(next_state)\n",
    "        history[4, :, :] = frame_next_state\n",
    "        terminal_state = check_live(life, info['lives'])\n",
    "\n",
    "        life = info['lives']\n",
    "        r = reward\n",
    "\n",
    "        # Store the transition in memory \n",
    "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "        # Start training after random sample generation\n",
    "        if(frame >= train_frame):\n",
    "            agent.train_policy_net(frame)\n",
    "            # Update the target network only for Double DQN only\n",
    "            if double_dqn and (frame % update_target_network_frequency)== 0:\n",
    "                agent.update_target_net()\n",
    "        score += reward\n",
    "        history[:4, :, :] = history[1:, :, :]\n",
    "            \n",
    "        if done:\n",
    "            evaluation_reward.append(score)\n",
    "            rewards.append(np.mean(evaluation_reward))\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, rewards, 'b')\n",
    "            pylab.xlabel('Episodes')\n",
    "            pylab.ylabel('Rewards') \n",
    "            pylab.title('Episodes vs Reward')\n",
    "            \n",
    "            ####\n",
    "            save_graph_dir = './save_graph'\n",
    "            if not os.path.exists(save_graph_dir):\n",
    "                os.makedirs(save_graph_dir)\n",
    "            ####\n",
    "            pylab.savefig(\"./save_graph/breakout_dqn.png\") # save graph for training visualization\n",
    "            \n",
    "            # every episode, plot the play time\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n",
    "                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n",
    "\n",
    "            # if the mean of scores of last 100 episode is bigger than 5 save model\n",
    "            ### Change this save condition to whatever you prefer ###\n",
    "            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n",
    "                torch.save(agent.policy_net, \"./save_model/breakout_dqn.pth\")\n",
    "                best_eval_reward = np.mean(evaluation_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_eval_reward"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
